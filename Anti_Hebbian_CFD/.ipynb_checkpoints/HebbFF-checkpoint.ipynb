{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b2b15ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import torchviz\n",
    "import sys\n",
    "# from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7225a477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07a382fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_seq(batch_size, vec_len, R, T):\n",
    "    batch_input = []\n",
    "    batch_target = []\n",
    "    \n",
    "    for batch in range (batch_size):\n",
    "        input = []\n",
    "        target = []\n",
    "        for i in range(R):\n",
    "            input.append(torch.bernoulli(torch.empty(vec_len).uniform_(0, 1)))\n",
    "            target.append(torch.zeros(1))\n",
    "        \n",
    "        for i in range(R, 2*R):\n",
    "            if np.random.rand() > 0.5:\n",
    "                input.append(input[i-R])\n",
    "                target.append(torch.ones(1))\n",
    "            else:\n",
    "                input.append(torch.bernoulli(torch.empty(vec_len).uniform_(0, 1)))\n",
    "                target.append(torch.zeros(1))\n",
    "\n",
    "        for i in range(2*R,T):\n",
    "            if np.random.rand() > 0.5 and (not torch.equal(input[i-R],input[i-2*R])):\n",
    "                input.append(input[i-R])\n",
    "                target.append(torch.ones(1))\n",
    "            else:\n",
    "                input.append(torch.bernoulli(torch.empty(vec_len).uniform_(0, 1)))\n",
    "                target.append(torch.zeros(1))\n",
    "        \n",
    "                \n",
    "        batch_input.append(torch.stack(input, dim=0))\n",
    "        batch_target.append(torch.stack(target, dim=0))\n",
    "    \n",
    "    input_seq = torch.stack(batch_input, dim=0)\n",
    "    target_seq = torch.stack(batch_target, dim=0)\n",
    "    return(input_seq,target_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec3d3f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mix_seq(batch_size, vec_len, R, T):\n",
    "    mix_input_seq = []\n",
    "    mix_target_seq = []\n",
    "    for r in R:\n",
    "        input_seq,target_seq = generate_seq(int(batch_size/len(R)), vec_len, r, T) \n",
    "        mix_input_seq.append(input_seq)\n",
    "        mix_target_seq.append(target_seq)\n",
    "    \n",
    "    mix_input_seq = torch.cat(mix_input_seq, dim=0)\n",
    "    mix_target_seq = torch.cat(mix_target_seq, dim=0)\n",
    "    shuf = np.random.permutation(len(mix_input_seq))\n",
    "\n",
    "    return mix_input_seq[shuf],mix_target_seq[shuf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c1fb909",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HebbFF(nn.Module):\n",
    "    def __init__(self,input_dim,hid_dim,out_dim, batch_size):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        \n",
    "        self.w1 = torch.nn.Parameter(torch.randn(hid_dim,input_dim))\n",
    "        #nn.init.kaiming_uniform_(self.w1, mode='fan_in', nonlinearity='sigmoid')\n",
    "        nn.init.xavier_uniform_(self.w1, gain=1.0)\n",
    "        \n",
    "        self.b1 = torch.nn.Parameter(torch.randn(hid_dim,1))\n",
    "        #nn.init.kaiming_uniform_(self.b1, mode='fan_in', nonlinearity='sigmoid')\n",
    "        nn.init.xavier_uniform_(self.b1, gain=1.0)\n",
    "        \n",
    "        self.w2 = torch.nn.Parameter(torch.randn(out_dim,hid_dim))\n",
    "        #nn.init.kaiming_uniform_(self.w2, mode='fan_in', nonlinearity='sigmoid')\n",
    "        nn.init.xavier_uniform_(self.w2, gain=1.0)\n",
    "        \n",
    "        self.b2 = torch.nn.Parameter(torch.randn(out_dim,1))\n",
    "        #nn.init.kaiming_uniform_(self.b2, mode='fan_in', nonlinearity='sigmoid')\n",
    "        nn.init.xavier_uniform_(self.b2, gain=1.0)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # plastic matrix\n",
    "        self.A = torch.zeros(self.batch_size, hid_dim,input_dim)\n",
    "        self.lmbda = torch.nn.Parameter(torch.tensor(0.9))\n",
    "        self.eta = torch.nn.Parameter(torch.randn(1))\n",
    "\n",
    "    def forward(self, x_t):\n",
    "        x_t = torch.unsqueeze(x_t,-1)\n",
    "        #print('x_t',x_t.shape)\n",
    "        h_t = self.sigmoid((self.w1 + self.A) @ x_t  + self.b1)\n",
    "        #print('h_t',h_t.shape) \n",
    "        self.A = self.lmbda * self.A + self.eta * (h_t @ torch.transpose(x_t,1,2))\n",
    "        #print('A',self.A.shape) \n",
    "        y_t = self.sigmoid(self.w2 @ (h_t) + self.b2)\n",
    "        y_t = torch.squeeze(y_t,-1)\n",
    "        #print('y_t',y_t.shape) \n",
    "\n",
    "        return y_t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3094390b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,criterion,optimizer,input_seq,target_seq,T):\n",
    "    total_loss = 0\n",
    "    accuracy = 0\n",
    "    \n",
    "    for i in range(T):\n",
    "        x_t = input_seq[:,i,:]\n",
    "        target = target_seq[:,i,:]\n",
    "        \n",
    "        output = model(x_t)\n",
    "        \n",
    "        loss = criterion(output, target) \n",
    "        total_loss += loss\n",
    "        \n",
    "        predicted = (output>0.5).float()\n",
    "        accuracy  += (predicted == target).sum() \n",
    "    \n",
    "    total_loss = total_loss / (T)\n",
    "    #print('total_loss: ',total_loss)\n",
    "    optimizer.zero_grad() \n",
    "    total_loss.backward()\n",
    "    \n",
    "    #print('grad: ',model.w1.grad.sum())\n",
    "    optimizer.step()\n",
    "    model.A = torch.zeros(model.batch_size, model.hid_dim,model.input_dim)\n",
    "    return accuracy/(T * batch_size), total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2517141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,criterion,optimizer,input_seq,target_seq,T):\n",
    "    total_loss = 0\n",
    "    accuracy = 0\n",
    "    model.A = torch.zeros(model.batch_size, model.hid_dim,model.input_dim)\n",
    "    for i in range(T):\n",
    "        x_t = input_seq[:,i,:]\n",
    "        target = target_seq[:,i,:]\n",
    "        \n",
    "        output = model(x_t)\n",
    "        \n",
    "        loss = criterion(output, target) \n",
    "        total_loss += loss\n",
    "        \n",
    "        predicted = (output>0.5).float()\n",
    "        accuracy  += (predicted == target).sum() \n",
    "    \n",
    "    total_loss = total_loss / (T)\n",
    "    return accuracy/(T * batch_size), total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92ba1b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_len = 100\n",
    "R = 1\n",
    "T = 500\n",
    "batch_size = 64\n",
    "HebbFF_CFD = HebbFF(input_dim = vec_len, hid_dim=100, out_dim=1, batch_size = batch_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(HebbFF_CFD.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ede6d27d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 10/500.... Loss: 0.4462 | Accuracy: 0.3311\n",
      "Iterations: 20/500.... Loss: 0.4169 | Accuracy: 0.3354\n",
      "Iterations: 30/500.... Loss: 0.3774 | Accuracy: 0.3377\n",
      "Iterations: 40/500.... Loss: 0.3231 | Accuracy: 0.3391\n",
      "Iterations: 50/500.... Loss: 0.2535 | Accuracy: 0.4345\n",
      "Iterations: 60/500.... Loss: 0.1765 | Accuracy: 0.7183\n",
      "Iterations: 70/500.... Loss: 0.1174 | Accuracy: 0.8787\n",
      "Iterations: 80/500.... Loss: 0.0862 | Accuracy: 0.9499\n",
      "Iterations: 90/500.... Loss: 0.0707 | Accuracy: 0.9779\n",
      "Iterations: 100/500.... Loss: 0.0646 | Accuracy: 0.9852\n",
      "Iterations: 110/500.... Loss: 0.0619 | Accuracy: 0.9783\n",
      "Iterations: 120/500.... Loss: 0.0605 | Accuracy: 0.9705\n",
      "Iterations: 130/500.... Loss: 0.0604 | Accuracy: 0.9650\n",
      "Iterations: 140/500.... Loss: 0.0598 | Accuracy: 0.9619\n",
      "Iterations: 150/500.... Loss: 0.0593 | Accuracy: 0.9607\n",
      "Iterations: 160/500.... Loss: 0.0592 | Accuracy: 0.9611\n",
      "Iterations: 170/500.... Loss: 0.0584 | Accuracy: 0.9608\n",
      "Iterations: 180/500.... Loss: 0.0575 | Accuracy: 0.9634\n",
      "Iterations: 190/500.... Loss: 0.0574 | Accuracy: 0.9638\n",
      "Iterations: 200/500.... Loss: 0.0572 | Accuracy: 0.9648\n",
      "Iterations: 210/500.... Loss: 0.0568 | Accuracy: 0.9658\n",
      "Iterations: 220/500.... Loss: 0.0561 | Accuracy: 0.9663\n",
      "Iterations: 230/500.... Loss: 0.0558 | Accuracy: 0.9669\n",
      "Iterations: 240/500.... Loss: 0.0556 | Accuracy: 0.9677\n",
      "Iterations: 250/500.... Loss: 0.0545 | Accuracy: 0.9696\n",
      "Iterations: 260/500.... Loss: 0.0537 | Accuracy: 0.9714\n",
      "Iterations: 270/500.... Loss: 0.0536 | Accuracy: 0.9707\n",
      "Iterations: 280/500.... Loss: 0.0526 | Accuracy: 0.9728\n",
      "Iterations: 290/500.... Loss: 0.0527 | Accuracy: 0.9721\n",
      "Iterations: 300/500.... Loss: 0.0515 | Accuracy: 0.9755\n",
      "Iterations: 310/500.... Loss: 0.0505 | Accuracy: 0.9760\n",
      "Iterations: 320/500.... Loss: 0.0505 | Accuracy: 0.9751\n",
      "Iterations: 330/500.... Loss: 0.0491 | Accuracy: 0.9778\n",
      "Iterations: 340/500.... Loss: 0.0488 | Accuracy: 0.9765\n",
      "Iterations: 350/500.... Loss: 0.0478 | Accuracy: 0.9780\n",
      "Iterations: 360/500.... Loss: 0.0467 | Accuracy: 0.9789\n",
      "Iterations: 370/500.... Loss: 0.0463 | Accuracy: 0.9805\n",
      "Iterations: 380/500.... Loss: 0.0449 | Accuracy: 0.9807\n",
      "Iterations: 390/500.... Loss: 0.0441 | Accuracy: 0.9822\n",
      "Iterations: 400/500.... Loss: 0.0428 | Accuracy: 0.9839\n",
      "Iterations: 410/500.... Loss: 0.0421 | Accuracy: 0.9838\n",
      "Iterations: 420/500.... Loss: 0.0408 | Accuracy: 0.9869\n",
      "Iterations: 430/500.... Loss: 0.0400 | Accuracy: 0.9870\n",
      "Iterations: 440/500.... Loss: 0.0394 | Accuracy: 0.9870\n",
      "Iterations: 450/500.... Loss: 0.0378 | Accuracy: 0.9888\n",
      "Iterations: 460/500.... Loss: 0.0372 | Accuracy: 0.9882\n",
      "Iterations: 470/500.... Loss: 0.0360 | Accuracy: 0.9893\n",
      "Iterations: 480/500.... Loss: 0.0350 | Accuracy: 0.9897\n",
      "Iterations: 490/500.... Loss: 0.0345 | Accuracy: 0.9896\n",
      "Iterations: 500/500.... Loss: 0.0330 | Accuracy: 0.9904\n"
     ]
    }
   ],
   "source": [
    "n_iterations = 500\n",
    "for iterations in range(1, n_iterations+1):\n",
    "    input_seq,target_seq = generate_seq(batch_size = batch_size, vec_len = vec_len, R = R, T = T)\n",
    "    #print('eta', HebbFF_CFD.eta)\n",
    "    #print('lambda', HebbFF_CFD.lmbda)\n",
    "\n",
    "    accuracy,total_loss = train(HebbFF_CFD,criterion,optimizer,input_seq,target_seq,T)\n",
    "    \n",
    "    \n",
    "    if iterations % 10 == 0:\n",
    "        print('Iterations: {}/{}....'.format(iterations, n_iterations), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(total_loss.item()), end=' | ')\n",
    "        print(\"Accuracy: {:.4f}\".format(accuracy.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb9faf2",
   "metadata": {},
   "source": [
    "# Shift training R = 1 to R = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "993fbd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac89c49d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 10/500.... Loss: 0.1180 | Accuracy: 0.8594\n",
      "Iterations: 20/500.... Loss: 0.1147 | Accuracy: 0.8594\n",
      "Iterations: 30/500.... Loss: 0.1098 | Accuracy: 0.8691\n",
      "Iterations: 40/500.... Loss: 0.1058 | Accuracy: 0.8723\n",
      "Iterations: 50/500.... Loss: 0.1038 | Accuracy: 0.8758\n",
      "Iterations: 60/500.... Loss: 0.1008 | Accuracy: 0.8786\n",
      "Iterations: 70/500.... Loss: 0.0995 | Accuracy: 0.8791\n",
      "Iterations: 80/500.... Loss: 0.0976 | Accuracy: 0.8812\n",
      "Iterations: 90/500.... Loss: 0.0961 | Accuracy: 0.8823\n",
      "Iterations: 100/500.... Loss: 0.0941 | Accuracy: 0.8850\n",
      "Iterations: 110/500.... Loss: 0.0929 | Accuracy: 0.8873\n",
      "Iterations: 120/500.... Loss: 0.0921 | Accuracy: 0.8856\n",
      "Iterations: 130/500.... Loss: 0.0912 | Accuracy: 0.8859\n",
      "Iterations: 140/500.... Loss: 0.0897 | Accuracy: 0.8864\n",
      "Iterations: 150/500.... Loss: 0.0884 | Accuracy: 0.8878\n",
      "Iterations: 160/500.... Loss: 0.0885 | Accuracy: 0.8839\n",
      "Iterations: 170/500.... Loss: 0.0865 | Accuracy: 0.8880\n",
      "Iterations: 180/500.... Loss: 0.0854 | Accuracy: 0.8900\n",
      "Iterations: 190/500.... Loss: 0.0847 | Accuracy: 0.8881\n",
      "Iterations: 200/500.... Loss: 0.0835 | Accuracy: 0.8888\n",
      "Iterations: 210/500.... Loss: 0.0826 | Accuracy: 0.8904\n",
      "Iterations: 220/500.... Loss: 0.0807 | Accuracy: 0.8930\n",
      "Iterations: 230/500.... Loss: 0.0801 | Accuracy: 0.8944\n",
      "Iterations: 240/500.... Loss: 0.0796 | Accuracy: 0.8928\n",
      "Iterations: 250/500.... Loss: 0.0775 | Accuracy: 0.8967\n",
      "Iterations: 260/500.... Loss: 0.0761 | Accuracy: 0.8999\n",
      "Iterations: 270/500.... Loss: 0.0757 | Accuracy: 0.8992\n",
      "Iterations: 280/500.... Loss: 0.0749 | Accuracy: 0.9018\n",
      "Iterations: 290/500.... Loss: 0.0736 | Accuracy: 0.9059\n",
      "Iterations: 300/500.... Loss: 0.0726 | Accuracy: 0.9073\n",
      "Iterations: 310/500.... Loss: 0.0727 | Accuracy: 0.9093\n",
      "Iterations: 320/500.... Loss: 0.0704 | Accuracy: 0.9162\n",
      "Iterations: 330/500.... Loss: 0.0698 | Accuracy: 0.9193\n",
      "Iterations: 340/500.... Loss: 0.0689 | Accuracy: 0.9243\n",
      "Iterations: 350/500.... Loss: 0.0675 | Accuracy: 0.9273\n",
      "Iterations: 360/500.... Loss: 0.0662 | Accuracy: 0.9370\n",
      "Iterations: 370/500.... Loss: 0.0657 | Accuracy: 0.9382\n",
      "Iterations: 380/500.... Loss: 0.0645 | Accuracy: 0.9444\n",
      "Iterations: 390/500.... Loss: 0.0639 | Accuracy: 0.9480\n",
      "Iterations: 400/500.... Loss: 0.0624 | Accuracy: 0.9524\n",
      "Iterations: 410/500.... Loss: 0.0624 | Accuracy: 0.9563\n",
      "Iterations: 420/500.... Loss: 0.0610 | Accuracy: 0.9604\n",
      "Iterations: 430/500.... Loss: 0.0597 | Accuracy: 0.9653\n",
      "Iterations: 440/500.... Loss: 0.0587 | Accuracy: 0.9677\n",
      "Iterations: 450/500.... Loss: 0.0580 | Accuracy: 0.9722\n",
      "Iterations: 460/500.... Loss: 0.0567 | Accuracy: 0.9738\n",
      "Iterations: 470/500.... Loss: 0.0560 | Accuracy: 0.9769\n",
      "Iterations: 480/500.... Loss: 0.0552 | Accuracy: 0.9801\n",
      "Iterations: 490/500.... Loss: 0.0543 | Accuracy: 0.9808\n",
      "Iterations: 500/500.... Loss: 0.0536 | Accuracy: 0.9828\n"
     ]
    }
   ],
   "source": [
    "n_iterations = 500\n",
    "for iterations in range(1, n_iterations+1):\n",
    "    input_seq,target_seq = generate_seq(batch_size = batch_size, vec_len = vec_len, R = R, T = T)\n",
    "    #print('eta', HebbFF_CFD.eta)\n",
    "    #print('lambda', HebbFF_CFD.lmbda)\n",
    "    accuracy,total_loss = train(HebbFF_CFD,criterion,optimizer,input_seq,target_seq,T)\n",
    "    if iterations % 10 == 0:\n",
    "        print('Iterations: {}/{}....'.format(iterations, n_iterations), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(total_loss.item()), end=' | ')\n",
    "        print(\"Accuracy: {:.4f}\".format(accuracy.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e717230",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "R = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04790f47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 10/500.... Loss: 0.0817 | Accuracy: 0.9367\n",
      "Iterations: 20/500.... Loss: 0.0800 | Accuracy: 0.9244\n",
      "Iterations: 30/500.... Loss: 0.0787 | Accuracy: 0.9331\n",
      "Iterations: 40/500.... Loss: 0.0772 | Accuracy: 0.9358\n",
      "Iterations: 50/500.... Loss: 0.0758 | Accuracy: 0.9388\n",
      "Iterations: 60/500.... Loss: 0.0753 | Accuracy: 0.9402\n",
      "Iterations: 70/500.... Loss: 0.0739 | Accuracy: 0.9435\n",
      "Iterations: 80/500.... Loss: 0.0732 | Accuracy: 0.9454\n",
      "Iterations: 90/500.... Loss: 0.0716 | Accuracy: 0.9471\n",
      "Iterations: 100/500.... Loss: 0.0712 | Accuracy: 0.9486\n",
      "Iterations: 110/500.... Loss: 0.0702 | Accuracy: 0.9507\n",
      "Iterations: 120/500.... Loss: 0.0697 | Accuracy: 0.9500\n",
      "Iterations: 130/500.... Loss: 0.0686 | Accuracy: 0.9526\n",
      "Iterations: 140/500.... Loss: 0.0686 | Accuracy: 0.9529\n",
      "Iterations: 150/500.... Loss: 0.0674 | Accuracy: 0.9546\n",
      "Iterations: 160/500.... Loss: 0.0666 | Accuracy: 0.9566\n",
      "Iterations: 170/500.... Loss: 0.0662 | Accuracy: 0.9579\n",
      "Iterations: 180/500.... Loss: 0.0643 | Accuracy: 0.9630\n",
      "Iterations: 190/500.... Loss: 0.0643 | Accuracy: 0.9623\n",
      "Iterations: 200/500.... Loss: 0.0635 | Accuracy: 0.9626\n",
      "Iterations: 210/500.... Loss: 0.0627 | Accuracy: 0.9650\n",
      "Iterations: 220/500.... Loss: 0.0617 | Accuracy: 0.9650\n",
      "Iterations: 230/500.... Loss: 0.0618 | Accuracy: 0.9653\n",
      "Iterations: 240/500.... Loss: 0.0599 | Accuracy: 0.9691\n",
      "Iterations: 250/500.... Loss: 0.0598 | Accuracy: 0.9699\n",
      "Iterations: 260/500.... Loss: 0.0583 | Accuracy: 0.9728\n",
      "Iterations: 270/500.... Loss: 0.0583 | Accuracy: 0.9713\n",
      "Iterations: 280/500.... Loss: 0.0581 | Accuracy: 0.9727\n",
      "Iterations: 290/500.... Loss: 0.0566 | Accuracy: 0.9753\n",
      "Iterations: 300/500.... Loss: 0.0560 | Accuracy: 0.9758\n",
      "Iterations: 310/500.... Loss: 0.0550 | Accuracy: 0.9772\n",
      "Iterations: 320/500.... Loss: 0.0549 | Accuracy: 0.9772\n",
      "Iterations: 330/500.... Loss: 0.0538 | Accuracy: 0.9783\n",
      "Iterations: 340/500.... Loss: 0.0535 | Accuracy: 0.9790\n",
      "Iterations: 350/500.... Loss: 0.0527 | Accuracy: 0.9803\n",
      "Iterations: 360/500.... Loss: 0.0522 | Accuracy: 0.9807\n",
      "Iterations: 370/500.... Loss: 0.0514 | Accuracy: 0.9808\n",
      "Iterations: 380/500.... Loss: 0.0507 | Accuracy: 0.9815\n",
      "Iterations: 390/500.... Loss: 0.0509 | Accuracy: 0.9817\n",
      "Iterations: 400/500.... Loss: 0.0497 | Accuracy: 0.9839\n",
      "Iterations: 410/500.... Loss: 0.0489 | Accuracy: 0.9849\n",
      "Iterations: 420/500.... Loss: 0.0486 | Accuracy: 0.9844\n",
      "Iterations: 430/500.... Loss: 0.0473 | Accuracy: 0.9859\n",
      "Iterations: 440/500.... Loss: 0.0472 | Accuracy: 0.9859\n",
      "Iterations: 450/500.... Loss: 0.0464 | Accuracy: 0.9868\n",
      "Iterations: 460/500.... Loss: 0.0462 | Accuracy: 0.9862\n",
      "Iterations: 470/500.... Loss: 0.0454 | Accuracy: 0.9881\n",
      "Iterations: 480/500.... Loss: 0.0447 | Accuracy: 0.9872\n",
      "Iterations: 490/500.... Loss: 0.0441 | Accuracy: 0.9886\n",
      "Iterations: 500/500.... Loss: 0.0441 | Accuracy: 0.9891\n"
     ]
    }
   ],
   "source": [
    "n_iterations = 500\n",
    "for iterations in range(1, n_iterations+1):\n",
    "    input_seq,target_seq = generate_seq(batch_size = batch_size, vec_len = vec_len, R = R, T = T)\n",
    "    #print('eta', HebbFF_CFD.eta)\n",
    "    #print('lambda', HebbFF_CFD.lmbda)\n",
    "    accuracy,total_loss = train(HebbFF_CFD,criterion,optimizer,input_seq,target_seq,T)\n",
    "    if iterations % 10 == 0:\n",
    "        print('Iterations: {}/{}....'.format(iterations, n_iterations), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(total_loss.item()), end=' | ')\n",
    "        print(\"Accuracy: {:.4f}\".format(accuracy.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45ca2d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R =  1 ... accuracy:  0.9949|loss:  0.0179\n",
      "R =  2 ... accuracy:  0.9948|loss:  0.0274\n",
      "R =  3 ... accuracy:  0.9891|loss:  0.0440\n",
      "R =  4 ... accuracy:  0.9579|loss:  0.0643\n",
      "R =  5 ... accuracy:  0.9129|loss:  0.0835\n",
      "R =  6 ... accuracy:  0.8692|loss:  0.0999\n",
      "R =  7 ... accuracy:  0.8384|loss:  0.1121\n",
      "R =  8 ... accuracy:  0.8083|loss:  0.1235\n",
      "R =  9 ... accuracy:  0.7902|loss:  0.1320\n",
      "R =  10 ... accuracy:  0.7706|loss:  0.1408\n"
     ]
    }
   ],
   "source": [
    "ACC_R = []\n",
    "for i in range(1, 11):\n",
    "    input_seq,target_seq = generate_seq(batch_size = batch_size, vec_len = vec_len, R = i, T = T)\n",
    "    accuracy,total_loss = test(HebbFF_CFD,criterion,optimizer,input_seq,target_seq,T)\n",
    "    print('R = ',i,'...','accuracy: ',format(accuracy.item() , '.4f'), end = '|')\n",
    "    print('loss: ',format(total_loss.item() , '.4f'))\n",
    "    ACC_R.append(accuracy.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e73329c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy across different intervals after training with R = [1,2,3]')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "r_axis = np.arange(1,11)\n",
    "plt.plot(r_axis,ACC_R)\n",
    "plt.title(\"Accuracy across different intervals after training with R = [1,2,3]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4994dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ddad29e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 10/500.... Loss: 0.1048 | Accuracy: 0.9135\n",
      "Iterations: 20/500.... Loss: 0.1000 | Accuracy: 0.8977\n",
      "Iterations: 30/500.... Loss: 0.0987 | Accuracy: 0.9039\n",
      "Iterations: 40/500.... Loss: 0.0964 | Accuracy: 0.9130\n",
      "Iterations: 50/500.... Loss: 0.0969 | Accuracy: 0.9055\n",
      "Iterations: 60/500.... Loss: 0.0955 | Accuracy: 0.9095\n",
      "Iterations: 70/500.... Loss: 0.0951 | Accuracy: 0.9111\n",
      "Iterations: 80/500.... Loss: 0.0936 | Accuracy: 0.9122\n",
      "Iterations: 90/500.... Loss: 0.0941 | Accuracy: 0.9104\n",
      "Iterations: 100/500.... Loss: 0.0930 | Accuracy: 0.9141\n",
      "Iterations: 110/500.... Loss: 0.0923 | Accuracy: 0.9149\n",
      "Iterations: 120/500.... Loss: 0.0923 | Accuracy: 0.9137\n",
      "Iterations: 130/500.... Loss: 0.0908 | Accuracy: 0.9159\n",
      "Iterations: 140/500.... Loss: 0.0905 | Accuracy: 0.9160\n",
      "Iterations: 150/500.... Loss: 0.0910 | Accuracy: 0.9153\n",
      "Iterations: 160/500.... Loss: 0.0899 | Accuracy: 0.9177\n",
      "Iterations: 170/500.... Loss: 0.0889 | Accuracy: 0.9162\n",
      "Iterations: 180/500.... Loss: 0.0886 | Accuracy: 0.9192\n",
      "Iterations: 190/500.... Loss: 0.0875 | Accuracy: 0.9224\n",
      "Iterations: 200/500.... Loss: 0.0875 | Accuracy: 0.9211\n",
      "Iterations: 210/500.... Loss: 0.0873 | Accuracy: 0.9202\n",
      "Iterations: 220/500.... Loss: 0.0864 | Accuracy: 0.9236\n",
      "Iterations: 230/500.... Loss: 0.0860 | Accuracy: 0.9245\n",
      "Iterations: 240/500.... Loss: 0.0841 | Accuracy: 0.9292\n",
      "Iterations: 250/500.... Loss: 0.0854 | Accuracy: 0.9264\n",
      "Iterations: 260/500.... Loss: 0.0846 | Accuracy: 0.9277\n",
      "Iterations: 270/500.... Loss: 0.0838 | Accuracy: 0.9265\n",
      "Iterations: 280/500.... Loss: 0.0846 | Accuracy: 0.9281\n",
      "Iterations: 290/500.... Loss: 0.0829 | Accuracy: 0.9293\n",
      "Iterations: 300/500.... Loss: 0.0826 | Accuracy: 0.9306\n",
      "Iterations: 310/500.... Loss: 0.0826 | Accuracy: 0.9289\n",
      "Iterations: 320/500.... Loss: 0.0818 | Accuracy: 0.9307\n",
      "Iterations: 330/500.... Loss: 0.0814 | Accuracy: 0.9308\n",
      "Iterations: 340/500.... Loss: 0.0805 | Accuracy: 0.9328\n",
      "Iterations: 350/500.... Loss: 0.0804 | Accuracy: 0.9318\n",
      "Iterations: 360/500.... Loss: 0.0798 | Accuracy: 0.9355\n",
      "Iterations: 370/500.... Loss: 0.0778 | Accuracy: 0.9405\n",
      "Iterations: 380/500.... Loss: 0.0792 | Accuracy: 0.9336\n",
      "Iterations: 390/500.... Loss: 0.0794 | Accuracy: 0.9330\n",
      "Iterations: 400/500.... Loss: 0.0789 | Accuracy: 0.9357\n",
      "Iterations: 410/500.... Loss: 0.0773 | Accuracy: 0.9385\n",
      "Iterations: 420/500.... Loss: 0.0782 | Accuracy: 0.9362\n",
      "Iterations: 430/500.... Loss: 0.0766 | Accuracy: 0.9379\n",
      "Iterations: 440/500.... Loss: 0.0778 | Accuracy: 0.9346\n",
      "Iterations: 450/500.... Loss: 0.0755 | Accuracy: 0.9400\n",
      "Iterations: 460/500.... Loss: 0.0754 | Accuracy: 0.9427\n",
      "Iterations: 470/500.... Loss: 0.0757 | Accuracy: 0.9400\n",
      "Iterations: 480/500.... Loss: 0.0750 | Accuracy: 0.9414\n",
      "Iterations: 490/500.... Loss: 0.0742 | Accuracy: 0.9421\n",
      "Iterations: 500/500.... Loss: 0.0743 | Accuracy: 0.9426\n"
     ]
    }
   ],
   "source": [
    "n_iterations = 500\n",
    "for iterations in range(1, n_iterations+1):\n",
    "    input_seq,target_seq = generate_seq(batch_size = batch_size, vec_len = vec_len, R = R, T = T)\n",
    "    #print('eta', HebbFF_CFD.eta)\n",
    "    #print('lambda', HebbFF_CFD.lmbda)\n",
    "    accuracy,total_loss = train(HebbFF_CFD,criterion,optimizer,input_seq,target_seq,T)\n",
    "    if iterations % 10 == 0:\n",
    "        print('Iterations: {}/{}....'.format(iterations, n_iterations), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(total_loss.item()), end=' | ')\n",
    "        print(\"Accuracy: {:.4f}\".format(accuracy.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "487772af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 510/1000.... Loss: 0.0735 | Accuracy: 0.9444\n",
      "Iterations: 520/1000.... Loss: 0.0735 | Accuracy: 0.9432\n",
      "Iterations: 530/1000.... Loss: 0.0733 | Accuracy: 0.9441\n",
      "Iterations: 540/1000.... Loss: 0.0733 | Accuracy: 0.9417\n",
      "Iterations: 550/1000.... Loss: 0.0722 | Accuracy: 0.9461\n",
      "Iterations: 560/1000.... Loss: 0.0723 | Accuracy: 0.9442\n",
      "Iterations: 570/1000.... Loss: 0.0717 | Accuracy: 0.9455\n",
      "Iterations: 580/1000.... Loss: 0.0712 | Accuracy: 0.9469\n",
      "Iterations: 590/1000.... Loss: 0.0702 | Accuracy: 0.9474\n",
      "Iterations: 600/1000.... Loss: 0.0705 | Accuracy: 0.9473\n",
      "Iterations: 610/1000.... Loss: 0.0704 | Accuracy: 0.9465\n",
      "Iterations: 620/1000.... Loss: 0.0695 | Accuracy: 0.9491\n",
      "Iterations: 630/1000.... Loss: 0.0691 | Accuracy: 0.9480\n",
      "Iterations: 640/1000.... Loss: 0.0686 | Accuracy: 0.9498\n",
      "Iterations: 650/1000.... Loss: 0.0689 | Accuracy: 0.9490\n",
      "Iterations: 660/1000.... Loss: 0.0690 | Accuracy: 0.9496\n",
      "Iterations: 670/1000.... Loss: 0.0668 | Accuracy: 0.9538\n",
      "Iterations: 680/1000.... Loss: 0.0678 | Accuracy: 0.9496\n",
      "Iterations: 690/1000.... Loss: 0.0673 | Accuracy: 0.9517\n",
      "Iterations: 700/1000.... Loss: 0.0667 | Accuracy: 0.9518\n",
      "Iterations: 710/1000.... Loss: 0.0670 | Accuracy: 0.9518\n",
      "Iterations: 720/1000.... Loss: 0.0665 | Accuracy: 0.9529\n",
      "Iterations: 730/1000.... Loss: 0.0660 | Accuracy: 0.9540\n",
      "Iterations: 740/1000.... Loss: 0.0658 | Accuracy: 0.9519\n",
      "Iterations: 750/1000.... Loss: 0.0662 | Accuracy: 0.9508\n",
      "Iterations: 760/1000.... Loss: 0.0641 | Accuracy: 0.9554\n",
      "Iterations: 770/1000.... Loss: 0.0647 | Accuracy: 0.9540\n",
      "Iterations: 780/1000.... Loss: 0.0650 | Accuracy: 0.9523\n",
      "Iterations: 790/1000.... Loss: 0.0644 | Accuracy: 0.9548\n",
      "Iterations: 800/1000.... Loss: 0.0642 | Accuracy: 0.9544\n",
      "Iterations: 810/1000.... Loss: 0.0629 | Accuracy: 0.9564\n",
      "Iterations: 820/1000.... Loss: 0.0628 | Accuracy: 0.9552\n",
      "Iterations: 830/1000.... Loss: 0.0630 | Accuracy: 0.9551\n",
      "Iterations: 840/1000.... Loss: 0.0627 | Accuracy: 0.9562\n",
      "Iterations: 850/1000.... Loss: 0.0621 | Accuracy: 0.9581\n",
      "Iterations: 860/1000.... Loss: 0.0626 | Accuracy: 0.9544\n",
      "Iterations: 870/1000.... Loss: 0.0618 | Accuracy: 0.9560\n",
      "Iterations: 880/1000.... Loss: 0.0628 | Accuracy: 0.9545\n",
      "Iterations: 890/1000.... Loss: 0.0615 | Accuracy: 0.9577\n",
      "Iterations: 900/1000.... Loss: 0.0612 | Accuracy: 0.9563\n",
      "Iterations: 910/1000.... Loss: 0.0610 | Accuracy: 0.9576\n",
      "Iterations: 920/1000.... Loss: 0.0608 | Accuracy: 0.9572\n",
      "Iterations: 930/1000.... Loss: 0.0590 | Accuracy: 0.9600\n",
      "Iterations: 940/1000.... Loss: 0.0593 | Accuracy: 0.9603\n",
      "Iterations: 950/1000.... Loss: 0.0583 | Accuracy: 0.9618\n",
      "Iterations: 960/1000.... Loss: 0.0592 | Accuracy: 0.9602\n",
      "Iterations: 970/1000.... Loss: 0.0590 | Accuracy: 0.9579\n",
      "Iterations: 980/1000.... Loss: 0.0584 | Accuracy: 0.9605\n",
      "Iterations: 990/1000.... Loss: 0.0586 | Accuracy: 0.9601\n",
      "Iterations: 1000/1000.... Loss: 0.0582 | Accuracy: 0.9609\n"
     ]
    }
   ],
   "source": [
    "n_iterations = 1000\n",
    "for iterations in range(501, n_iterations+1):\n",
    "    input_seq,target_seq = generate_seq(batch_size = batch_size, vec_len = vec_len, R = R, T = T)\n",
    "    #print('eta', HebbFF_CFD.eta)\n",
    "    #print('lambda', HebbFF_CFD.lmbda)\n",
    "    accuracy,total_loss = train(HebbFF_CFD,criterion,optimizer,input_seq,target_seq,T)\n",
    "    if iterations % 10 == 0:\n",
    "        print('Iterations: {}/{}....'.format(iterations, n_iterations), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(total_loss.item()), end=' | ')\n",
    "        print(\"Accuracy: {:.4f}\".format(accuracy.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "055a388f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 1010/1500.... Loss: 0.0572 | Accuracy: 0.9619\n",
      "Iterations: 1020/1500.... Loss: 0.0573 | Accuracy: 0.9611\n",
      "Iterations: 1030/1500.... Loss: 0.0576 | Accuracy: 0.9613\n",
      "Iterations: 1040/1500.... Loss: 0.0572 | Accuracy: 0.9607\n",
      "Iterations: 1050/1500.... Loss: 0.0571 | Accuracy: 0.9612\n",
      "Iterations: 1060/1500.... Loss: 0.0567 | Accuracy: 0.9622\n",
      "Iterations: 1070/1500.... Loss: 0.0565 | Accuracy: 0.9616\n",
      "Iterations: 1080/1500.... Loss: 0.0556 | Accuracy: 0.9635\n",
      "Iterations: 1090/1500.... Loss: 0.0561 | Accuracy: 0.9612\n",
      "Iterations: 1100/1500.... Loss: 0.0553 | Accuracy: 0.9625\n",
      "Iterations: 1110/1500.... Loss: 0.0559 | Accuracy: 0.9608\n",
      "Iterations: 1120/1500.... Loss: 0.0558 | Accuracy: 0.9618\n",
      "Iterations: 1130/1500.... Loss: 0.0552 | Accuracy: 0.9627\n",
      "Iterations: 1140/1500.... Loss: 0.0548 | Accuracy: 0.9634\n",
      "Iterations: 1150/1500.... Loss: 0.0541 | Accuracy: 0.9643\n",
      "Iterations: 1160/1500.... Loss: 0.0548 | Accuracy: 0.9629\n",
      "Iterations: 1170/1500.... Loss: 0.0546 | Accuracy: 0.9625\n",
      "Iterations: 1180/1500.... Loss: 0.0538 | Accuracy: 0.9646\n",
      "Iterations: 1190/1500.... Loss: 0.0542 | Accuracy: 0.9634\n",
      "Iterations: 1200/1500.... Loss: 0.0535 | Accuracy: 0.9645\n",
      "Iterations: 1210/1500.... Loss: 0.0527 | Accuracy: 0.9638\n",
      "Iterations: 1220/1500.... Loss: 0.0534 | Accuracy: 0.9628\n",
      "Iterations: 1230/1500.... Loss: 0.0526 | Accuracy: 0.9632\n",
      "Iterations: 1240/1500.... Loss: 0.0529 | Accuracy: 0.9656\n",
      "Iterations: 1250/1500.... Loss: 0.0518 | Accuracy: 0.9654\n",
      "Iterations: 1260/1500.... Loss: 0.0527 | Accuracy: 0.9635\n",
      "Iterations: 1270/1500.... Loss: 0.0522 | Accuracy: 0.9649\n",
      "Iterations: 1280/1500.... Loss: 0.0514 | Accuracy: 0.9663\n",
      "Iterations: 1290/1500.... Loss: 0.0516 | Accuracy: 0.9647\n",
      "Iterations: 1300/1500.... Loss: 0.0513 | Accuracy: 0.9650\n",
      "Iterations: 1310/1500.... Loss: 0.0513 | Accuracy: 0.9648\n",
      "Iterations: 1320/1500.... Loss: 0.0516 | Accuracy: 0.9646\n",
      "Iterations: 1330/1500.... Loss: 0.0507 | Accuracy: 0.9658\n",
      "Iterations: 1340/1500.... Loss: 0.0505 | Accuracy: 0.9654\n",
      "Iterations: 1350/1500.... Loss: 0.0504 | Accuracy: 0.9654\n",
      "Iterations: 1360/1500.... Loss: 0.0500 | Accuracy: 0.9676\n",
      "Iterations: 1370/1500.... Loss: 0.0505 | Accuracy: 0.9657\n",
      "Iterations: 1380/1500.... Loss: 0.0498 | Accuracy: 0.9665\n",
      "Iterations: 1390/1500.... Loss: 0.0498 | Accuracy: 0.9662\n",
      "Iterations: 1400/1500.... Loss: 0.0484 | Accuracy: 0.9682\n",
      "Iterations: 1410/1500.... Loss: 0.0486 | Accuracy: 0.9675\n",
      "Iterations: 1420/1500.... Loss: 0.0491 | Accuracy: 0.9681\n",
      "Iterations: 1430/1500.... Loss: 0.0487 | Accuracy: 0.9667\n",
      "Iterations: 1440/1500.... Loss: 0.0481 | Accuracy: 0.9691\n",
      "Iterations: 1450/1500.... Loss: 0.0482 | Accuracy: 0.9676\n",
      "Iterations: 1460/1500.... Loss: 0.0484 | Accuracy: 0.9669\n",
      "Iterations: 1470/1500.... Loss: 0.0480 | Accuracy: 0.9688\n",
      "Iterations: 1480/1500.... Loss: 0.0476 | Accuracy: 0.9678\n",
      "Iterations: 1490/1500.... Loss: 0.0485 | Accuracy: 0.9675\n",
      "Iterations: 1500/1500.... Loss: 0.0475 | Accuracy: 0.9667\n"
     ]
    }
   ],
   "source": [
    "n_iterations = 1500\n",
    "for iterations in range(1001, n_iterations+1):\n",
    "    input_seq,target_seq = generate_seq(batch_size = batch_size, vec_len = vec_len, R = R, T = T)\n",
    "    #print('eta', HebbFF_CFD.eta)\n",
    "    #print('lambda', HebbFF_CFD.lmbda)\n",
    "    accuracy,total_loss = train(HebbFF_CFD,criterion,optimizer,input_seq,target_seq,T)\n",
    "    if iterations % 10 == 0:\n",
    "        print('Iterations: {}/{}....'.format(iterations, n_iterations), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(total_loss.item()), end=' | ')\n",
    "        print(\"Accuracy: {:.4f}\".format(accuracy.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b507caba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R =  1 ... accuracy:  0.9859|loss:  0.0178\n",
      "R =  2 ... accuracy:  0.9852|loss:  0.0196\n",
      "R =  3 ... accuracy:  0.9845|loss:  0.0229\n",
      "R =  4 ... accuracy:  0.9818|loss:  0.0274\n",
      "R =  5 ... accuracy:  0.9806|loss:  0.0326\n",
      "R =  6 ... accuracy:  0.9749|loss:  0.0400\n",
      "R =  7 ... accuracy:  0.9695|loss:  0.0469\n",
      "R =  8 ... accuracy:  0.9562|loss:  0.0560\n",
      "R =  9 ... accuracy:  0.9367|loss:  0.0663\n",
      "R =  10 ... accuracy:  0.9128|loss:  0.0761\n",
      "R =  11 ... accuracy:  0.8968|loss:  0.0844\n",
      "R =  12 ... accuracy:  0.8827|loss:  0.0910\n",
      "R =  13 ... accuracy:  0.8709|loss:  0.0967\n",
      "R =  14 ... accuracy:  0.8580|loss:  0.1025\n",
      "R =  15 ... accuracy:  0.8470|loss:  0.1082\n",
      "R =  16 ... accuracy:  0.8405|loss:  0.1116\n",
      "R =  17 ... accuracy:  0.8272|loss:  0.1170\n",
      "R =  18 ... accuracy:  0.8236|loss:  0.1196\n",
      "R =  19 ... accuracy:  0.8148|loss:  0.1243\n",
      "R =  20 ... accuracy:  0.8087|loss:  0.1266\n",
      "R =  21 ... accuracy:  0.8038|loss:  0.1305\n",
      "R =  22 ... accuracy:  0.7935|loss:  0.1358\n",
      "R =  23 ... accuracy:  0.7910|loss:  0.1377\n",
      "R =  24 ... accuracy:  0.7831|loss:  0.1417\n",
      "R =  25 ... accuracy:  0.7749|loss:  0.1466\n",
      "R =  26 ... accuracy:  0.7720|loss:  0.1481\n",
      "R =  27 ... accuracy:  0.7673|loss:  0.1516\n",
      "R =  28 ... accuracy:  0.7669|loss:  0.1532\n",
      "R =  29 ... accuracy:  0.7616|loss:  0.1555\n",
      "R =  30 ... accuracy:  0.7570|loss:  0.1579\n",
      "R =  31 ... accuracy:  0.7507|loss:  0.1619\n",
      "R =  32 ... accuracy:  0.7450|loss:  0.1643\n",
      "R =  33 ... accuracy:  0.7406|loss:  0.1693\n",
      "R =  34 ... accuracy:  0.7435|loss:  0.1676\n",
      "R =  35 ... accuracy:  0.7388|loss:  0.1715\n",
      "R =  36 ... accuracy:  0.7338|loss:  0.1734\n",
      "R =  37 ... accuracy:  0.7317|loss:  0.1763\n",
      "R =  38 ... accuracy:  0.7282|loss:  0.1775\n",
      "R =  39 ... accuracy:  0.7242|loss:  0.1809\n",
      "R =  40 ... accuracy:  0.7233|loss:  0.1817\n"
     ]
    }
   ],
   "source": [
    "ACC_R = []\n",
    "for i in range(1, 41):\n",
    "    input_seq,target_seq = generate_seq(batch_size = batch_size, vec_len = vec_len, R = i, T = T)\n",
    "    accuracy,total_loss = test(HebbFF_CFD,criterion,optimizer,input_seq,target_seq,T)\n",
    "    print('R = ',i,'...','accuracy: ',format(accuracy.item() , '.4f'), end = '|')\n",
    "    print('loss: ',format(total_loss.item() , '.4f'))\n",
    "    ACC_R.append(accuracy.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1cb67b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy across different intervals after training with R in [1,41]')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEICAYAAACXo2mmAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAwgElEQVR4nO3dd5wddfX/8dfZmt1k0zdt0yuphLAJhBICCIQIgiAKQoQIhiggKirYUL/y+4r4RQVBaVKkB+lFipQQAiG9kl5I2ZRNb5tsO78/ZoKXZXdzs7mbubv7fj4e+7h7p547c++8Zz4zd665OyIiIomQEnUBIiJSfyhUREQkYRQqIiKSMAoVERFJGIWKiIgkjEJFREQSRqFSz5jZFWb2Qczz3WbWPfw/y8xeNrMdZvZM2O0WM9tsZhuiqrkqZnapmb0ZdR3xMLOHzeyWBE/TzOwhM9tmZlMTOe1EMrOTzWxxooetLWa2wMxGVtP/PTO7qpbm3Tn8TKbWYNwrzKwsHL9vbdR3kPm/Y2b7YrcvlalRqIQLfZuZZdasPDlS3L2Ju68In34NaAu0cveLzKwTcAPQz93bHenazMzNrGdV/d39cXc/M85pXXGwN3sddBJwBtDR3YeZ2W/M7LFEziAR03T3Se7eJ9HD1hZ37+/u78Hhv34zG2lm5eGGfpeZLTazsdXMe3X4mSyr4Sw/CsdfGM5/gJm9Ee4Yxv2lQzO7PPz8XRXTrdppuftpwPiDTfuQQ8XMugInAw585VDHPxxmlnYk53e4krDeLsASdy+Neb7F3Tcd6oTCveh6c6SbhOsKgvWzyt33JGJiNXmN9W0915ICd28CNAV+CNxvZkcqOEuACcCV8Y5gZi2AnwELDndalXL3Q/oDbgYmA38CXqnQrxPwHFAIbAHuiun3HWAhsAv4BBgSdnegZ8xwDwO3hP+PBNYCNwIbgEeBFsAr4Ty2hf93jBm/JfAQUBD2fyHsPh84N2a4dGAzMLiS11jTeVRWbybwl3DYgvD/zHD41uG0twNbgUlAStjvRmBduLwWA6dXsT5aAS8BO4GpwO+AD2L6O9AT+C1QTPDG2Q1cDRQB5eHzh8Phjwc+DGuaA4yMmdZ7wP8L139RON2jgLfC+hcDX6+wLu8GXg1fx8dAj7Df+2Fte8L5f6OS13ZFJa9lPLA0XO53Awb0BfYBZeG0tofDZwL/B6wGNgL3AFnVrKuFwDkx80sjeI8ceK8+Ew67I6y/fxXv2yrXayWv8Q5gTbj+ZgAnh92vrPCaPq6w/uaEwzUD/gGsJ3i/3AKkxiy/ycCfwzpuqTDvUVVMs7L1PJb/fn5XAFfHTGcksDbm+Srgx8DccFk9DTQ61GHD/j8NX1sBcBUVthcxw50KzIt5/h9gaszzD4DzY+b5pYO8/t+Fr38X8CbQuor197nXE3bbBFxUxfBdw9eQVoN5XUHM56FCv56Ax7kNvwf4Xjjvqw5lWtXV8Nkw8RRRYaLLwoKODVdG27B7KsFG6M9AY6ARcFLY7yKCN/xQgo1AT6BL7Eavig/nSKAU+APBBiKLYCN6IZAN5BB80F+IGf/V8I3ZgiA4Tol5cz4dM9x5sW/CCq+xpvOorN7/AaYAbYBcgg3278Lhfx+u4PTw7+Rw+fQh2NB0iHkj9qii1qcI9i4aAwPC5fyFUAn//w3wWDUbgzyCnYHRBEexZ4TPc2M+AKuB/gQb3GZhnWPD50MINsL9Y9blVmBY2P9x4KnKaovnDRwO/wrQHOhMEPqjqnqzEwT4SwQ7ATnAy8Dvq1lXNwOPx4z/ZWBRzPNvh9M5sKMwu4r3baXrtYrXeBnB+y2NoClyA//dAFd8/Z9bf2G3F4B7w/XfhmDH4uqY8UuB68LpZ1Uy/8qmWXE9p4fLogfB+/MUYC//DduRfDEopgIdwmW/EBhfg2FHhcujP8Fn8VGqDpVGBAHYOqx5A0EQ5YTrtoig2ffAPL90kNe/HOgdjvsecGsV6++z10PwmfkKwY7aMVUM35Uvhkq88/rc+6FCv7hCheCzOD2s9T1qIVQO6bDWzE4iOCSf4O4zwoXxzbD3MII3xk/cfY+773P3A23cVwG3ufs0Dyxz90/jnG058Gt33+/uRe6+xd2fdfe97r6LYI/qlLC+9sDZBG/Kbe5e4u4Tw+k8Bow2s6bh8zEEb9IvOIx5fKFe4FLgf9x9k7sXEhwxjAmHLQHaEwRsiQftzU6wd5oJ9DOzdHdf5e7LK9YZnuy7ELg5XObzgUfiXK6VuQx4zd1fc/dyd3+L4A04OmaYh919gQdNaKMImmcecvdSd58JPEtw7uaA59x9ajj848Dgw6gPgg/cdndfDbxb1fTMzAiOjn/o7lvD9fi/wMUxg1VcV08AXzGz7LD/N8NuALj7g+6+y933E2yMjjazZpXMvqr1+gXu/lj4fit199sJ1ntcTSdm1pbgvfiDcP1vItipi32NBe7+13D6RfFMN/TZeg5fw6vuvjz8/E4k2KM+uZrx73T3AnffShDmg2sw7NeBh8I69hJ8dirl7vsI3qsjgHyCI58PgBMJjr6XuvuWOF73AQ+5+5JwmU04SP0dzGw7QXA9D/zI3WfV0rxqLNxe/A24zt3La2MecOjnVC4H3nT3zeHzJ8JuEDR9fer/ba+P1YkggGqiMHzDAGBm2WZ2r5l9amY7CZohmocLrBOw1d23VZyIuxcQHGJeaGbNCT6Mj1c2w5rOo7J6CYI2NkA/DbsB/JHgyO9NM1thZjeFtS4DfkCw4dpkZk+ZWQe+KJdgr2xNhenXVBfgIjPbfuCP4GRx+5hh1lQY/rgKw18KxJ70j72qbC/Q5DDqO5Tp5RLs3c6Iqe31sPsBn1tX4XJfCJwbBstXCEPFzFLN7FYzWx6+J1aFo7WuZN6VrtfKmNkNZrbQgivythMc/VU2zcp0ITiKWB/zGu8lOGI5YE1lI8bhc+OZ2dlmNsXMtobzGX2QOg9lvVc1bIcKdRzstUwkOHIYEf7/HsHO4Cnh80NxKPUXuHtzgnMqdwKn1eK8Dsf3gLnu/lEtTR8INkhxMbMsgj2HVPvv5aeZBBvbowlWeGczS6skWNYQHDpXZi/Bh/+AdgRt3QdU3MO7gWBP7jh332Bmg4FZBIfla4CWZtbc3bdXMq9HCI6a0giuolhXRU2HM4+K9RYQfPgPnBTrHHYj3Hu+AbjBzPoD75rZNHd/292fAJ4Ij6zuJWimGVNh2oUEzRudgEUx06+pNcCj7v6daoaJfX1rgInufsZhzDNRKi73zQR7jv2rWc+VHT08CVxCsMP1SRg0EBy1nEfQFr+KYOO/jeA98fmJVrNeY4czs5MJzumcDixw93Izq3SaVdS7BthP0AZf2c5cVa8xnv6fdQ+v8nwW+BbworuXmNkL1dSZKOuBjjHPOx1k+InA7QRNd7cSrJ/7CZbR3VWMc7DlEzd3329mNwKLzex8d38hUdNOkNOBU8zsQMtDS+AYMxvs7tcmaiaHcqRyPkGzTD+Cw7PBBCdIJxG82aYSvAluNbPGZtbIzE4Mx30A+LGZHRteTdLTzLqE/WYD3wz3BEcRNjNVI4dgY7HdzFoCvz7Qw93XA/8G/mZmLcws3cxGxIz7AkG7//XAP2tpHhU9CfzSzHLNrDVBu/1jAGZ2TrgsjOBEbRlQZmZ9zOy08MO8L6zlC5cgenBZ4nPAb8Kjq37898ixJh4j2Es/K1wfjSy4ZLJjFcO/AvQ2szHhckg3s6EW/zX0G4Huh1FvxWl1NLMMgPDw/n7gz2bWBsDM8szsrINM5yngTOC7xDR9Ebwn9hOcY8omaEqrVFXrtZJBcwh2CgqBNDO7mWBvt7rX2NXCq7HC9+KbwO1m1tTMUsysh5kd7DNU5TSrkEGwA1kIlJrZ2QTLqLZNAMaaWd/wyPHmgwz/IcHO4DCCk/QLCI+mCVobKhPP64+buxcTBNvBak2IcHvaiGAdEX5mM2P6P2xmD4dPryDYZg8O/6YTNCn+Ip5pxetQFuTlBG1/q919w4E/4C6CJg8DziU4ybOa4GjjGwDu/gzBeYknCK5weIEgJSHYwJ9LcKXMpWG/6vyF4ITWZoIT4K9X6D+GoE17EcFVGD840CNss3wW6EawMU74PCpxC8HKmwvMA2aG3QB6EVylshv4CPibB9fPZxLsaW0mODRuA/y8iulfS3C4vIHgZPFD1dRSLXdfQ7A3/nOCDcga4CdU8T4J98jPJGjDLwhrOHDiOx6/AR4Jm26+XtO6Q+8QHA1uMLMDzbM3EjRDTQmbrP7DQc5XhBvqj4ATCC7GOOCfBE2L6wiuXpxSzWSqWq8VvUGwg7IknPY+qm/ieSZ83GJmM8P/v0WwEfiEYM/8X3y+ufJgKpvm54Tr+fsEG/ltBEdtLx3CPGrE3f9N0Jz0LsF6PNBss7+K4fcQfL4WhBt3wnE+9aovmz/o66+BBwlabc5N0PSq04Vgp/NAS0gRwVWYB3QiaPYnPBcZu+0uBna6+444pxUXq+L8Yb0V7g32dvfLoq5FROIXHgHPJ7gkv6rmvnrLzMYQNIUXA8M9/AJkNcNnEFyRO8jdSxIw/7cILnqY6u6nVzlcQwqVsClrFjDG3as6HBaRJGFmXyW4hL8xwTnRcnc/P9KipFoN5puyZvYdgqaFfytQROqMqwmaYpcTnJf6brTlyME0qCMVERGpXQ3mSEVERGpfMt5Ej9atW3vXrl2jLkNEpM6YMWPGZnfPPfiQtSspQ6Vr165Mnz496jJEROoMMzucu2kkjJq/REQkYRQqIiKSMAoVERFJGIWKiIgkjEJFREQSRqEiIiIJo1AREZGEScrvqdTUnW8vJSMtheZZ6TTLSqdZdjrNszLCx3SyM1IJfuJCRERqQ70JFXfnnonL2Vtc2W8hBdJTjWZZGTTLSqN5dkYQPgeCJyud1jkZ5HdpSe+2TRQ+IiI1UG9CxcxY8NuzKCopY/veErbvLWFHUQk7ioo/+39b+LizqITtRcVs2LmPRRt2saOohN37//vzDK2bZHB891YM79GKE3q0pmurbIWMiEgc6k2oQBAs2RlpZGek0aF51iGNW1JWTsH2Ij5esZWPVmzhw+WbeWXuegDaNW3ECT1aMaRLCzq1zCaveRZ5zbPIykitjZchIlJnJeWt7/Pz8z3qe3+5Oys37+HD5Vv4aMUWpizfwpY9xZ8bplXjDPJaZNGhWRZ5LbI4vnsrvtS3jY5qROSIM7MZ7p4feR0Klfi4OwU79rFuWxEF24tYt72ItduCx3Xb9rJuexH7Sso5tksLfj76KI7t0jLqkkWkAUmWUKlXzV+1ycw+a/aqTGlZOc/OXMvtby7hwr9/xKj+7fjpqD50z21yhCsVEYmOjlQSbG9xKf+YtJJ7Ji5nf2k53zyuM98/vRetm2RGXZqI1GPJcqSiUKklhbv2c+fbS3li6mqy0lMZf0p3vn1SN7IzdHAoIomnUKlGfQiVA5YX7ua21xfxxoKN5OZkct1pPbl4aGcy0nQzAxFJnGQJFW3ZalmP3CbcOyaff40fTrfWjbn5xQWcdvt7PDtjLWXlyRfoIiKHQ6FyhOR3bcnT447nkW8Po3l2Ojc8M4dRf3mf1+dvIBmPFkVEakKhcgSZGaf0zuXla0/ib5cOocyd8Y/N4Ly7JzNpaWHU5YmIHDaFSgTMjNED2/PmD0Zw29cGsWV3MWP+MZX73l8edWkiIodFoRKhtNQUvp7fiXd+fApnD2jHrf9exIfLNkddlohIjSlUkkBmWip/vOhourVuzHVPzmL9jqKoSxIRqRGFSpJokpnGvWOOZV9JGd99bCb7S6u+hb+ISLJSqCSRnm1y+ONFRzN7zXZueWVh1OWIiBwyhUqSGT2wPeNGdOfRKZ/y7Iy1UZcjInJIFCpJ6Kdn9eH47i35+fPzWFCwI+pyRETiplBJQmmpKfz1kiE0z07nu4/NZMfekqhLEhGJi0IlSeXmZPK3S49l/Y4ifjhhNuW6pYuI1AEKlSR2bJcW/OqcfryzaBN3v7ss6nJERA5KoZLkxhzfha8ek8ef/rOEuWu3R12OiEi1FCpJzsz43fkDaJGdwR9eXxR1OSIi1YorVMxslJktNrNlZnZTJf1bmNnzZjbXzKaa2YCYfqvMbJ6ZzTaz+vEjKUdYk8w0rj21J5OXbeGDpbqNi4gkr4OGipmlAncDZwP9gEvMrF+FwX4OzHb3QcC3gDsq9D/V3Qcnww/I1FWXHt+ZvOZZ/OH1RTppLyJJK54jlWHAMndf4e7FwFPAeRWG6Qe8DeDui4CuZtY2oZU2cJlpqfzojN7MW7eDf8/fEHU5IiKViidU8oA1Mc/Xht1izQEuADCzYUAXoGPYz4E3zWyGmY2raiZmNs7MppvZ9MJC/bZIZc4/Jo8+bXP4vzcXU1JWHnU5IiJfEE+oWCXdKra/3Aq0MLPZwHXALKA07Heiuw8haD67xsxGVDYTd7/P3fPdPT83Nzeu4hua1BTjJ2f1YeXmPTwzXbdwEZHkE0+orAU6xTzvCBTEDuDuO919rLsPJjinkgusDPsVhI+bgOcJmtOkhk7v24b8Li34y3+WUFSsOxmLSHKJJ1SmAb3MrJuZZQAXAy/FDmBmzcN+AFcB77v7TjNrbGY54TCNgTOB+Ykrv+ExM248+yg27drPwx+uirocEZHPOWiouHspcC3wBrAQmODuC8xsvJmNDwfrCywws0UEzVzXh93bAh+Y2RxgKvCqu7+e6BfR0Azt2pLTjmrD399bpvuCiUhSMffkuzw1Pz/fp0/XV1qqs3D9TkbfOYmrR/TgprOPirocEYmYmc1Ihq9t6Bv1dVTf9k05f3AeD01eyYYd+6IuR0QEUKjUaT86ozfl7tzx9tKoSxERARQqdVqnltlcelwXJkxfw4rC3VGXIyKiUKnrrjm1J5lpKdz+5pKoSxERUajUdbk5mVx5Ujdenbee5TpaEZGIKVTqgW8N70pGagqP6HsrIhIxhUo9kJuTyTlHt+dfM9ayo0jfWxGR6ChU6olvn9iNvcVlPDN9zcEHFhGpJQqVemJAXjOGdm3Bwx+uoky/tyIiEVGo1CNjT+zG2m1F/GfhxqhLEZEGSqFSj5zZry15zbN4aPLKqEsRkQZKoVKPpKWmMGZ4F6as2MrC9TujLkdEGiCFSj1z8dBONEpP0dGKiERCoVLPNM/O4IIhHXlhdgFbdu+PuhwRaWAUKvXQ2BO6UlxazpNTV0ddiog0MAqVeqhX2xxO7tWaR6d8SklZedTliEgDolCpp8ae2JWNO/fz2rz1UZciIg2IQqWeGtm7Dd1aN+ahyauiLkVEGhCFSj2VkmJccUJXZq/ZzqzV26IuR0QaCIVKPXbhsR3JyUzT0YqIHDEKlXqsSWYaXx/aidfmrdfv2IvIEaFQqecuH96VMncenbIq6lJEpAFQqNRznVtlM6p/Ox6avIo1W/dGXY6I1HMKlQbgF1/uiwE/f34e7rotvojUHoVKA9CxRTY3nn0Uk5Zu5tmZ66IuR0TqMYVKA3HZcV3I79KC373yCZt26aS9iNQOhUoDkZJi/OFrgygqKeM3Ly2IuhwRqacUKg1Ij9wmXH96L16bt4HX52+IuhwRqYcUKg3MuBHd6de+Kb96cT479pZEXY6I1DNxhYqZjTKzxWa2zMxuqqR/CzN73szmmtlUMxsQ77hyZKWnpnDb1waxdU8x//vawqjLEZF65qChYmapwN3A2UA/4BIz61dhsJ8Ds919EPAt4I5DGFeOsAF5zRg3ojtPT1/D5GWboy5HROqReI5UhgHL3H2FuxcDTwHnVRimH/A2gLsvArqaWds4x5UIXH96L7q3bsxNz81lb3Fp1OWISD0RT6jkAWtinq8Nu8WaA1wAYGbDgC5AxzjHJRxvnJlNN7PphYWF8VUvNdYoPZVbLxzEmq1F3P7mkqjLEZF6Ip5QsUq6Vfxa9q1ACzObDVwHzAJK4xw36Oh+n7vnu3t+bm5uHGXJ4RrWrSVjju/CQ5NX6vb4IpIQ8YTKWqBTzPOOQEHsAO6+093HuvtggnMqucDKeMaVaP10VB/aNW3ED5+eze79agYTkcMTT6hMA3qZWTczywAuBl6KHcDMmof9AK4C3nf3nfGMK9HKaZTOXy4+htVb93LzC/OjLkdE6riDhoq7lwLXAm8AC4EJ7r7AzMab2fhwsL7AAjNbRHCl1/XVjZv4lyGHY1i3lnz/9F48N2sdz81cG3U5IlKHWTLetTY/P9+nT58edRkNSlm5c8n9U5i/bgevfv9kurVuHHVJInIIzGyGu+dHXYe+US8ApKYYd1w8mIy0FK57cib7S8uiLklE6iCFinymfbMsbrtwEPPX7eS21xdHXY6I1EEKFfmcM/u34/LhXfjHByt5d9GmqMsRkTpGoSJf8LPRfenbvik3PDOHjTv12ysiEj+FinxBo/RU/nrJMRQVl/HDp2dTVp58F3OISHJSqEilerZpwm+/0p8Pl2/hnonLoy5HROoIhYpU6aL8jpx7dAf+9NYSpqzYEnU5IlIHKFSkSmbG/351AF1aZXP1ozNYtmlX1CWJSJJTqEi1chql88jYYaSnpnD5g9N04l5EqqVQkYPq1DKbh8cOZdveYsY+NI1d+/QzxCJSOYWKxGVAXjP+dukQFm/cxfcen0lJWXnUJYlIElKoSNxG9mnD7y8YyKSlm7nx2bkk433jRCRaaVEXIHXL1/M7sX77Pv78nyXkNc/ihjP7RF2SiCQRhYocsu+f3pP1O4r46zvLaNesEZce1yXqkkQkSShU5JCZGbecP4CNO/fxqxfm065pI07v2zbqskQkCeicitRIWmoKd31zCAPymnHNEzOZv25H1CWJSBJQqEiNNc5M4x+XD6VldgZXPzqDLbv3R12SiERMoSKHJTcnk3vH5LN5936ufWKWLjUWaeAUKnLYBnZsxu8vGMhHK7bwv68tjLocEYmQTtRLQlwwpCPz1+3kwckr6d+hGV87tmPUJYlIBHSkIgnz89FHMbx7K37+/DzmrNkedTkiEgGFiiRMcEXYMeQ2yWT8YzMo3KUT9yINjUJFEqpVk0zuHXMs2/YW873HZ1BcqhP3Ig2JQkUSbkBeM/5w4SCmrdrG7175JOpyROQI0ol6qRXnDc5jQcFO7nt/BQPymvKNoZ2jLklEjgAdqUit+elZfTipZ2t++cJ8Ji4pjLocETkCFCpSa9JSU7j70iH0apPD1Y9OZ9qqrVGXJCK1TKEitapZVjr/vHIYHZpl8e2HpukeYSL1XFyhYmajzGyxmS0zs5sq6d/MzF42szlmtsDMxsb0W2Vm88xstplNT2TxUje0bpLJo1cdR06jNC5/cCrLC3dHXZKI1JKDhoqZpQJ3A2cD/YBLzKxfhcGuAT5x96OBkcDtZpYR0/9Udx/s7vmJKVvqmrzmWTx21XEAjHngY9ZtL4q4IhGpDfEcqQwDlrn7CncvBp4CzqswjAM5ZmZAE2ArUJrQSqXO657bhH9eOYxd+0sZ88DH+nKkSD0UT6jkAWtinq8Nu8W6C+gLFADzgOvd/cC33hx408xmmNm4w6xX6rj+HZrx0BVDKdhRxLcenMqOopKoSxKRBIonVKySbl7h+VnAbKADMBi4y8yahv1OdPchBM1n15jZiEpnYjbOzKab2fTCQl1+Wp/ld23JvWPyWbZpF99+eBp7i3VQK1JfxBMqa4FOMc87EhyRxBoLPOeBZcBK4CgAdy8IHzcBzxM0p32Bu9/n7vnunp+bm3tor0LqnFN653LHxccwa/U2LnvgY5Zt0sl7kfognlCZBvQys27hyfeLgZcqDLMaOB3AzNoCfYAVZtbYzHLC7o2BM4H5iSpe6rbRA9tz5yXHsGzTbkbfMYk/vbWEfSVlUZclIofhoKHi7qXAtcAbwEJggrsvMLPxZjY+HOx3wAlmNg94G7jR3TcDbYEPzGwOMBV41d1fr40XInXTOYM68PYNIxk9sB13vr2Us++YxIfLNkddlojUkLlXPD0Svfz8fJ8+XV9paWgmLS3kly/M59Mte7lgSB6/GN2XVk0yoy5LpE4wsxnJ8LUNfaNeksbJvXJ54wcjuO60nrw8p4DT/zSRCdPWkIw7PiJSOYWKJJVG6anccGYfXvv+yfRuk8NPn53LT/41V8EiUkcoVCQp9Wqbw1PjjueaU3vwrxlreezj1VGXJCJxUKhI0kpJMW44ow+n9snlf15ewKzV26IuSUQOQqEiSS0lxfjLN46hXbNGfO/xmWzZrVu7iCQzhYokvWbZ6fz90mPZuqeY656cRWmZfvdeJFkpVKROGJDXjFvOH8CHy7dw+1tLoi5HRKqgUJE646L8TlwyrDN/f285by7YEHU5IlIJhYrUKb8+tx+DOjbjhglzWLl5T9TliEgFChWpUxqlp/K3S4eQlmqMf3SG7nAskmQUKlLndGyRzR0XH8OSTbv42XPz9MVIkSSSFnUBIjUxoncuP/pSb25/awnrthVx3uAOjB7YXvcKE4mYbigpdVZ5ufPAByt4Zvpalm7aTWqKcWLP1pw7qD1nDWhH00bpUZcocsQkyw0lFSpS57k7izfu4qXZBbw8t4A1W4vISEvh1D65nD84j1ED2mFW2Q+YitQfCpVqKFSkptyd2Wu289KcAl6Zu57CXfs59+gO/PFrg2iUnhp1eSK1JllCRedUpF4xM47p3IJjOrfgl1/ux73vL+e21xezdtte7huTT26OzrmI1CZd/SX1VmqK8b2RPbnnsiEsXL+T8++ezOINu6IuS6ReU6hIvTdqQHsmXD2ckrJyLvz7h7y3eFPUJYnUWwoVaRAGdWzOi9eeSOeW2Xz74Wk88uGqqEsSqZcUKtJgtG+WxTPjh3PaUW359UsLuPnF+brjsUiCKVSkQWmcmca9Y47lOyd3458ffcrYh6exZuveqMsSqTcUKtLgpKYYv/hyP269YCDTV23jS3+ayJ/eWkJRcVnUpYnUeQoVabAuHtaZd358Cmf1b8edby/l9Nvf45W5BbqXmMhhUKhIg9a+WRZ3XnIME64eTrPsDK59YhYX3zeFhet3Rl2aSJ2kUBEBhnVrySvXncT/++oAlmzcxZfvnMSvXpjPtj3FUZcmUqfoNi0iFWzfW8yf31rCo1M+JTsjjTHDu/DtE7vp2/iS1JLlNi0KFZEqLN6wi7++s5RX560nIzWFi4d24jsjutOxRXbUpYl8gUKlGgoVSSYrCndz78QVPDdrLe5w3uA8vjuyBz3bNIm6NJHPKFSqoVCRZFSwvYj7J63gyamr2V9azqj+7fjxWX3okatwkeglS6jEdaLezEaZ2WIzW2ZmN1XSv5mZvWxmc8xsgZmNjXdckbqiQ/Msfn1ufybfeBrXjOzJB8s287W/f8gnBbpSTOSAg4aKmaUCdwNnA/2AS8ysX4XBrgE+cfejgZHA7WaWEee4InVKqyaZ/PisPrxy3UlkpafyzQemsKBgR9RliSSFeI5UhgHL3H2FuxcDTwHnVRjGgRwLfl6vCbAVKI1zXJE6qUurxjw1bjiNM9L45v0fM3+dgkUknlDJA9bEPF8bdot1F9AXKADmAde7e3mc4wJgZuPMbLqZTS8sLIyzfJFodW6VzVPjjqdJZhqXPvAx89YqWKRhiydUKvtx74pn988CZgMdgMHAXWbWNM5xg47u97l7vrvn5+bmxlGWSHLo1DI2WKYwd+32qEsSiUw8obIW6BTzvCPBEUmsscBzHlgGrASOinNckTqvU8tsnr76eJpmpXPpAx8ze832qEsSiUQ8oTIN6GVm3cwsA7gYeKnCMKuB0wHMrC3QB1gR57gi9ULHFtk8ffVwmmenM+aBj5m1elvUJYkccQcNFXcvBa4F3gAWAhPcfYGZjTez8eFgvwNOMLN5wNvAje6+uapxa+OFiCSDvOZZPD1uOC0aZzDmH1P5y3+W8NHyLewr0W31pWHQlx9FasH6HUVc98QsZqzehjtkpKZwdKdmHNetFcO6teTYLi1onJkWdZlSjyTLlx8VKiK1aEdRCdNXbWXqyq1MWbmV+et2UFbupKYYgzs151fn9GNwp+ZRlyn1gEKlGgoVqa927y9l5qfb+HjlFp6fuY7C3fu5+Zx+XHZ8F4KveYnUjEKlGgoVaQi27y3mRxPm8M6iTZx7dAduvWCgmsSkxpIlVPQjXSIRaZ6dwQPfyucnZ/Xh1bkFfOWuD1i6cVfUZYkcFoWKSIRSUoxrTu3JY1cex46iEr5y12RenL0u6rJEakyhIpIETujZmle/fzID85px/VOz+eUL89hfqsuQpe5RqIgkibZNG/HEd47j6hHdeWzKai665yPWbtsbdVkih0ShIpJE0lJT+Nnovtw35lhWFu7h3L9+wAdLN0ddlkjcFCoiSejM/u148doTyc3J5FsPfszf3ltGMl6pKVKRQkUkSXXPbcLz3zuR0QPbc9vri/nuYzPZta8k6rJEqqVQEUlijTPT+Oslx/DLL/flrYUbOf/uySzbpMuOJXkpVESSnJlx1cndP7vs+Ly7JvPveeujLkukUgoVkTpieI9WvHzdSfRqm8N3H5/JT/81h/cWb9IdkCWp6DYtInXM/tIyfv/aIp6cupr9peVkpqVwfPdWjOyTyym9c+nWurHuI9YAJcttWhQqInXUvpIypqzYwsQlhUxcXMiKzXsA6NQyi5G923Du0R0Y2rWFAqaBUKhUQ6EicuhWb9nLxCWbmLikkMnLtlBUUsbRHZvxnRHdGdW/HWmpau2uzxQq1VCoiByeouIynp25ln98sJKVm/fQsUUWV57Uja/nd9KdkOsphUo1FCoiiVFW7vxn4UYemLSCaau20bRRGpcd34UrTuhKm6aNoi5PEkihUg2FikjizVy9jQcmreD1+RtIMaNNTiaZ6alkpqWQmZ5Ko5jHnEbpXDysE0O7toy6bImTQqUaChWR2rN6y16emraawl372V9azr6Ssi88rt+xjx1FJYzoncsNZ/TmaP3kcdJTqFRDoSISraLiMv750SrumbicbXtLOKNfW350Rm/6tm8adWlSBYVKNRQqIslh174SHpq8ivvfX8Gu/aWcM6g9P/hSb3q2aRJ1aVKBQqUaChWR5LJ9bzH3T1rBQ5NXsa+kjPMH5zHulO4c1U5HLslCoVINhYpIctq8ez9/f285j3/8KftKyjm5V2uuOrk7I3q11pcsI6ZQqYZCRSS5bdtTzBNTV/Pwh6so3LWfXm2acNXJ3ThvcB6N0lOjLq9BUqhUQ6EiUjfsLy3jlTnruX/SChZt2EWrxhmMGd6FMcd3oVWTzKjLa1AUKtVQqIjULe7OR8u38MAHK3ln0SaaZKbxwzN6c/nwLro9zBGiUKmGQkWk7lq6cRe3vLqQiUsKOapdDv9z3gCGddOXKGtbsoSKdiFEJKF6tc3h4bFDueeyY9m1r5Sv3/sRP5owm8Jd+6MuTY6AuELFzEaZ2WIzW2ZmN1XS/ydmNjv8m29mZWbWMuy3yszmhf10+CHSAJgZowa0460fjeCaU3vw8pwCTrv9PR75cBWlZeVRlye16KDNX2aWCiwBzgDWAtOAS9z9kyqGPxf4obufFj5fBeS7++Z4i1Lzl0j9srxwN79+cQEfLNtMv/ZN+e15/XVfsQSrS81fw4Bl7r7C3YuBp4Dzqhn+EuDJRBQnIvVDj9wmPHrlMP526RC27S3mons+4upHp7O8cHfUpUmCxRMqecCamOdrw25fYGbZwCjg2ZjODrxpZjPMbFxVMzGzcWY23cymFxYWxlGWiNQlZsboge15+4ZTuOGM3nywdDNn/vl9fvXCfJ1vqUfiCZXKviZbVZvZucBkd98a0+1Edx8CnA1cY2YjKhvR3e9z93x3z8/NzY2jLBGpi7Iz0rju9F5M/OmpfHNYZ56YupqRf3yXO99eyt7i0qjLk8MUT6isBTrFPO8IFFQx7MVUaPpy94LwcRPwPEFzmog0cK2bZPK78wfw5g9HcFKv1vzprSWM/ON7PDV1tU7m12HxhMo0oJeZdTOzDILgeKniQGbWDDgFeDGmW2MzyznwP3AmMD8RhYtI/dAjtwn3jsnnX+OH07FFFjc9N48Rt73L3e8uY+ue4qjLk0N00B+rdvdSM7sWeANIBR509wVmNj7sf0846FeBN919T8zobYHnwxvNpQFPuPvriXwBIlI/5HdtybPfPYH/LNzEwx+u5I9vLOaOt5dy7qAOXHFCVwZ2bFbpeMWl5Uz/dCvvL9nM+0sKKdhRxIVDOjL2xK50bJF9hF+F6Bv1IpKUlm7cxSMfreK5mevYW1zGkM7NufyErpw9oD1rt+1l0tIgRD5asYW9xWWkpRhDurSgVeMM3vxkIwBfHtie75zcvcpAqk+S5ZJihYqIJLUdRSX8a8ZaHv1oFau27CUzLYX9pcE5ly6tshnRK5cRvXMZ3qMVTTKDxpd124t4ePJKnpy6ht37Szm+e0vGjejOyN5tSEmpn7foV6hUQ6EiIhWVlzsTlxby1icb6dsuhxG9c+nSqnG14+zcV8LTU9fw4OSVrN+xj55tmjDu5O6cf0weGWn16y5VCpVqKFREJJFKysp5bd567nt/BQsKdpLXPIvxp3TnovxO9eb3XxQq1VCoiEhtcHcmLinkr+8sY8an22iTk8m4Ed355nGdyc446HVLSU2hUg2FiojUJndnyoqt/PWdpXy4fAstG2dw5Und+NbwLuQ0So+6vBpRqFRDoSIiR8qMT7dy1zvLeHdxIU0bpfHlQe0ZmNecgXnN6N2uCZlpdaN5TKFSDYWKiBxp89bu4J6Jy5m0tJCd+4LbxaSnGn3a5TAwrxn9OzQLH5sm5a9ZKlSqoVARkai4O2u2FjFv3Q7mrdvB/PBxR1EJAK2bZHD2gPacM6g9Q7u2TJpLlBUq1VCoiEgycXfWbiti9prtvL5gA28v3Mi+knLaNs1k9MD2nDOoA0M6Nye8e0gkFCrVUKiISDLbW1zK2ws38fKcAt5bUkhxaTl5zbM4Z1B7Ljy2I73b5hzxmhQq1VCoiEhdsWtfCW99spGX5xQwaelmSsudwZ2a842hnThnUPsjdjWZQqUaChURqYu27N7P87PWMWH6GpZs3E1WeiqjB7bnG0M7MbRri1ptHlOoVEOhIiJ1mbsze812Jkxfy8tzCti9v5RurRtz7tEd6Ngii5bZGbRskkGrxhm0bJxBk8y0ww4chUo1FCoiUl/sLS7ltXkbmDB9DVNXbq10mIzUFFo2zqBTyyyeGX9CjeaTLKFSt+9LICKS5LIz0vjasR352rEd2VtcypbdxWzdE/xt2VPM1j37g8fdxaQmyeXJh0OhIiJyhGRnpJHdMo1OLevvj4cl39dCRUSkzlKoiIhIwihUREQkYRQqIiKSMAoVERFJGIWKiIgkjEJFREQSRqEiIiIJk5S3aTGzQuDTKnq3BjYfwXIOhWqrGdVWM6qtZuprbV3cPTeRxdREUoZKdcxsejLc36Yyqq1mVFvNqLaaUW21S81fIiKSMAoVERFJmLoYKvdFXUA1VFvNqLaaUW01o9pqUZ07pyIiIsmrLh6piIhIklKoiIhIwtSZUDGzUWa22MyWmdlNUddTkZmtMrN5ZjbbzCL9LWQze9DMNpnZ/JhuLc3sLTNbGj62SKLafmNm68JlN9vMRkdQVycze9fMFprZAjO7Puwe+XKrprZkWG6NzGyqmc0Ja/tt2D0ZlltVtUW+3GJqTDWzWWb2Svg88uV2uOrEORUzSwWWAGcAa4FpwCXu/kmkhcUws1VAvrtH/qUqMxsB7Ab+6e4Dwm63AVvd/dYwlFu4+41JUttvgN3u/n9Hup6YutoD7d19ppnlADOA84EriHi5VVPb14l+uRnQ2N13m1k68AFwPXAB0S+3qmobRcTL7QAz+xGQDzR193OS5XN6OOrKkcowYJm7r3D3YuAp4LyIa0pa7v4+sLVC5/OAR8L/HyHYKB1xVdQWOXdf7+4zw/93AQuBPJJguVVTW+Q8sDt8mh7+Ocmx3KqqLSmYWUfgy8ADMZ0jX26Hq66ESh6wJub5WpLkQxXDgTfNbIaZjYu6mEq0dff1EGykgDYR11PRtWY2N2wei/SQ38y6AscAH5Nky61CbZAEyy1swpkNbALecvekWW5V1AZJsNyAvwA/BcpjuiXFcjscdSVUrJJuSbPHETrR3YcAZwPXhM08Ep+/Az2AwcB64PaoCjGzJsCzwA/cfWdUdVSmktqSYrm5e5m7DwY6AsPMbEAUdVSmitoiX25mdg6wyd1nHOl517a6EiprgU4xzzsCBRHVUil3LwgfNwHPEzTZJZONYdv8gTb6TRHX8xl33xh++MuB+4lo2YXt7s8Cj7v7c2HnpFhuldWWLMvtAHffDrxHcM4iKZbbAbG1JclyOxH4Sngu9ingNDN7jCRbbjVRV0JlGtDLzLqZWQZwMfBSxDV9xswahydQMbPGwJnA/OrHOuJeAi4P/78ceDHCWj7nwIco9FUiWHbhSd1/AAvd/U8xvSJfblXVliTLLdfMmof/ZwFfAhaRHMut0tqSYbm5+8/cvaO7dyXYnr3j7peRBMvtsLl7nfgDRhNcAbYc+EXU9VSorTswJ/xbEHV9wJMEh/UlBEd5VwKtgLeBpeFjyySq7VFgHjCX4EPVPoK6TiJoUp0LzA7/RifDcqumtmRYboOAWWEN84Gbw+7JsNyqqi3y5VahzpHAK8my3A73r05cUiwiInVDXWn+EhGROkChIiIiCaNQERGRhFGoiIhIwihUREQkYRQqIiKSMAoVERFJmP8P9mmtvJOHzskAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "r_axis = np.arange(1,41)\n",
    "plt.plot(r_axis,ACC_R)\n",
    "plt.title(\"Accuracy across different intervals after training with R in [1,41]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96ea271",
   "metadata": {},
   "source": [
    "## R3 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b8e8f978",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_len = 100\n",
    "R = 3\n",
    "T = 500\n",
    "batch_size = 64\n",
    "HebbFF_R3 = HebbFF(input_dim = vec_len, hid_dim=100, out_dim=1, batch_size = batch_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(HebbFF_R3.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6095a6ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 10/500.... Loss: 0.2718 | Accuracy: 0.3343\n",
      "Iterations: 20/500.... Loss: 0.2606 | Accuracy: 0.3423\n",
      "Iterations: 30/500.... Loss: 0.2476 | Accuracy: 0.4711\n",
      "Iterations: 40/500.... Loss: 0.2330 | Accuracy: 0.7058\n",
      "Iterations: 50/500.... Loss: 0.2173 | Accuracy: 0.7901\n",
      "Iterations: 60/500.... Loss: 0.2037 | Accuracy: 0.7876\n",
      "Iterations: 70/500.... Loss: 0.1922 | Accuracy: 0.7811\n",
      "Iterations: 80/500.... Loss: 0.1852 | Accuracy: 0.7615\n",
      "Iterations: 90/500.... Loss: 0.1825 | Accuracy: 0.7457\n",
      "Iterations: 100/500.... Loss: 0.1799 | Accuracy: 0.7430\n",
      "Iterations: 110/500.... Loss: 0.1792 | Accuracy: 0.7311\n",
      "Iterations: 120/500.... Loss: 0.1773 | Accuracy: 0.7314\n",
      "Iterations: 130/500.... Loss: 0.1759 | Accuracy: 0.7244\n",
      "Iterations: 140/500.... Loss: 0.1755 | Accuracy: 0.7197\n",
      "Iterations: 150/500.... Loss: 0.1749 | Accuracy: 0.7138\n",
      "Iterations: 160/500.... Loss: 0.1744 | Accuracy: 0.7081\n",
      "Iterations: 170/500.... Loss: 0.1731 | Accuracy: 0.7069\n",
      "Iterations: 180/500.... Loss: 0.1709 | Accuracy: 0.7046\n",
      "Iterations: 190/500.... Loss: 0.1718 | Accuracy: 0.6990\n",
      "Iterations: 200/500.... Loss: 0.1698 | Accuracy: 0.6966\n",
      "Iterations: 210/500.... Loss: 0.1691 | Accuracy: 0.6954\n",
      "Iterations: 220/500.... Loss: 0.1692 | Accuracy: 0.6923\n",
      "Iterations: 230/500.... Loss: 0.1665 | Accuracy: 0.6950\n",
      "Iterations: 240/500.... Loss: 0.1665 | Accuracy: 0.6904\n",
      "Iterations: 250/500.... Loss: 0.1649 | Accuracy: 0.6909\n",
      "Iterations: 260/500.... Loss: 0.1646 | Accuracy: 0.6894\n",
      "Iterations: 270/500.... Loss: 0.1625 | Accuracy: 0.6918\n",
      "Iterations: 280/500.... Loss: 0.1631 | Accuracy: 0.6888\n",
      "Iterations: 290/500.... Loss: 0.1620 | Accuracy: 0.6889\n",
      "Iterations: 300/500.... Loss: 0.1612 | Accuracy: 0.6873\n",
      "Iterations: 310/500.... Loss: 0.1592 | Accuracy: 0.6908\n",
      "Iterations: 320/500.... Loss: 0.1579 | Accuracy: 0.6921\n",
      "Iterations: 330/500.... Loss: 0.1574 | Accuracy: 0.6909\n",
      "Iterations: 340/500.... Loss: 0.1546 | Accuracy: 0.6942\n",
      "Iterations: 350/500.... Loss: 0.1537 | Accuracy: 0.6961\n",
      "Iterations: 360/500.... Loss: 0.1525 | Accuracy: 0.6958\n",
      "Iterations: 370/500.... Loss: 0.1514 | Accuracy: 0.6953\n",
      "Iterations: 380/500.... Loss: 0.1484 | Accuracy: 0.7017\n",
      "Iterations: 390/500.... Loss: 0.1478 | Accuracy: 0.7009\n",
      "Iterations: 400/500.... Loss: 0.1466 | Accuracy: 0.7043\n",
      "Iterations: 410/500.... Loss: 0.1442 | Accuracy: 0.7051\n",
      "Iterations: 420/500.... Loss: 0.1428 | Accuracy: 0.7088\n",
      "Iterations: 430/500.... Loss: 0.1406 | Accuracy: 0.7132\n",
      "Iterations: 440/500.... Loss: 0.1385 | Accuracy: 0.7182\n",
      "Iterations: 450/500.... Loss: 0.1367 | Accuracy: 0.7247\n",
      "Iterations: 460/500.... Loss: 0.1348 | Accuracy: 0.7316\n",
      "Iterations: 470/500.... Loss: 0.1329 | Accuracy: 0.7374\n",
      "Iterations: 480/500.... Loss: 0.1307 | Accuracy: 0.7451\n",
      "Iterations: 490/500.... Loss: 0.1275 | Accuracy: 0.7567\n",
      "Iterations: 500/500.... Loss: 0.1252 | Accuracy: 0.7687\n"
     ]
    }
   ],
   "source": [
    "n_iterations = 500\n",
    "for iterations in range(1, n_iterations+1):\n",
    "    input_seq,target_seq = generate_seq(batch_size = batch_size, vec_len = vec_len, R = R, T = T)\n",
    "    accuracy,total_loss = train(HebbFF_R3,criterion,optimizer,input_seq,target_seq,T)\n",
    "    if iterations % 10 == 0:\n",
    "        print('Iterations: {}/{}....'.format(iterations, n_iterations), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(total_loss.item()), end=' | ')\n",
    "        print(\"Accuracy: {:.4f}\".format(accuracy.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "11580723",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 510/1000.... Loss: 0.1224 | Accuracy: 0.7806\n",
      "Iterations: 520/1000.... Loss: 0.1202 | Accuracy: 0.7946\n",
      "Iterations: 530/1000.... Loss: 0.1170 | Accuracy: 0.8090\n",
      "Iterations: 540/1000.... Loss: 0.1141 | Accuracy: 0.8273\n",
      "Iterations: 550/1000.... Loss: 0.1113 | Accuracy: 0.8431\n",
      "Iterations: 560/1000.... Loss: 0.1084 | Accuracy: 0.8622\n",
      "Iterations: 570/1000.... Loss: 0.1057 | Accuracy: 0.8767\n",
      "Iterations: 580/1000.... Loss: 0.1017 | Accuracy: 0.9005\n",
      "Iterations: 590/1000.... Loss: 0.0985 | Accuracy: 0.9149\n",
      "Iterations: 600/1000.... Loss: 0.0955 | Accuracy: 0.9360\n",
      "Iterations: 610/1000.... Loss: 0.0926 | Accuracy: 0.9472\n",
      "Iterations: 620/1000.... Loss: 0.0897 | Accuracy: 0.9583\n",
      "Iterations: 630/1000.... Loss: 0.0875 | Accuracy: 0.9666\n",
      "Iterations: 640/1000.... Loss: 0.0850 | Accuracy: 0.9731\n",
      "Iterations: 650/1000.... Loss: 0.0823 | Accuracy: 0.9799\n",
      "Iterations: 660/1000.... Loss: 0.0801 | Accuracy: 0.9824\n",
      "Iterations: 670/1000.... Loss: 0.0779 | Accuracy: 0.9845\n",
      "Iterations: 680/1000.... Loss: 0.0762 | Accuracy: 0.9880\n",
      "Iterations: 690/1000.... Loss: 0.0742 | Accuracy: 0.9890\n",
      "Iterations: 700/1000.... Loss: 0.0728 | Accuracy: 0.9901\n",
      "Iterations: 710/1000.... Loss: 0.0708 | Accuracy: 0.9911\n",
      "Iterations: 720/1000.... Loss: 0.0688 | Accuracy: 0.9932\n",
      "Iterations: 730/1000.... Loss: 0.0672 | Accuracy: 0.9938\n",
      "Iterations: 740/1000.... Loss: 0.0658 | Accuracy: 0.9944\n",
      "Iterations: 750/1000.... Loss: 0.0640 | Accuracy: 0.9946\n",
      "Iterations: 760/1000.... Loss: 0.0628 | Accuracy: 0.9953\n",
      "Iterations: 770/1000.... Loss: 0.0612 | Accuracy: 0.9957\n",
      "Iterations: 780/1000.... Loss: 0.0599 | Accuracy: 0.9959\n",
      "Iterations: 790/1000.... Loss: 0.0585 | Accuracy: 0.9957\n",
      "Iterations: 800/1000.... Loss: 0.0573 | Accuracy: 0.9965\n",
      "Iterations: 810/1000.... Loss: 0.0565 | Accuracy: 0.9960\n",
      "Iterations: 820/1000.... Loss: 0.0548 | Accuracy: 0.9962\n",
      "Iterations: 830/1000.... Loss: 0.0539 | Accuracy: 0.9966\n",
      "Iterations: 840/1000.... Loss: 0.0526 | Accuracy: 0.9962\n",
      "Iterations: 850/1000.... Loss: 0.0515 | Accuracy: 0.9967\n",
      "Iterations: 860/1000.... Loss: 0.0505 | Accuracy: 0.9968\n",
      "Iterations: 870/1000.... Loss: 0.0495 | Accuracy: 0.9965\n",
      "Iterations: 880/1000.... Loss: 0.0487 | Accuracy: 0.9972\n",
      "Iterations: 890/1000.... Loss: 0.0479 | Accuracy: 0.9958\n",
      "Iterations: 900/1000.... Loss: 0.0469 | Accuracy: 0.9972\n",
      "Iterations: 910/1000.... Loss: 0.0460 | Accuracy: 0.9962\n",
      "Iterations: 920/1000.... Loss: 0.0452 | Accuracy: 0.9967\n",
      "Iterations: 930/1000.... Loss: 0.0447 | Accuracy: 0.9964\n",
      "Iterations: 940/1000.... Loss: 0.0434 | Accuracy: 0.9971\n",
      "Iterations: 950/1000.... Loss: 0.0428 | Accuracy: 0.9965\n",
      "Iterations: 960/1000.... Loss: 0.0423 | Accuracy: 0.9965\n",
      "Iterations: 970/1000.... Loss: 0.0412 | Accuracy: 0.9970\n",
      "Iterations: 980/1000.... Loss: 0.0407 | Accuracy: 0.9966\n",
      "Iterations: 990/1000.... Loss: 0.0399 | Accuracy: 0.9969\n",
      "Iterations: 1000/1000.... Loss: 0.0397 | Accuracy: 0.9960\n"
     ]
    }
   ],
   "source": [
    "n_iterations = 1000\n",
    "for iterations in range(501, n_iterations+1):\n",
    "    input_seq,target_seq = generate_seq(batch_size = batch_size, vec_len = vec_len, R = R, T = T)\n",
    "    accuracy,total_loss = train(HebbFF_R3,criterion,optimizer,input_seq,target_seq,T)\n",
    "    if iterations % 10 == 0:\n",
    "        print('Iterations: {}/{}....'.format(iterations, n_iterations), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(total_loss.item()), end=' | ')\n",
    "        print(\"Accuracy: {:.4f}\".format(accuracy.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "65d1eb0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R =  1 ... accuracy:  0.9973|loss:  0.0195\n",
      "R =  2 ... accuracy:  0.9967|loss:  0.0266\n",
      "R =  3 ... accuracy:  0.9967|loss:  0.0393\n",
      "R =  4 ... accuracy:  0.9808|loss:  0.0582\n",
      "R =  5 ... accuracy:  0.9207|loss:  0.0811\n",
      "R =  6 ... accuracy:  0.8508|loss:  0.1015\n",
      "R =  7 ... accuracy:  0.8024|loss:  0.1186\n",
      "R =  8 ... accuracy:  0.7671|loss:  0.1319\n",
      "R =  9 ... accuracy:  0.7554|loss:  0.1393\n",
      "R =  10 ... accuracy:  0.7399|loss:  0.1475\n",
      "R =  11 ... accuracy:  0.7299|loss:  0.1533\n",
      "R =  12 ... accuracy:  0.7211|loss:  0.1597\n",
      "R =  13 ... accuracy:  0.7117|loss:  0.1670\n",
      "R =  14 ... accuracy:  0.7066|loss:  0.1720\n",
      "R =  15 ... accuracy:  0.7049|loss:  0.1768\n",
      "R =  16 ... accuracy:  0.6970|loss:  0.1826\n",
      "R =  17 ... accuracy:  0.6954|loss:  0.1867\n",
      "R =  18 ... accuracy:  0.6911|loss:  0.1909\n",
      "R =  19 ... accuracy:  0.6936|loss:  0.1925\n",
      "R =  20 ... accuracy:  0.6877|loss:  0.1974\n",
      "R =  21 ... accuracy:  0.6880|loss:  0.1998\n",
      "R =  22 ... accuracy:  0.6835|loss:  0.2034\n",
      "R =  23 ... accuracy:  0.6850|loss:  0.2055\n",
      "R =  24 ... accuracy:  0.6859|loss:  0.2067\n",
      "R =  25 ... accuracy:  0.6821|loss:  0.2100\n",
      "R =  26 ... accuracy:  0.6794|loss:  0.2122\n",
      "R =  27 ... accuracy:  0.6798|loss:  0.2157\n",
      "R =  28 ... accuracy:  0.6840|loss:  0.2141\n",
      "R =  29 ... accuracy:  0.6811|loss:  0.2176\n",
      "R =  30 ... accuracy:  0.6808|loss:  0.2187\n",
      "R =  31 ... accuracy:  0.6832|loss:  0.2190\n",
      "R =  32 ... accuracy:  0.6803|loss:  0.2213\n",
      "R =  33 ... accuracy:  0.6842|loss:  0.2208\n",
      "R =  34 ... accuracy:  0.6811|loss:  0.2232\n",
      "R =  35 ... accuracy:  0.6809|loss:  0.2239\n",
      "R =  36 ... accuracy:  0.6799|loss:  0.2255\n",
      "R =  37 ... accuracy:  0.6803|loss:  0.2260\n",
      "R =  38 ... accuracy:  0.6817|loss:  0.2253\n",
      "R =  39 ... accuracy:  0.6837|loss:  0.2256\n",
      "R =  40 ... accuracy:  0.6824|loss:  0.2271\n"
     ]
    }
   ],
   "source": [
    "ACC_R3 = []\n",
    "for i in range(1, 41):\n",
    "    input_seq,target_seq = generate_seq(batch_size = batch_size, vec_len = vec_len, R = i, T = T)\n",
    "    accuracy,total_loss = test(HebbFF_R3,criterion,optimizer,input_seq,target_seq,T)\n",
    "    print('R = ',i,'...','accuracy: ',format(accuracy.item() , '.4f'), end = '|')\n",
    "    print('loss: ',format(total_loss.item() , '.4f'))\n",
    "    ACC_R3.append(accuracy.item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "03f2cd22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy across different intervals after training with R = 3')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "r_axis = np.arange(1,41)\n",
    "plt.plot(r_axis,ACC_R3)\n",
    "plt.title(\"Accuracy across different intervals after training with R = 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "00cc222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_len = 100\n",
    "R = 6\n",
    "T = 500\n",
    "batch_size = 64\n",
    "HebbFF_R6 = HebbFF(input_dim = vec_len, hid_dim=100, out_dim=1, batch_size = batch_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(HebbFF_R6.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4ecb660a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 10/500.... Loss: 0.4697 | Accuracy: 0.3309\n",
      "Iterations: 20/500.... Loss: 0.4595 | Accuracy: 0.3328\n",
      "Iterations: 30/500.... Loss: 0.4495 | Accuracy: 0.3316\n",
      "Iterations: 40/500.... Loss: 0.4356 | Accuracy: 0.3318\n",
      "Iterations: 50/500.... Loss: 0.4168 | Accuracy: 0.3339\n",
      "Iterations: 60/500.... Loss: 0.3940 | Accuracy: 0.3347\n",
      "Iterations: 70/500.... Loss: 0.3664 | Accuracy: 0.3409\n",
      "Iterations: 80/500.... Loss: 0.3334 | Accuracy: 0.3742\n",
      "Iterations: 90/500.... Loss: 0.3070 | Accuracy: 0.4237\n",
      "Iterations: 100/500.... Loss: 0.2887 | Accuracy: 0.4637\n",
      "Iterations: 110/500.... Loss: 0.2791 | Accuracy: 0.4827\n",
      "Iterations: 120/500.... Loss: 0.2714 | Accuracy: 0.5015\n",
      "Iterations: 130/500.... Loss: 0.2641 | Accuracy: 0.5183\n",
      "Iterations: 140/500.... Loss: 0.2559 | Accuracy: 0.5378\n",
      "Iterations: 150/500.... Loss: 0.2513 | Accuracy: 0.5520\n",
      "Iterations: 160/500.... Loss: 0.2454 | Accuracy: 0.5668\n",
      "Iterations: 170/500.... Loss: 0.2380 | Accuracy: 0.5853\n",
      "Iterations: 180/500.... Loss: 0.2319 | Accuracy: 0.5988\n",
      "Iterations: 190/500.... Loss: 0.2299 | Accuracy: 0.6050\n",
      "Iterations: 200/500.... Loss: 0.2249 | Accuracy: 0.6191\n",
      "Iterations: 210/500.... Loss: 0.2215 | Accuracy: 0.6287\n",
      "Iterations: 220/500.... Loss: 0.2193 | Accuracy: 0.6381\n",
      "Iterations: 230/500.... Loss: 0.2150 | Accuracy: 0.6482\n",
      "Iterations: 240/500.... Loss: 0.2092 | Accuracy: 0.6625\n",
      "Iterations: 250/500.... Loss: 0.2094 | Accuracy: 0.6642\n",
      "Iterations: 260/500.... Loss: 0.2082 | Accuracy: 0.6633\n",
      "Iterations: 270/500.... Loss: 0.2093 | Accuracy: 0.6625\n",
      "Iterations: 280/500.... Loss: 0.2069 | Accuracy: 0.6664\n",
      "Iterations: 290/500.... Loss: 0.2046 | Accuracy: 0.6739\n",
      "Iterations: 300/500.... Loss: 0.2035 | Accuracy: 0.6761\n",
      "Iterations: 310/500.... Loss: 0.2021 | Accuracy: 0.6797\n",
      "Iterations: 320/500.... Loss: 0.1999 | Accuracy: 0.6848\n",
      "Iterations: 330/500.... Loss: 0.1973 | Accuracy: 0.6902\n",
      "Iterations: 340/500.... Loss: 0.1992 | Accuracy: 0.6881\n",
      "Iterations: 350/500.... Loss: 0.1969 | Accuracy: 0.6918\n",
      "Iterations: 360/500.... Loss: 0.1943 | Accuracy: 0.7007\n",
      "Iterations: 370/500.... Loss: 0.1949 | Accuracy: 0.7005\n",
      "Iterations: 380/500.... Loss: 0.1952 | Accuracy: 0.6969\n",
      "Iterations: 390/500.... Loss: 0.1935 | Accuracy: 0.7014\n",
      "Iterations: 400/500.... Loss: 0.1936 | Accuracy: 0.7033\n",
      "Iterations: 410/500.... Loss: 0.1919 | Accuracy: 0.7069\n",
      "Iterations: 420/500.... Loss: 0.1927 | Accuracy: 0.7067\n",
      "Iterations: 430/500.... Loss: 0.1908 | Accuracy: 0.7080\n",
      "Iterations: 440/500.... Loss: 0.1914 | Accuracy: 0.7093\n",
      "Iterations: 450/500.... Loss: 0.1911 | Accuracy: 0.7088\n",
      "Iterations: 460/500.... Loss: 0.1910 | Accuracy: 0.7123\n",
      "Iterations: 470/500.... Loss: 0.1900 | Accuracy: 0.7142\n",
      "Iterations: 480/500.... Loss: 0.1899 | Accuracy: 0.7166\n",
      "Iterations: 490/500.... Loss: 0.1903 | Accuracy: 0.7138\n",
      "Iterations: 500/500.... Loss: 0.1893 | Accuracy: 0.7153\n"
     ]
    }
   ],
   "source": [
    "n_iterations = 500\n",
    "for iterations in range(1, n_iterations+1):\n",
    "    input_seq,target_seq = generate_seq(batch_size = batch_size, vec_len = vec_len, R = R, T = T)\n",
    "    accuracy,total_loss = train(HebbFF_R6,criterion,optimizer,input_seq,target_seq,T)\n",
    "    if iterations % 10 == 0:\n",
    "        print('Iterations: {}/{}....'.format(iterations, n_iterations), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(total_loss.item()), end=' | ')\n",
    "        print(\"Accuracy: {:.4f}\".format(accuracy.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e0809b25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 510/1000.... Loss: 0.1902 | Accuracy: 0.7118\n",
      "Iterations: 520/1000.... Loss: 0.1885 | Accuracy: 0.7173\n",
      "Iterations: 530/1000.... Loss: 0.1879 | Accuracy: 0.7156\n",
      "Iterations: 540/1000.... Loss: 0.1889 | Accuracy: 0.7169\n",
      "Iterations: 550/1000.... Loss: 0.1881 | Accuracy: 0.7196\n",
      "Iterations: 560/1000.... Loss: 0.1866 | Accuracy: 0.7211\n",
      "Iterations: 570/1000.... Loss: 0.1888 | Accuracy: 0.7161\n",
      "Iterations: 580/1000.... Loss: 0.1874 | Accuracy: 0.7200\n",
      "Iterations: 590/1000.... Loss: 0.1883 | Accuracy: 0.7170\n",
      "Iterations: 600/1000.... Loss: 0.1867 | Accuracy: 0.7215\n",
      "Iterations: 610/1000.... Loss: 0.1883 | Accuracy: 0.7199\n",
      "Iterations: 620/1000.... Loss: 0.1862 | Accuracy: 0.7227\n",
      "Iterations: 630/1000.... Loss: 0.1867 | Accuracy: 0.7197\n",
      "Iterations: 640/1000.... Loss: 0.1860 | Accuracy: 0.7224\n",
      "Iterations: 650/1000.... Loss: 0.1852 | Accuracy: 0.7238\n",
      "Iterations: 660/1000.... Loss: 0.1869 | Accuracy: 0.7217\n",
      "Iterations: 670/1000.... Loss: 0.1854 | Accuracy: 0.7243\n",
      "Iterations: 680/1000.... Loss: 0.1845 | Accuracy: 0.7222\n",
      "Iterations: 690/1000.... Loss: 0.1837 | Accuracy: 0.7253\n",
      "Iterations: 700/1000.... Loss: 0.1826 | Accuracy: 0.7252\n",
      "Iterations: 710/1000.... Loss: 0.1830 | Accuracy: 0.7256\n",
      "Iterations: 720/1000.... Loss: 0.1823 | Accuracy: 0.7304\n",
      "Iterations: 730/1000.... Loss: 0.1819 | Accuracy: 0.7284\n",
      "Iterations: 740/1000.... Loss: 0.1813 | Accuracy: 0.7299\n",
      "Iterations: 750/1000.... Loss: 0.1831 | Accuracy: 0.7263\n",
      "Iterations: 760/1000.... Loss: 0.1813 | Accuracy: 0.7278\n",
      "Iterations: 770/1000.... Loss: 0.1800 | Accuracy: 0.7349\n",
      "Iterations: 780/1000.... Loss: 0.1804 | Accuracy: 0.7323\n",
      "Iterations: 790/1000.... Loss: 0.1807 | Accuracy: 0.7323\n",
      "Iterations: 800/1000.... Loss: 0.1820 | Accuracy: 0.7297\n",
      "Iterations: 810/1000.... Loss: 0.1819 | Accuracy: 0.7313\n",
      "Iterations: 820/1000.... Loss: 0.1809 | Accuracy: 0.7313\n",
      "Iterations: 830/1000.... Loss: 0.1807 | Accuracy: 0.7280\n",
      "Iterations: 840/1000.... Loss: 0.1799 | Accuracy: 0.7336\n",
      "Iterations: 850/1000.... Loss: 0.1800 | Accuracy: 0.7318\n",
      "Iterations: 860/1000.... Loss: 0.1797 | Accuracy: 0.7341\n",
      "Iterations: 870/1000.... Loss: 0.1799 | Accuracy: 0.7322\n",
      "Iterations: 880/1000.... Loss: 0.1806 | Accuracy: 0.7333\n",
      "Iterations: 890/1000.... Loss: 0.1790 | Accuracy: 0.7324\n",
      "Iterations: 900/1000.... Loss: 0.1789 | Accuracy: 0.7362\n",
      "Iterations: 910/1000.... Loss: 0.1815 | Accuracy: 0.7277\n",
      "Iterations: 920/1000.... Loss: 0.1796 | Accuracy: 0.7339\n",
      "Iterations: 930/1000.... Loss: 0.1806 | Accuracy: 0.7332\n",
      "Iterations: 940/1000.... Loss: 0.1798 | Accuracy: 0.7331\n",
      "Iterations: 950/1000.... Loss: 0.1810 | Accuracy: 0.7337\n",
      "Iterations: 960/1000.... Loss: 0.1807 | Accuracy: 0.7302\n",
      "Iterations: 970/1000.... Loss: 0.1817 | Accuracy: 0.7303\n",
      "Iterations: 980/1000.... Loss: 0.1792 | Accuracy: 0.7348\n",
      "Iterations: 990/1000.... Loss: 0.1779 | Accuracy: 0.7383\n",
      "Iterations: 1000/1000.... Loss: 0.1793 | Accuracy: 0.7331\n"
     ]
    }
   ],
   "source": [
    "n_iterations = 1000\n",
    "for iterations in range(501, n_iterations+1):\n",
    "    input_seq,target_seq = generate_seq(batch_size = batch_size, vec_len = vec_len, R = R, T = T)\n",
    "    accuracy,total_loss = train(HebbFF_R6,criterion,optimizer,input_seq,target_seq,T)\n",
    "    if iterations % 10 == 0:\n",
    "        print('Iterations: {}/{}....'.format(iterations, n_iterations), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(total_loss.item()), end=' | ')\n",
    "        print(\"Accuracy: {:.4f}\".format(accuracy.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fc15a322",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 1010/1500.... Loss: 0.1784 | Accuracy: 0.7386\n",
      "Iterations: 1020/1500.... Loss: 0.1784 | Accuracy: 0.7348\n",
      "Iterations: 1030/1500.... Loss: 0.1790 | Accuracy: 0.7332\n",
      "Iterations: 1040/1500.... Loss: 0.1787 | Accuracy: 0.7373\n",
      "Iterations: 1050/1500.... Loss: 0.1802 | Accuracy: 0.7320\n",
      "Iterations: 1060/1500.... Loss: 0.1787 | Accuracy: 0.7392\n",
      "Iterations: 1070/1500.... Loss: 0.1763 | Accuracy: 0.7383\n",
      "Iterations: 1080/1500.... Loss: 0.1799 | Accuracy: 0.7343\n",
      "Iterations: 1090/1500.... Loss: 0.1794 | Accuracy: 0.7358\n",
      "Iterations: 1100/1500.... Loss: 0.1782 | Accuracy: 0.7347\n",
      "Iterations: 1110/1500.... Loss: 0.1770 | Accuracy: 0.7368\n",
      "Iterations: 1120/1500.... Loss: 0.1785 | Accuracy: 0.7339\n",
      "Iterations: 1130/1500.... Loss: 0.1777 | Accuracy: 0.7373\n",
      "Iterations: 1140/1500.... Loss: 0.1775 | Accuracy: 0.7373\n",
      "Iterations: 1150/1500.... Loss: 0.1792 | Accuracy: 0.7345\n",
      "Iterations: 1160/1500.... Loss: 0.1785 | Accuracy: 0.7360\n",
      "Iterations: 1170/1500.... Loss: 0.1783 | Accuracy: 0.7373\n",
      "Iterations: 1180/1500.... Loss: 0.1768 | Accuracy: 0.7389\n",
      "Iterations: 1190/1500.... Loss: 0.1778 | Accuracy: 0.7375\n",
      "Iterations: 1200/1500.... Loss: 0.1795 | Accuracy: 0.7350\n",
      "Iterations: 1210/1500.... Loss: 0.1774 | Accuracy: 0.7388\n",
      "Iterations: 1220/1500.... Loss: 0.1772 | Accuracy: 0.7392\n",
      "Iterations: 1230/1500.... Loss: 0.1794 | Accuracy: 0.7362\n",
      "Iterations: 1240/1500.... Loss: 0.1767 | Accuracy: 0.7385\n",
      "Iterations: 1250/1500.... Loss: 0.1779 | Accuracy: 0.7350\n",
      "Iterations: 1260/1500.... Loss: 0.1782 | Accuracy: 0.7377\n",
      "Iterations: 1270/1500.... Loss: 0.1776 | Accuracy: 0.7418\n",
      "Iterations: 1280/1500.... Loss: 0.1791 | Accuracy: 0.7330\n",
      "Iterations: 1290/1500.... Loss: 0.1780 | Accuracy: 0.7371\n",
      "Iterations: 1300/1500.... Loss: 0.1785 | Accuracy: 0.7333\n",
      "Iterations: 1310/1500.... Loss: 0.1765 | Accuracy: 0.7416\n",
      "Iterations: 1320/1500.... Loss: 0.1777 | Accuracy: 0.7366\n",
      "Iterations: 1330/1500.... Loss: 0.1762 | Accuracy: 0.7418\n",
      "Iterations: 1340/1500.... Loss: 0.1768 | Accuracy: 0.7418\n",
      "Iterations: 1350/1500.... Loss: 0.1763 | Accuracy: 0.7406\n",
      "Iterations: 1360/1500.... Loss: 0.1773 | Accuracy: 0.7384\n",
      "Iterations: 1370/1500.... Loss: 0.1779 | Accuracy: 0.7370\n",
      "Iterations: 1380/1500.... Loss: 0.1777 | Accuracy: 0.7359\n",
      "Iterations: 1390/1500.... Loss: 0.1787 | Accuracy: 0.7360\n",
      "Iterations: 1400/1500.... Loss: 0.1763 | Accuracy: 0.7387\n",
      "Iterations: 1410/1500.... Loss: 0.1744 | Accuracy: 0.7430\n",
      "Iterations: 1420/1500.... Loss: 0.1767 | Accuracy: 0.7391\n",
      "Iterations: 1430/1500.... Loss: 0.1754 | Accuracy: 0.7426\n",
      "Iterations: 1440/1500.... Loss: 0.1763 | Accuracy: 0.7395\n",
      "Iterations: 1450/1500.... Loss: 0.1758 | Accuracy: 0.7412\n",
      "Iterations: 1460/1500.... Loss: 0.1773 | Accuracy: 0.7374\n",
      "Iterations: 1470/1500.... Loss: 0.1772 | Accuracy: 0.7398\n",
      "Iterations: 1480/1500.... Loss: 0.1774 | Accuracy: 0.7378\n",
      "Iterations: 1490/1500.... Loss: 0.1784 | Accuracy: 0.7352\n",
      "Iterations: 1500/1500.... Loss: 0.1761 | Accuracy: 0.7419\n"
     ]
    }
   ],
   "source": [
    "n_iterations = 1500\n",
    "for iterations in range(1001, n_iterations+1):\n",
    "    input_seq,target_seq = generate_seq(batch_size = batch_size, vec_len = vec_len, R = R, T = T)\n",
    "    accuracy,total_loss = train(HebbFF_R6,criterion,optimizer,input_seq,target_seq,T)\n",
    "    if iterations % 10 == 0:\n",
    "        print('Iterations: {}/{}....'.format(iterations, n_iterations), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(total_loss.item()), end=' | ')\n",
    "        print(\"Accuracy: {:.4f}\".format(accuracy.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "22c70c16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 1510/3000.... Loss: 0.1765 | Accuracy: 0.7410\n",
      "Iterations: 1520/3000.... Loss: 0.1767 | Accuracy: 0.7390\n",
      "Iterations: 1530/3000.... Loss: 0.1765 | Accuracy: 0.7412\n",
      "Iterations: 1540/3000.... Loss: 0.1759 | Accuracy: 0.7424\n",
      "Iterations: 1550/3000.... Loss: 0.1772 | Accuracy: 0.7384\n",
      "Iterations: 1560/3000.... Loss: 0.1763 | Accuracy: 0.7390\n",
      "Iterations: 1570/3000.... Loss: 0.1744 | Accuracy: 0.7436\n",
      "Iterations: 1580/3000.... Loss: 0.1765 | Accuracy: 0.7412\n",
      "Iterations: 1590/3000.... Loss: 0.1736 | Accuracy: 0.7460\n",
      "Iterations: 1600/3000.... Loss: 0.1761 | Accuracy: 0.7412\n",
      "Iterations: 1610/3000.... Loss: 0.1755 | Accuracy: 0.7416\n",
      "Iterations: 1620/3000.... Loss: 0.1762 | Accuracy: 0.7374\n",
      "Iterations: 1630/3000.... Loss: 0.1735 | Accuracy: 0.7460\n",
      "Iterations: 1640/3000.... Loss: 0.1757 | Accuracy: 0.7395\n",
      "Iterations: 1650/3000.... Loss: 0.1738 | Accuracy: 0.7473\n",
      "Iterations: 1660/3000.... Loss: 0.1747 | Accuracy: 0.7432\n",
      "Iterations: 1670/3000.... Loss: 0.1746 | Accuracy: 0.7430\n",
      "Iterations: 1680/3000.... Loss: 0.1750 | Accuracy: 0.7431\n",
      "Iterations: 1690/3000.... Loss: 0.1756 | Accuracy: 0.7410\n",
      "Iterations: 1700/3000.... Loss: 0.1739 | Accuracy: 0.7460\n",
      "Iterations: 1710/3000.... Loss: 0.1749 | Accuracy: 0.7437\n",
      "Iterations: 1720/3000.... Loss: 0.1747 | Accuracy: 0.7417\n",
      "Iterations: 1730/3000.... Loss: 0.1742 | Accuracy: 0.7463\n",
      "Iterations: 1740/3000.... Loss: 0.1742 | Accuracy: 0.7458\n",
      "Iterations: 1750/3000.... Loss: 0.1734 | Accuracy: 0.7467\n",
      "Iterations: 1760/3000.... Loss: 0.1750 | Accuracy: 0.7437\n",
      "Iterations: 1770/3000.... Loss: 0.1734 | Accuracy: 0.7448\n",
      "Iterations: 1780/3000.... Loss: 0.1750 | Accuracy: 0.7417\n",
      "Iterations: 1790/3000.... Loss: 0.1749 | Accuracy: 0.7420\n",
      "Iterations: 1800/3000.... Loss: 0.1739 | Accuracy: 0.7461\n",
      "Iterations: 1810/3000.... Loss: 0.1743 | Accuracy: 0.7441\n",
      "Iterations: 1820/3000.... Loss: 0.1748 | Accuracy: 0.7452\n",
      "Iterations: 1830/3000.... Loss: 0.1729 | Accuracy: 0.7484\n",
      "Iterations: 1840/3000.... Loss: 0.1745 | Accuracy: 0.7463\n",
      "Iterations: 1850/3000.... Loss: 0.1741 | Accuracy: 0.7450\n",
      "Iterations: 1860/3000.... Loss: 0.1736 | Accuracy: 0.7463\n",
      "Iterations: 1870/3000.... Loss: 0.1729 | Accuracy: 0.7471\n",
      "Iterations: 1880/3000.... Loss: 0.1723 | Accuracy: 0.7508\n",
      "Iterations: 1890/3000.... Loss: 0.1743 | Accuracy: 0.7450\n",
      "Iterations: 1900/3000.... Loss: 0.1747 | Accuracy: 0.7463\n",
      "Iterations: 1910/3000.... Loss: 0.1730 | Accuracy: 0.7474\n",
      "Iterations: 1920/3000.... Loss: 0.1732 | Accuracy: 0.7484\n",
      "Iterations: 1930/3000.... Loss: 0.1739 | Accuracy: 0.7437\n",
      "Iterations: 1940/3000.... Loss: 0.1741 | Accuracy: 0.7467\n",
      "Iterations: 1950/3000.... Loss: 0.1716 | Accuracy: 0.7505\n",
      "Iterations: 1960/3000.... Loss: 0.1732 | Accuracy: 0.7475\n",
      "Iterations: 1970/3000.... Loss: 0.1727 | Accuracy: 0.7476\n",
      "Iterations: 1980/3000.... Loss: 0.1737 | Accuracy: 0.7451\n",
      "Iterations: 1990/3000.... Loss: 0.1747 | Accuracy: 0.7435\n",
      "Iterations: 2000/3000.... Loss: 0.1728 | Accuracy: 0.7482\n",
      "Iterations: 2010/3000.... Loss: 0.1717 | Accuracy: 0.7497\n",
      "Iterations: 2020/3000.... Loss: 0.1736 | Accuracy: 0.7487\n",
      "Iterations: 2030/3000.... Loss: 0.1729 | Accuracy: 0.7464\n",
      "Iterations: 2040/3000.... Loss: 0.1725 | Accuracy: 0.7474\n",
      "Iterations: 2050/3000.... Loss: 0.1720 | Accuracy: 0.7487\n",
      "Iterations: 2060/3000.... Loss: 0.1719 | Accuracy: 0.7523\n",
      "Iterations: 2070/3000.... Loss: 0.1710 | Accuracy: 0.7525\n",
      "Iterations: 2080/3000.... Loss: 0.1719 | Accuracy: 0.7490\n",
      "Iterations: 2090/3000.... Loss: 0.1726 | Accuracy: 0.7491\n",
      "Iterations: 2100/3000.... Loss: 0.1707 | Accuracy: 0.7523\n",
      "Iterations: 2110/3000.... Loss: 0.1731 | Accuracy: 0.7461\n",
      "Iterations: 2120/3000.... Loss: 0.1719 | Accuracy: 0.7511\n",
      "Iterations: 2130/3000.... Loss: 0.1699 | Accuracy: 0.7533\n",
      "Iterations: 2140/3000.... Loss: 0.1720 | Accuracy: 0.7496\n",
      "Iterations: 2150/3000.... Loss: 0.1712 | Accuracy: 0.7522\n",
      "Iterations: 2160/3000.... Loss: 0.1712 | Accuracy: 0.7513\n",
      "Iterations: 2170/3000.... Loss: 0.1730 | Accuracy: 0.7477\n",
      "Iterations: 2180/3000.... Loss: 0.1705 | Accuracy: 0.7533\n",
      "Iterations: 2190/3000.... Loss: 0.1711 | Accuracy: 0.7506\n",
      "Iterations: 2200/3000.... Loss: 0.1712 | Accuracy: 0.7533\n",
      "Iterations: 2210/3000.... Loss: 0.1719 | Accuracy: 0.7495\n",
      "Iterations: 2220/3000.... Loss: 0.1716 | Accuracy: 0.7498\n",
      "Iterations: 2230/3000.... Loss: 0.1714 | Accuracy: 0.7511\n",
      "Iterations: 2240/3000.... Loss: 0.1702 | Accuracy: 0.7513\n",
      "Iterations: 2250/3000.... Loss: 0.1700 | Accuracy: 0.7550\n",
      "Iterations: 2260/3000.... Loss: 0.1693 | Accuracy: 0.7548\n",
      "Iterations: 2270/3000.... Loss: 0.1697 | Accuracy: 0.7556\n",
      "Iterations: 2280/3000.... Loss: 0.1702 | Accuracy: 0.7542\n",
      "Iterations: 2290/3000.... Loss: 0.1694 | Accuracy: 0.7548\n",
      "Iterations: 2300/3000.... Loss: 0.1688 | Accuracy: 0.7591\n",
      "Iterations: 2310/3000.... Loss: 0.1696 | Accuracy: 0.7556\n",
      "Iterations: 2320/3000.... Loss: 0.1702 | Accuracy: 0.7541\n",
      "Iterations: 2330/3000.... Loss: 0.1703 | Accuracy: 0.7527\n",
      "Iterations: 2340/3000.... Loss: 0.1689 | Accuracy: 0.7562\n",
      "Iterations: 2350/3000.... Loss: 0.1686 | Accuracy: 0.7550\n",
      "Iterations: 2360/3000.... Loss: 0.1690 | Accuracy: 0.7570\n",
      "Iterations: 2370/3000.... Loss: 0.1683 | Accuracy: 0.7590\n",
      "Iterations: 2380/3000.... Loss: 0.1693 | Accuracy: 0.7549\n",
      "Iterations: 2390/3000.... Loss: 0.1691 | Accuracy: 0.7555\n",
      "Iterations: 2400/3000.... Loss: 0.1683 | Accuracy: 0.7609\n",
      "Iterations: 2410/3000.... Loss: 0.1692 | Accuracy: 0.7547\n",
      "Iterations: 2420/3000.... Loss: 0.1674 | Accuracy: 0.7604\n",
      "Iterations: 2430/3000.... Loss: 0.1673 | Accuracy: 0.7600\n",
      "Iterations: 2440/3000.... Loss: 0.1666 | Accuracy: 0.7642\n",
      "Iterations: 2450/3000.... Loss: 0.1696 | Accuracy: 0.7552\n",
      "Iterations: 2460/3000.... Loss: 0.1689 | Accuracy: 0.7563\n",
      "Iterations: 2470/3000.... Loss: 0.1685 | Accuracy: 0.7587\n",
      "Iterations: 2480/3000.... Loss: 0.1678 | Accuracy: 0.7576\n",
      "Iterations: 2490/3000.... Loss: 0.1679 | Accuracy: 0.7591\n",
      "Iterations: 2500/3000.... Loss: 0.1692 | Accuracy: 0.7572\n",
      "Iterations: 2510/3000.... Loss: 0.1677 | Accuracy: 0.7573\n",
      "Iterations: 2520/3000.... Loss: 0.1660 | Accuracy: 0.7645\n",
      "Iterations: 2530/3000.... Loss: 0.1676 | Accuracy: 0.7579\n",
      "Iterations: 2540/3000.... Loss: 0.1661 | Accuracy: 0.7638\n",
      "Iterations: 2550/3000.... Loss: 0.1667 | Accuracy: 0.7642\n",
      "Iterations: 2560/3000.... Loss: 0.1669 | Accuracy: 0.7601\n",
      "Iterations: 2570/3000.... Loss: 0.1658 | Accuracy: 0.7627\n",
      "Iterations: 2580/3000.... Loss: 0.1672 | Accuracy: 0.7614\n",
      "Iterations: 2590/3000.... Loss: 0.1660 | Accuracy: 0.7623\n",
      "Iterations: 2600/3000.... Loss: 0.1670 | Accuracy: 0.7595\n",
      "Iterations: 2610/3000.... Loss: 0.1677 | Accuracy: 0.7581\n",
      "Iterations: 2620/3000.... Loss: 0.1674 | Accuracy: 0.7585\n",
      "Iterations: 2630/3000.... Loss: 0.1659 | Accuracy: 0.7629\n",
      "Iterations: 2640/3000.... Loss: 0.1656 | Accuracy: 0.7642\n",
      "Iterations: 2650/3000.... Loss: 0.1656 | Accuracy: 0.7632\n",
      "Iterations: 2660/3000.... Loss: 0.1653 | Accuracy: 0.7644\n",
      "Iterations: 2670/3000.... Loss: 0.1657 | Accuracy: 0.7620\n",
      "Iterations: 2680/3000.... Loss: 0.1645 | Accuracy: 0.7659\n",
      "Iterations: 2690/3000.... Loss: 0.1638 | Accuracy: 0.7681\n",
      "Iterations: 2700/3000.... Loss: 0.1648 | Accuracy: 0.7666\n",
      "Iterations: 2710/3000.... Loss: 0.1658 | Accuracy: 0.7638\n",
      "Iterations: 2720/3000.... Loss: 0.1653 | Accuracy: 0.7661\n",
      "Iterations: 2730/3000.... Loss: 0.1663 | Accuracy: 0.7636\n",
      "Iterations: 2740/3000.... Loss: 0.1630 | Accuracy: 0.7711\n",
      "Iterations: 2750/3000.... Loss: 0.1630 | Accuracy: 0.7700\n",
      "Iterations: 2760/3000.... Loss: 0.1651 | Accuracy: 0.7649\n",
      "Iterations: 2770/3000.... Loss: 0.1649 | Accuracy: 0.7646\n",
      "Iterations: 2780/3000.... Loss: 0.1643 | Accuracy: 0.7663\n",
      "Iterations: 2790/3000.... Loss: 0.1642 | Accuracy: 0.7650\n",
      "Iterations: 2800/3000.... Loss: 0.1643 | Accuracy: 0.7688\n",
      "Iterations: 2810/3000.... Loss: 0.1652 | Accuracy: 0.7669\n",
      "Iterations: 2820/3000.... Loss: 0.1639 | Accuracy: 0.7678\n",
      "Iterations: 2830/3000.... Loss: 0.1645 | Accuracy: 0.7680\n",
      "Iterations: 2840/3000.... Loss: 0.1643 | Accuracy: 0.7690\n",
      "Iterations: 2850/3000.... Loss: 0.1636 | Accuracy: 0.7695\n",
      "Iterations: 2860/3000.... Loss: 0.1619 | Accuracy: 0.7764\n",
      "Iterations: 2870/3000.... Loss: 0.1626 | Accuracy: 0.7701\n",
      "Iterations: 2880/3000.... Loss: 0.1636 | Accuracy: 0.7677\n",
      "Iterations: 2890/3000.... Loss: 0.1644 | Accuracy: 0.7666\n",
      "Iterations: 2900/3000.... Loss: 0.1633 | Accuracy: 0.7712\n",
      "Iterations: 2910/3000.... Loss: 0.1616 | Accuracy: 0.7739\n",
      "Iterations: 2920/3000.... Loss: 0.1618 | Accuracy: 0.7723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 2930/3000.... Loss: 0.1624 | Accuracy: 0.7733\n",
      "Iterations: 2940/3000.... Loss: 0.1627 | Accuracy: 0.7713\n",
      "Iterations: 2950/3000.... Loss: 0.1638 | Accuracy: 0.7688\n",
      "Iterations: 2960/3000.... Loss: 0.1621 | Accuracy: 0.7725\n",
      "Iterations: 2970/3000.... Loss: 0.1629 | Accuracy: 0.7710\n",
      "Iterations: 2980/3000.... Loss: 0.1626 | Accuracy: 0.7715\n",
      "Iterations: 2990/3000.... Loss: 0.1628 | Accuracy: 0.7688\n",
      "Iterations: 3000/3000.... Loss: 0.1609 | Accuracy: 0.7749\n"
     ]
    }
   ],
   "source": [
    "n_iterations = 3000\n",
    "for iterations in range(1501, n_iterations+1):\n",
    "    input_seq,target_seq = generate_seq(batch_size = batch_size, vec_len = vec_len, R = R, T = T)\n",
    "    accuracy,total_loss = train(HebbFF_R6,criterion,optimizer,input_seq,target_seq,T)\n",
    "    if iterations % 10 == 0:\n",
    "        print('Iterations: {}/{}....'.format(iterations, n_iterations), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(total_loss.item()), end=' | ')\n",
    "        print(\"Accuracy: {:.4f}\".format(accuracy.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6eb4677d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 3010/5000.... Loss: 0.1609 | Accuracy: 0.7753\n",
      "Iterations: 3020/5000.... Loss: 0.1621 | Accuracy: 0.7737\n",
      "Iterations: 3030/5000.... Loss: 0.1624 | Accuracy: 0.7724\n",
      "Iterations: 3040/5000.... Loss: 0.1612 | Accuracy: 0.7750\n",
      "Iterations: 3050/5000.... Loss: 0.1611 | Accuracy: 0.7758\n",
      "Iterations: 3060/5000.... Loss: 0.1608 | Accuracy: 0.7742\n",
      "Iterations: 3070/5000.... Loss: 0.1616 | Accuracy: 0.7753\n",
      "Iterations: 3080/5000.... Loss: 0.1606 | Accuracy: 0.7731\n",
      "Iterations: 3090/5000.... Loss: 0.1611 | Accuracy: 0.7737\n",
      "Iterations: 3100/5000.... Loss: 0.1604 | Accuracy: 0.7763\n",
      "Iterations: 3110/5000.... Loss: 0.1609 | Accuracy: 0.7738\n",
      "Iterations: 3120/5000.... Loss: 0.1620 | Accuracy: 0.7730\n",
      "Iterations: 3130/5000.... Loss: 0.1604 | Accuracy: 0.7745\n",
      "Iterations: 3140/5000.... Loss: 0.1623 | Accuracy: 0.7715\n",
      "Iterations: 3150/5000.... Loss: 0.1596 | Accuracy: 0.7765\n",
      "Iterations: 3160/5000.... Loss: 0.1600 | Accuracy: 0.7786\n",
      "Iterations: 3170/5000.... Loss: 0.1594 | Accuracy: 0.7801\n",
      "Iterations: 3180/5000.... Loss: 0.1589 | Accuracy: 0.7791\n",
      "Iterations: 3190/5000.... Loss: 0.1601 | Accuracy: 0.7770\n",
      "Iterations: 3200/5000.... Loss: 0.1593 | Accuracy: 0.7774\n",
      "Iterations: 3210/5000.... Loss: 0.1585 | Accuracy: 0.7794\n",
      "Iterations: 3220/5000.... Loss: 0.1603 | Accuracy: 0.7759\n",
      "Iterations: 3230/5000.... Loss: 0.1603 | Accuracy: 0.7759\n",
      "Iterations: 3240/5000.... Loss: 0.1592 | Accuracy: 0.7797\n",
      "Iterations: 3250/5000.... Loss: 0.1588 | Accuracy: 0.7791\n",
      "Iterations: 3260/5000.... Loss: 0.1575 | Accuracy: 0.7814\n",
      "Iterations: 3270/5000.... Loss: 0.1581 | Accuracy: 0.7813\n",
      "Iterations: 3280/5000.... Loss: 0.1595 | Accuracy: 0.7768\n",
      "Iterations: 3290/5000.... Loss: 0.1596 | Accuracy: 0.7780\n",
      "Iterations: 3300/5000.... Loss: 0.1585 | Accuracy: 0.7788\n",
      "Iterations: 3310/5000.... Loss: 0.1586 | Accuracy: 0.7761\n",
      "Iterations: 3320/5000.... Loss: 0.1584 | Accuracy: 0.7790\n",
      "Iterations: 3330/5000.... Loss: 0.1591 | Accuracy: 0.7784\n",
      "Iterations: 3340/5000.... Loss: 0.1605 | Accuracy: 0.7763\n",
      "Iterations: 3350/5000.... Loss: 0.1577 | Accuracy: 0.7820\n",
      "Iterations: 3360/5000.... Loss: 0.1558 | Accuracy: 0.7883\n",
      "Iterations: 3370/5000.... Loss: 0.1581 | Accuracy: 0.7799\n",
      "Iterations: 3380/5000.... Loss: 0.1576 | Accuracy: 0.7789\n",
      "Iterations: 3390/5000.... Loss: 0.1580 | Accuracy: 0.7800\n",
      "Iterations: 3400/5000.... Loss: 0.1578 | Accuracy: 0.7804\n",
      "Iterations: 3410/5000.... Loss: 0.1558 | Accuracy: 0.7864\n",
      "Iterations: 3420/5000.... Loss: 0.1581 | Accuracy: 0.7803\n",
      "Iterations: 3430/5000.... Loss: 0.1573 | Accuracy: 0.7828\n",
      "Iterations: 3440/5000.... Loss: 0.1566 | Accuracy: 0.7857\n",
      "Iterations: 3450/5000.... Loss: 0.1568 | Accuracy: 0.7847\n",
      "Iterations: 3460/5000.... Loss: 0.1564 | Accuracy: 0.7819\n",
      "Iterations: 3470/5000.... Loss: 0.1567 | Accuracy: 0.7812\n",
      "Iterations: 3480/5000.... Loss: 0.1568 | Accuracy: 0.7835\n",
      "Iterations: 3490/5000.... Loss: 0.1562 | Accuracy: 0.7844\n",
      "Iterations: 3500/5000.... Loss: 0.1560 | Accuracy: 0.7839\n",
      "Iterations: 3510/5000.... Loss: 0.1553 | Accuracy: 0.7847\n",
      "Iterations: 3520/5000.... Loss: 0.1560 | Accuracy: 0.7847\n",
      "Iterations: 3530/5000.... Loss: 0.1560 | Accuracy: 0.7843\n",
      "Iterations: 3540/5000.... Loss: 0.1556 | Accuracy: 0.7849\n",
      "Iterations: 3550/5000.... Loss: 0.1549 | Accuracy: 0.7847\n",
      "Iterations: 3560/5000.... Loss: 0.1543 | Accuracy: 0.7882\n",
      "Iterations: 3570/5000.... Loss: 0.1548 | Accuracy: 0.7866\n",
      "Iterations: 3580/5000.... Loss: 0.1540 | Accuracy: 0.7889\n",
      "Iterations: 3590/5000.... Loss: 0.1548 | Accuracy: 0.7857\n",
      "Iterations: 3600/5000.... Loss: 0.1551 | Accuracy: 0.7830\n",
      "Iterations: 3610/5000.... Loss: 0.1536 | Accuracy: 0.7905\n",
      "Iterations: 3620/5000.... Loss: 0.1541 | Accuracy: 0.7888\n",
      "Iterations: 3630/5000.... Loss: 0.1542 | Accuracy: 0.7900\n",
      "Iterations: 3640/5000.... Loss: 0.1534 | Accuracy: 0.7873\n",
      "Iterations: 3650/5000.... Loss: 0.1541 | Accuracy: 0.7866\n",
      "Iterations: 3660/5000.... Loss: 0.1538 | Accuracy: 0.7892\n",
      "Iterations: 3670/5000.... Loss: 0.1528 | Accuracy: 0.7901\n",
      "Iterations: 3680/5000.... Loss: 0.1538 | Accuracy: 0.7859\n",
      "Iterations: 3690/5000.... Loss: 0.1546 | Accuracy: 0.7857\n",
      "Iterations: 3700/5000.... Loss: 0.1521 | Accuracy: 0.7916\n",
      "Iterations: 3710/5000.... Loss: 0.1529 | Accuracy: 0.7912\n",
      "Iterations: 3720/5000.... Loss: 0.1532 | Accuracy: 0.7888\n",
      "Iterations: 3730/5000.... Loss: 0.1532 | Accuracy: 0.7935\n",
      "Iterations: 3740/5000.... Loss: 0.1522 | Accuracy: 0.7928\n",
      "Iterations: 3750/5000.... Loss: 0.1530 | Accuracy: 0.7899\n",
      "Iterations: 3760/5000.... Loss: 0.1514 | Accuracy: 0.7947\n",
      "Iterations: 3770/5000.... Loss: 0.1518 | Accuracy: 0.7933\n",
      "Iterations: 3780/5000.... Loss: 0.1518 | Accuracy: 0.7918\n",
      "Iterations: 3790/5000.... Loss: 0.1520 | Accuracy: 0.7911\n",
      "Iterations: 3800/5000.... Loss: 0.1509 | Accuracy: 0.7952\n",
      "Iterations: 3810/5000.... Loss: 0.1509 | Accuracy: 0.7929\n",
      "Iterations: 3820/5000.... Loss: 0.1525 | Accuracy: 0.7896\n",
      "Iterations: 3830/5000.... Loss: 0.1511 | Accuracy: 0.7937\n",
      "Iterations: 3840/5000.... Loss: 0.1509 | Accuracy: 0.7930\n",
      "Iterations: 3850/5000.... Loss: 0.1509 | Accuracy: 0.7937\n",
      "Iterations: 3860/5000.... Loss: 0.1502 | Accuracy: 0.7952\n",
      "Iterations: 3870/5000.... Loss: 0.1509 | Accuracy: 0.7937\n",
      "Iterations: 3880/5000.... Loss: 0.1501 | Accuracy: 0.7948\n",
      "Iterations: 3890/5000.... Loss: 0.1516 | Accuracy: 0.7937\n",
      "Iterations: 3900/5000.... Loss: 0.1495 | Accuracy: 0.7958\n",
      "Iterations: 3910/5000.... Loss: 0.1510 | Accuracy: 0.7953\n",
      "Iterations: 3920/5000.... Loss: 0.1489 | Accuracy: 0.8008\n",
      "Iterations: 3930/5000.... Loss: 0.1489 | Accuracy: 0.7974\n",
      "Iterations: 3940/5000.... Loss: 0.1493 | Accuracy: 0.7974\n",
      "Iterations: 3950/5000.... Loss: 0.1494 | Accuracy: 0.7974\n",
      "Iterations: 3960/5000.... Loss: 0.1484 | Accuracy: 0.7989\n",
      "Iterations: 3970/5000.... Loss: 0.1482 | Accuracy: 0.8007\n",
      "Iterations: 3980/5000.... Loss: 0.1493 | Accuracy: 0.7970\n",
      "Iterations: 3990/5000.... Loss: 0.1482 | Accuracy: 0.7999\n",
      "Iterations: 4000/5000.... Loss: 0.1489 | Accuracy: 0.7975\n",
      "Iterations: 4010/5000.... Loss: 0.1495 | Accuracy: 0.7965\n",
      "Iterations: 4020/5000.... Loss: 0.1469 | Accuracy: 0.8022\n",
      "Iterations: 4030/5000.... Loss: 0.1477 | Accuracy: 0.7975\n",
      "Iterations: 4040/5000.... Loss: 0.1483 | Accuracy: 0.7973\n",
      "Iterations: 4050/5000.... Loss: 0.1472 | Accuracy: 0.8011\n",
      "Iterations: 4060/5000.... Loss: 0.1480 | Accuracy: 0.7974\n",
      "Iterations: 4070/5000.... Loss: 0.1466 | Accuracy: 0.8024\n",
      "Iterations: 4080/5000.... Loss: 0.1462 | Accuracy: 0.8037\n",
      "Iterations: 4090/5000.... Loss: 0.1470 | Accuracy: 0.7986\n",
      "Iterations: 4100/5000.... Loss: 0.1460 | Accuracy: 0.8043\n",
      "Iterations: 4110/5000.... Loss: 0.1462 | Accuracy: 0.8016\n",
      "Iterations: 4120/5000.... Loss: 0.1461 | Accuracy: 0.8032\n",
      "Iterations: 4130/5000.... Loss: 0.1460 | Accuracy: 0.8040\n",
      "Iterations: 4140/5000.... Loss: 0.1446 | Accuracy: 0.8042\n",
      "Iterations: 4150/5000.... Loss: 0.1447 | Accuracy: 0.8058\n",
      "Iterations: 4160/5000.... Loss: 0.1456 | Accuracy: 0.8048\n",
      "Iterations: 4170/5000.... Loss: 0.1442 | Accuracy: 0.8067\n",
      "Iterations: 4180/5000.... Loss: 0.1453 | Accuracy: 0.8053\n",
      "Iterations: 4190/5000.... Loss: 0.1455 | Accuracy: 0.8027\n",
      "Iterations: 4200/5000.... Loss: 0.1450 | Accuracy: 0.8028\n",
      "Iterations: 4210/5000.... Loss: 0.1444 | Accuracy: 0.8062\n",
      "Iterations: 4220/5000.... Loss: 0.1451 | Accuracy: 0.8019\n",
      "Iterations: 4230/5000.... Loss: 0.1448 | Accuracy: 0.8042\n",
      "Iterations: 4240/5000.... Loss: 0.1440 | Accuracy: 0.8080\n",
      "Iterations: 4250/5000.... Loss: 0.1467 | Accuracy: 0.8007\n",
      "Iterations: 4260/5000.... Loss: 0.1452 | Accuracy: 0.8020\n",
      "Iterations: 4270/5000.... Loss: 0.1441 | Accuracy: 0.8050\n",
      "Iterations: 4280/5000.... Loss: 0.1440 | Accuracy: 0.8060\n",
      "Iterations: 4290/5000.... Loss: 0.1452 | Accuracy: 0.8027\n",
      "Iterations: 4300/5000.... Loss: 0.1433 | Accuracy: 0.8068\n",
      "Iterations: 4310/5000.... Loss: 0.1431 | Accuracy: 0.8068\n",
      "Iterations: 4320/5000.... Loss: 0.1433 | Accuracy: 0.8080\n",
      "Iterations: 4330/5000.... Loss: 0.1431 | Accuracy: 0.8071\n",
      "Iterations: 4340/5000.... Loss: 0.1420 | Accuracy: 0.8076\n",
      "Iterations: 4350/5000.... Loss: 0.1420 | Accuracy: 0.8119\n",
      "Iterations: 4360/5000.... Loss: 0.1423 | Accuracy: 0.8073\n",
      "Iterations: 4370/5000.... Loss: 0.1419 | Accuracy: 0.8085\n",
      "Iterations: 4380/5000.... Loss: 0.1426 | Accuracy: 0.8095\n",
      "Iterations: 4390/5000.... Loss: 0.1424 | Accuracy: 0.8064\n",
      "Iterations: 4400/5000.... Loss: 0.1409 | Accuracy: 0.8134\n",
      "Iterations: 4410/5000.... Loss: 0.1423 | Accuracy: 0.8096\n",
      "Iterations: 4420/5000.... Loss: 0.1408 | Accuracy: 0.8099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 4430/5000.... Loss: 0.1402 | Accuracy: 0.8130\n",
      "Iterations: 4440/5000.... Loss: 0.1400 | Accuracy: 0.8112\n",
      "Iterations: 4450/5000.... Loss: 0.1412 | Accuracy: 0.8116\n",
      "Iterations: 4460/5000.... Loss: 0.1403 | Accuracy: 0.8108\n",
      "Iterations: 4470/5000.... Loss: 0.1402 | Accuracy: 0.8100\n",
      "Iterations: 4480/5000.... Loss: 0.1405 | Accuracy: 0.8113\n",
      "Iterations: 4490/5000.... Loss: 0.1405 | Accuracy: 0.8115\n",
      "Iterations: 4500/5000.... Loss: 0.1384 | Accuracy: 0.8155\n",
      "Iterations: 4510/5000.... Loss: 0.1398 | Accuracy: 0.8118\n",
      "Iterations: 4520/5000.... Loss: 0.1378 | Accuracy: 0.8157\n",
      "Iterations: 4530/5000.... Loss: 0.1396 | Accuracy: 0.8142\n",
      "Iterations: 4540/5000.... Loss: 0.1395 | Accuracy: 0.8127\n",
      "Iterations: 4550/5000.... Loss: 0.1402 | Accuracy: 0.8129\n",
      "Iterations: 4560/5000.... Loss: 0.1375 | Accuracy: 0.8167\n",
      "Iterations: 4570/5000.... Loss: 0.1390 | Accuracy: 0.8131\n",
      "Iterations: 4580/5000.... Loss: 0.1379 | Accuracy: 0.8179\n",
      "Iterations: 4590/5000.... Loss: 0.1377 | Accuracy: 0.8151\n",
      "Iterations: 4600/5000.... Loss: 0.1372 | Accuracy: 0.8195\n",
      "Iterations: 4610/5000.... Loss: 0.1371 | Accuracy: 0.8174\n",
      "Iterations: 4620/5000.... Loss: 0.1382 | Accuracy: 0.8141\n",
      "Iterations: 4630/5000.... Loss: 0.1377 | Accuracy: 0.8153\n",
      "Iterations: 4640/5000.... Loss: 0.1387 | Accuracy: 0.8120\n",
      "Iterations: 4650/5000.... Loss: 0.1362 | Accuracy: 0.8188\n",
      "Iterations: 4660/5000.... Loss: 0.1370 | Accuracy: 0.8165\n",
      "Iterations: 4670/5000.... Loss: 0.1372 | Accuracy: 0.8171\n",
      "Iterations: 4680/5000.... Loss: 0.1366 | Accuracy: 0.8166\n",
      "Iterations: 4690/5000.... Loss: 0.1373 | Accuracy: 0.8152\n",
      "Iterations: 4700/5000.... Loss: 0.1345 | Accuracy: 0.8225\n",
      "Iterations: 4710/5000.... Loss: 0.1358 | Accuracy: 0.8173\n",
      "Iterations: 4720/5000.... Loss: 0.1340 | Accuracy: 0.8238\n",
      "Iterations: 4730/5000.... Loss: 0.1367 | Accuracy: 0.8170\n",
      "Iterations: 4740/5000.... Loss: 0.1359 | Accuracy: 0.8185\n",
      "Iterations: 4750/5000.... Loss: 0.1352 | Accuracy: 0.8181\n",
      "Iterations: 4760/5000.... Loss: 0.1350 | Accuracy: 0.8206\n",
      "Iterations: 4770/5000.... Loss: 0.1339 | Accuracy: 0.8232\n",
      "Iterations: 4780/5000.... Loss: 0.1354 | Accuracy: 0.8196\n",
      "Iterations: 4790/5000.... Loss: 0.1350 | Accuracy: 0.8192\n",
      "Iterations: 4800/5000.... Loss: 0.1350 | Accuracy: 0.8198\n",
      "Iterations: 4810/5000.... Loss: 0.1342 | Accuracy: 0.8212\n",
      "Iterations: 4820/5000.... Loss: 0.1343 | Accuracy: 0.8216\n",
      "Iterations: 4830/5000.... Loss: 0.1347 | Accuracy: 0.8198\n",
      "Iterations: 4840/5000.... Loss: 0.1339 | Accuracy: 0.8221\n",
      "Iterations: 4850/5000.... Loss: 0.1335 | Accuracy: 0.8213\n",
      "Iterations: 4860/5000.... Loss: 0.1331 | Accuracy: 0.8228\n",
      "Iterations: 4870/5000.... Loss: 0.1336 | Accuracy: 0.8237\n",
      "Iterations: 4880/5000.... Loss: 0.1324 | Accuracy: 0.8250\n",
      "Iterations: 4890/5000.... Loss: 0.1334 | Accuracy: 0.8212\n",
      "Iterations: 4900/5000.... Loss: 0.1332 | Accuracy: 0.8253\n",
      "Iterations: 4910/5000.... Loss: 0.1323 | Accuracy: 0.8239\n",
      "Iterations: 4920/5000.... Loss: 0.1327 | Accuracy: 0.8232\n",
      "Iterations: 4930/5000.... Loss: 0.1321 | Accuracy: 0.8258\n",
      "Iterations: 4940/5000.... Loss: 0.1322 | Accuracy: 0.8218\n",
      "Iterations: 4950/5000.... Loss: 0.1320 | Accuracy: 0.8247\n",
      "Iterations: 4960/5000.... Loss: 0.1321 | Accuracy: 0.8271\n",
      "Iterations: 4970/5000.... Loss: 0.1317 | Accuracy: 0.8247\n",
      "Iterations: 4980/5000.... Loss: 0.1302 | Accuracy: 0.8293\n",
      "Iterations: 4990/5000.... Loss: 0.1309 | Accuracy: 0.8272\n",
      "Iterations: 5000/5000.... Loss: 0.1306 | Accuracy: 0.8263\n"
     ]
    }
   ],
   "source": [
    "n_iterations = 5000\n",
    "for iterations in range(3001, n_iterations+1):\n",
    "    input_seq,target_seq = generate_seq(batch_size = batch_size, vec_len = vec_len, R = R, T = T)\n",
    "    accuracy,total_loss = train(HebbFF_R6,criterion,optimizer,input_seq,target_seq,T)\n",
    "    if iterations % 10 == 0:\n",
    "        print('Iterations: {}/{}....'.format(iterations, n_iterations), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(total_loss.item()), end=' | ')\n",
    "        print(\"Accuracy: {:.4f}\".format(accuracy.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f93472e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 5010/10000.... Loss: 0.1315 | Accuracy: 0.8241\n",
      "Iterations: 5020/10000.... Loss: 0.1300 | Accuracy: 0.8275\n",
      "Iterations: 5030/10000.... Loss: 0.1311 | Accuracy: 0.8263\n",
      "Iterations: 5040/10000.... Loss: 0.1294 | Accuracy: 0.8305\n",
      "Iterations: 5050/10000.... Loss: 0.1300 | Accuracy: 0.8270\n",
      "Iterations: 5060/10000.... Loss: 0.1292 | Accuracy: 0.8330\n",
      "Iterations: 5070/10000.... Loss: 0.1301 | Accuracy: 0.8283\n",
      "Iterations: 5080/10000.... Loss: 0.1292 | Accuracy: 0.8305\n",
      "Iterations: 5090/10000.... Loss: 0.1292 | Accuracy: 0.8295\n",
      "Iterations: 5100/10000.... Loss: 0.1280 | Accuracy: 0.8316\n",
      "Iterations: 5110/10000.... Loss: 0.1294 | Accuracy: 0.8299\n",
      "Iterations: 5120/10000.... Loss: 0.1301 | Accuracy: 0.8278\n",
      "Iterations: 5130/10000.... Loss: 0.1277 | Accuracy: 0.8335\n",
      "Iterations: 5140/10000.... Loss: 0.1292 | Accuracy: 0.8307\n",
      "Iterations: 5150/10000.... Loss: 0.1279 | Accuracy: 0.8313\n",
      "Iterations: 5160/10000.... Loss: 0.1276 | Accuracy: 0.8305\n",
      "Iterations: 5170/10000.... Loss: 0.1285 | Accuracy: 0.8294\n",
      "Iterations: 5180/10000.... Loss: 0.1293 | Accuracy: 0.8297\n",
      "Iterations: 5190/10000.... Loss: 0.1288 | Accuracy: 0.8302\n",
      "Iterations: 5200/10000.... Loss: 0.1275 | Accuracy: 0.8314\n",
      "Iterations: 5210/10000.... Loss: 0.1272 | Accuracy: 0.8324\n",
      "Iterations: 5220/10000.... Loss: 0.1274 | Accuracy: 0.8312\n",
      "Iterations: 5230/10000.... Loss: 0.1264 | Accuracy: 0.8326\n",
      "Iterations: 5240/10000.... Loss: 0.1277 | Accuracy: 0.8307\n",
      "Iterations: 5250/10000.... Loss: 0.1263 | Accuracy: 0.8342\n",
      "Iterations: 5260/10000.... Loss: 0.1264 | Accuracy: 0.8337\n",
      "Iterations: 5270/10000.... Loss: 0.1257 | Accuracy: 0.8358\n",
      "Iterations: 5280/10000.... Loss: 0.1273 | Accuracy: 0.8319\n",
      "Iterations: 5290/10000.... Loss: 0.1250 | Accuracy: 0.8366\n",
      "Iterations: 5300/10000.... Loss: 0.1262 | Accuracy: 0.8349\n",
      "Iterations: 5310/10000.... Loss: 0.1267 | Accuracy: 0.8329\n",
      "Iterations: 5320/10000.... Loss: 0.1246 | Accuracy: 0.8379\n",
      "Iterations: 5330/10000.... Loss: 0.1237 | Accuracy: 0.8389\n",
      "Iterations: 5340/10000.... Loss: 0.1234 | Accuracy: 0.8394\n",
      "Iterations: 5350/10000.... Loss: 0.1235 | Accuracy: 0.8373\n",
      "Iterations: 5360/10000.... Loss: 0.1258 | Accuracy: 0.8322\n",
      "Iterations: 5370/10000.... Loss: 0.1249 | Accuracy: 0.8357\n",
      "Iterations: 5380/10000.... Loss: 0.1254 | Accuracy: 0.8362\n",
      "Iterations: 5390/10000.... Loss: 0.1233 | Accuracy: 0.8382\n",
      "Iterations: 5400/10000.... Loss: 0.1254 | Accuracy: 0.8342\n",
      "Iterations: 5410/10000.... Loss: 0.1229 | Accuracy: 0.8403\n",
      "Iterations: 5420/10000.... Loss: 0.1248 | Accuracy: 0.8358\n",
      "Iterations: 5430/10000.... Loss: 0.1230 | Accuracy: 0.8405\n",
      "Iterations: 5440/10000.... Loss: 0.1240 | Accuracy: 0.8359\n",
      "Iterations: 5450/10000.... Loss: 0.1217 | Accuracy: 0.8422\n",
      "Iterations: 5460/10000.... Loss: 0.1230 | Accuracy: 0.8374\n",
      "Iterations: 5470/10000.... Loss: 0.1225 | Accuracy: 0.8401\n",
      "Iterations: 5480/10000.... Loss: 0.1220 | Accuracy: 0.8411\n",
      "Iterations: 5490/10000.... Loss: 0.1230 | Accuracy: 0.8371\n",
      "Iterations: 5500/10000.... Loss: 0.1216 | Accuracy: 0.8420\n",
      "Iterations: 5510/10000.... Loss: 0.1226 | Accuracy: 0.8379\n",
      "Iterations: 5520/10000.... Loss: 0.1209 | Accuracy: 0.8461\n",
      "Iterations: 5530/10000.... Loss: 0.1210 | Accuracy: 0.8425\n",
      "Iterations: 5540/10000.... Loss: 0.1213 | Accuracy: 0.8442\n",
      "Iterations: 5550/10000.... Loss: 0.1224 | Accuracy: 0.8388\n",
      "Iterations: 5560/10000.... Loss: 0.1213 | Accuracy: 0.8441\n",
      "Iterations: 5570/10000.... Loss: 0.1206 | Accuracy: 0.8441\n",
      "Iterations: 5580/10000.... Loss: 0.1209 | Accuracy: 0.8424\n",
      "Iterations: 5590/10000.... Loss: 0.1215 | Accuracy: 0.8415\n",
      "Iterations: 5600/10000.... Loss: 0.1201 | Accuracy: 0.8462\n",
      "Iterations: 5610/10000.... Loss: 0.1204 | Accuracy: 0.8440\n",
      "Iterations: 5620/10000.... Loss: 0.1207 | Accuracy: 0.8402\n",
      "Iterations: 5630/10000.... Loss: 0.1199 | Accuracy: 0.8444\n",
      "Iterations: 5640/10000.... Loss: 0.1206 | Accuracy: 0.8415\n",
      "Iterations: 5650/10000.... Loss: 0.1204 | Accuracy: 0.8416\n",
      "Iterations: 5660/10000.... Loss: 0.1188 | Accuracy: 0.8446\n",
      "Iterations: 5670/10000.... Loss: 0.1196 | Accuracy: 0.8452\n",
      "Iterations: 5680/10000.... Loss: 0.1190 | Accuracy: 0.8436\n",
      "Iterations: 5690/10000.... Loss: 0.1179 | Accuracy: 0.8501\n",
      "Iterations: 5700/10000.... Loss: 0.1186 | Accuracy: 0.8472\n",
      "Iterations: 5710/10000.... Loss: 0.1177 | Accuracy: 0.8475\n",
      "Iterations: 5720/10000.... Loss: 0.1180 | Accuracy: 0.8474\n",
      "Iterations: 5730/10000.... Loss: 0.1180 | Accuracy: 0.8463\n",
      "Iterations: 5740/10000.... Loss: 0.1165 | Accuracy: 0.8501\n",
      "Iterations: 5750/10000.... Loss: 0.1172 | Accuracy: 0.8485\n",
      "Iterations: 5760/10000.... Loss: 0.1175 | Accuracy: 0.8482\n",
      "Iterations: 5770/10000.... Loss: 0.1176 | Accuracy: 0.8477\n",
      "Iterations: 5780/10000.... Loss: 0.1165 | Accuracy: 0.8491\n",
      "Iterations: 5790/10000.... Loss: 0.1169 | Accuracy: 0.8485\n",
      "Iterations: 5800/10000.... Loss: 0.1174 | Accuracy: 0.8454\n",
      "Iterations: 5810/10000.... Loss: 0.1168 | Accuracy: 0.8481\n",
      "Iterations: 5820/10000.... Loss: 0.1157 | Accuracy: 0.8521\n",
      "Iterations: 5830/10000.... Loss: 0.1160 | Accuracy: 0.8526\n",
      "Iterations: 5840/10000.... Loss: 0.1164 | Accuracy: 0.8490\n",
      "Iterations: 5850/10000.... Loss: 0.1166 | Accuracy: 0.8476\n",
      "Iterations: 5860/10000.... Loss: 0.1146 | Accuracy: 0.8540\n",
      "Iterations: 5870/10000.... Loss: 0.1154 | Accuracy: 0.8502\n",
      "Iterations: 5880/10000.... Loss: 0.1165 | Accuracy: 0.8465\n",
      "Iterations: 5890/10000.... Loss: 0.1154 | Accuracy: 0.8521\n",
      "Iterations: 5900/10000.... Loss: 0.1145 | Accuracy: 0.8504\n",
      "Iterations: 5910/10000.... Loss: 0.1154 | Accuracy: 0.8495\n",
      "Iterations: 5920/10000.... Loss: 0.1146 | Accuracy: 0.8525\n",
      "Iterations: 5930/10000.... Loss: 0.1139 | Accuracy: 0.8524\n",
      "Iterations: 5940/10000.... Loss: 0.1127 | Accuracy: 0.8553\n",
      "Iterations: 5950/10000.... Loss: 0.1148 | Accuracy: 0.8522\n",
      "Iterations: 5960/10000.... Loss: 0.1146 | Accuracy: 0.8522\n",
      "Iterations: 5970/10000.... Loss: 0.1125 | Accuracy: 0.8559\n",
      "Iterations: 5980/10000.... Loss: 0.1136 | Accuracy: 0.8568\n",
      "Iterations: 5990/10000.... Loss: 0.1136 | Accuracy: 0.8534\n",
      "Iterations: 6000/10000.... Loss: 0.1134 | Accuracy: 0.8540\n",
      "Iterations: 6010/10000.... Loss: 0.1124 | Accuracy: 0.8576\n",
      "Iterations: 6020/10000.... Loss: 0.1129 | Accuracy: 0.8540\n",
      "Iterations: 6030/10000.... Loss: 0.1129 | Accuracy: 0.8544\n",
      "Iterations: 6040/10000.... Loss: 0.1129 | Accuracy: 0.8547\n",
      "Iterations: 6050/10000.... Loss: 0.1117 | Accuracy: 0.8557\n",
      "Iterations: 6060/10000.... Loss: 0.1111 | Accuracy: 0.8587\n",
      "Iterations: 6070/10000.... Loss: 0.1116 | Accuracy: 0.8569\n",
      "Iterations: 6080/10000.... Loss: 0.1122 | Accuracy: 0.8559\n",
      "Iterations: 6090/10000.... Loss: 0.1106 | Accuracy: 0.8568\n",
      "Iterations: 6100/10000.... Loss: 0.1099 | Accuracy: 0.8603\n",
      "Iterations: 6110/10000.... Loss: 0.1111 | Accuracy: 0.8581\n",
      "Iterations: 6120/10000.... Loss: 0.1098 | Accuracy: 0.8584\n",
      "Iterations: 6130/10000.... Loss: 0.1107 | Accuracy: 0.8566\n",
      "Iterations: 6140/10000.... Loss: 0.1100 | Accuracy: 0.8587\n",
      "Iterations: 6150/10000.... Loss: 0.1095 | Accuracy: 0.8602\n",
      "Iterations: 6160/10000.... Loss: 0.1096 | Accuracy: 0.8597\n",
      "Iterations: 6170/10000.... Loss: 0.1096 | Accuracy: 0.8600\n",
      "Iterations: 6180/10000.... Loss: 0.1103 | Accuracy: 0.8591\n",
      "Iterations: 6190/10000.... Loss: 0.1096 | Accuracy: 0.8595\n",
      "Iterations: 6200/10000.... Loss: 0.1092 | Accuracy: 0.8602\n",
      "Iterations: 6210/10000.... Loss: 0.1088 | Accuracy: 0.8590\n",
      "Iterations: 6220/10000.... Loss: 0.1095 | Accuracy: 0.8590\n",
      "Iterations: 6230/10000.... Loss: 0.1081 | Accuracy: 0.8642\n",
      "Iterations: 6240/10000.... Loss: 0.1078 | Accuracy: 0.8630\n",
      "Iterations: 6250/10000.... Loss: 0.1086 | Accuracy: 0.8630\n",
      "Iterations: 6260/10000.... Loss: 0.1091 | Accuracy: 0.8608\n",
      "Iterations: 6270/10000.... Loss: 0.1088 | Accuracy: 0.8602\n",
      "Iterations: 6280/10000.... Loss: 0.1078 | Accuracy: 0.8616\n",
      "Iterations: 6290/10000.... Loss: 0.1080 | Accuracy: 0.8602\n",
      "Iterations: 6300/10000.... Loss: 0.1068 | Accuracy: 0.8643\n",
      "Iterations: 6310/10000.... Loss: 0.1063 | Accuracy: 0.8638\n",
      "Iterations: 6320/10000.... Loss: 0.1067 | Accuracy: 0.8648\n",
      "Iterations: 6330/10000.... Loss: 0.1058 | Accuracy: 0.8652\n",
      "Iterations: 6340/10000.... Loss: 0.1058 | Accuracy: 0.8656\n",
      "Iterations: 6350/10000.... Loss: 0.1050 | Accuracy: 0.8667\n",
      "Iterations: 6360/10000.... Loss: 0.1060 | Accuracy: 0.8662\n",
      "Iterations: 6370/10000.... Loss: 0.1053 | Accuracy: 0.8671\n",
      "Iterations: 6380/10000.... Loss: 0.1057 | Accuracy: 0.8649\n",
      "Iterations: 6390/10000.... Loss: 0.1057 | Accuracy: 0.8637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 6400/10000.... Loss: 0.1064 | Accuracy: 0.8659\n",
      "Iterations: 6410/10000.... Loss: 0.1048 | Accuracy: 0.8667\n",
      "Iterations: 6420/10000.... Loss: 0.1057 | Accuracy: 0.8660\n",
      "Iterations: 6430/10000.... Loss: 0.1052 | Accuracy: 0.8659\n",
      "Iterations: 6440/10000.... Loss: 0.1049 | Accuracy: 0.8663\n",
      "Iterations: 6450/10000.... Loss: 0.1043 | Accuracy: 0.8677\n",
      "Iterations: 6460/10000.... Loss: 0.1033 | Accuracy: 0.8704\n",
      "Iterations: 6470/10000.... Loss: 0.1033 | Accuracy: 0.8690\n",
      "Iterations: 6480/10000.... Loss: 0.1021 | Accuracy: 0.8725\n",
      "Iterations: 6490/10000.... Loss: 0.1044 | Accuracy: 0.8648\n",
      "Iterations: 6500/10000.... Loss: 0.1024 | Accuracy: 0.8701\n",
      "Iterations: 6510/10000.... Loss: 0.1033 | Accuracy: 0.8678\n",
      "Iterations: 6520/10000.... Loss: 0.1031 | Accuracy: 0.8700\n",
      "Iterations: 6530/10000.... Loss: 0.1024 | Accuracy: 0.8715\n",
      "Iterations: 6540/10000.... Loss: 0.1027 | Accuracy: 0.8684\n",
      "Iterations: 6550/10000.... Loss: 0.1017 | Accuracy: 0.8704\n",
      "Iterations: 6560/10000.... Loss: 0.1015 | Accuracy: 0.8710\n",
      "Iterations: 6570/10000.... Loss: 0.1018 | Accuracy: 0.8705\n",
      "Iterations: 6580/10000.... Loss: 0.1005 | Accuracy: 0.8755\n",
      "Iterations: 6590/10000.... Loss: 0.0998 | Accuracy: 0.8767\n",
      "Iterations: 6600/10000.... Loss: 0.1005 | Accuracy: 0.8725\n",
      "Iterations: 6610/10000.... Loss: 0.0987 | Accuracy: 0.8767\n",
      "Iterations: 6620/10000.... Loss: 0.1011 | Accuracy: 0.8722\n",
      "Iterations: 6630/10000.... Loss: 0.1009 | Accuracy: 0.8746\n",
      "Iterations: 6640/10000.... Loss: 0.0979 | Accuracy: 0.8796\n",
      "Iterations: 6650/10000.... Loss: 0.1005 | Accuracy: 0.8723\n",
      "Iterations: 6660/10000.... Loss: 0.0998 | Accuracy: 0.8769\n",
      "Iterations: 6670/10000.... Loss: 0.0993 | Accuracy: 0.8758\n",
      "Iterations: 6680/10000.... Loss: 0.1003 | Accuracy: 0.8735\n",
      "Iterations: 6690/10000.... Loss: 0.0991 | Accuracy: 0.8749\n",
      "Iterations: 6700/10000.... Loss: 0.0978 | Accuracy: 0.8774\n",
      "Iterations: 6710/10000.... Loss: 0.0973 | Accuracy: 0.8793\n",
      "Iterations: 6720/10000.... Loss: 0.0992 | Accuracy: 0.8747\n",
      "Iterations: 6730/10000.... Loss: 0.0993 | Accuracy: 0.8743\n",
      "Iterations: 6740/10000.... Loss: 0.0981 | Accuracy: 0.8762\n",
      "Iterations: 6750/10000.... Loss: 0.0990 | Accuracy: 0.8752\n",
      "Iterations: 6760/10000.... Loss: 0.0973 | Accuracy: 0.8787\n",
      "Iterations: 6770/10000.... Loss: 0.0971 | Accuracy: 0.8786\n",
      "Iterations: 6780/10000.... Loss: 0.0981 | Accuracy: 0.8768\n",
      "Iterations: 6790/10000.... Loss: 0.0975 | Accuracy: 0.8774\n",
      "Iterations: 6800/10000.... Loss: 0.0963 | Accuracy: 0.8792\n",
      "Iterations: 6810/10000.... Loss: 0.0952 | Accuracy: 0.8823\n",
      "Iterations: 6820/10000.... Loss: 0.0947 | Accuracy: 0.8832\n",
      "Iterations: 6830/10000.... Loss: 0.0952 | Accuracy: 0.8802\n",
      "Iterations: 6840/10000.... Loss: 0.0964 | Accuracy: 0.8796\n",
      "Iterations: 6850/10000.... Loss: 0.0962 | Accuracy: 0.8774\n",
      "Iterations: 6860/10000.... Loss: 0.0952 | Accuracy: 0.8808\n",
      "Iterations: 6870/10000.... Loss: 0.0948 | Accuracy: 0.8823\n",
      "Iterations: 6880/10000.... Loss: 0.0946 | Accuracy: 0.8806\n",
      "Iterations: 6890/10000.... Loss: 0.0953 | Accuracy: 0.8798\n",
      "Iterations: 6900/10000.... Loss: 0.0955 | Accuracy: 0.8776\n",
      "Iterations: 6910/10000.... Loss: 0.0938 | Accuracy: 0.8857\n",
      "Iterations: 6920/10000.... Loss: 0.0931 | Accuracy: 0.8825\n",
      "Iterations: 6930/10000.... Loss: 0.0942 | Accuracy: 0.8814\n",
      "Iterations: 6940/10000.... Loss: 0.0940 | Accuracy: 0.8843\n",
      "Iterations: 6950/10000.... Loss: 0.0931 | Accuracy: 0.8849\n",
      "Iterations: 6960/10000.... Loss: 0.0929 | Accuracy: 0.8831\n",
      "Iterations: 6970/10000.... Loss: 0.0930 | Accuracy: 0.8848\n",
      "Iterations: 6980/10000.... Loss: 0.0937 | Accuracy: 0.8813\n",
      "Iterations: 6990/10000.... Loss: 0.0921 | Accuracy: 0.8857\n",
      "Iterations: 7000/10000.... Loss: 0.0933 | Accuracy: 0.8846\n",
      "Iterations: 7010/10000.... Loss: 0.0920 | Accuracy: 0.8861\n",
      "Iterations: 7020/10000.... Loss: 0.0927 | Accuracy: 0.8836\n",
      "Iterations: 7030/10000.... Loss: 0.0917 | Accuracy: 0.8861\n",
      "Iterations: 7040/10000.... Loss: 0.0925 | Accuracy: 0.8840\n",
      "Iterations: 7050/10000.... Loss: 0.0919 | Accuracy: 0.8857\n",
      "Iterations: 7060/10000.... Loss: 0.0913 | Accuracy: 0.8856\n",
      "Iterations: 7070/10000.... Loss: 0.0902 | Accuracy: 0.8894\n",
      "Iterations: 7080/10000.... Loss: 0.0907 | Accuracy: 0.8871\n",
      "Iterations: 7090/10000.... Loss: 0.0895 | Accuracy: 0.8894\n",
      "Iterations: 7100/10000.... Loss: 0.0898 | Accuracy: 0.8880\n",
      "Iterations: 7110/10000.... Loss: 0.0886 | Accuracy: 0.8911\n",
      "Iterations: 7120/10000.... Loss: 0.0896 | Accuracy: 0.8915\n",
      "Iterations: 7130/10000.... Loss: 0.0893 | Accuracy: 0.8898\n",
      "Iterations: 7140/10000.... Loss: 0.0884 | Accuracy: 0.8922\n",
      "Iterations: 7150/10000.... Loss: 0.0904 | Accuracy: 0.8879\n",
      "Iterations: 7160/10000.... Loss: 0.0893 | Accuracy: 0.8920\n",
      "Iterations: 7170/10000.... Loss: 0.0893 | Accuracy: 0.8882\n",
      "Iterations: 7180/10000.... Loss: 0.0890 | Accuracy: 0.8891\n",
      "Iterations: 7190/10000.... Loss: 0.0882 | Accuracy: 0.8900\n",
      "Iterations: 7200/10000.... Loss: 0.0868 | Accuracy: 0.8944\n",
      "Iterations: 7210/10000.... Loss: 0.0881 | Accuracy: 0.8929\n",
      "Iterations: 7220/10000.... Loss: 0.0884 | Accuracy: 0.8912\n",
      "Iterations: 7230/10000.... Loss: 0.0878 | Accuracy: 0.8908\n",
      "Iterations: 7240/10000.... Loss: 0.0861 | Accuracy: 0.8952\n",
      "Iterations: 7250/10000.... Loss: 0.0873 | Accuracy: 0.8924\n",
      "Iterations: 7260/10000.... Loss: 0.0869 | Accuracy: 0.8915\n",
      "Iterations: 7270/10000.... Loss: 0.0859 | Accuracy: 0.8952\n",
      "Iterations: 7280/10000.... Loss: 0.0882 | Accuracy: 0.8901\n",
      "Iterations: 7290/10000.... Loss: 0.0855 | Accuracy: 0.8980\n",
      "Iterations: 7300/10000.... Loss: 0.0861 | Accuracy: 0.8943\n",
      "Iterations: 7310/10000.... Loss: 0.0856 | Accuracy: 0.8940\n",
      "Iterations: 7320/10000.... Loss: 0.0853 | Accuracy: 0.8958\n",
      "Iterations: 7330/10000.... Loss: 0.0842 | Accuracy: 0.8967\n",
      "Iterations: 7340/10000.... Loss: 0.0863 | Accuracy: 0.8923\n",
      "Iterations: 7350/10000.... Loss: 0.0844 | Accuracy: 0.8971\n",
      "Iterations: 7360/10000.... Loss: 0.0852 | Accuracy: 0.8950\n",
      "Iterations: 7370/10000.... Loss: 0.0836 | Accuracy: 0.8982\n",
      "Iterations: 7380/10000.... Loss: 0.0853 | Accuracy: 0.8954\n",
      "Iterations: 7390/10000.... Loss: 0.0833 | Accuracy: 0.8994\n",
      "Iterations: 7400/10000.... Loss: 0.0846 | Accuracy: 0.8963\n",
      "Iterations: 7410/10000.... Loss: 0.0839 | Accuracy: 0.8978\n",
      "Iterations: 7420/10000.... Loss: 0.0829 | Accuracy: 0.8984\n",
      "Iterations: 7430/10000.... Loss: 0.0837 | Accuracy: 0.8975\n",
      "Iterations: 7440/10000.... Loss: 0.0832 | Accuracy: 0.8988\n",
      "Iterations: 7450/10000.... Loss: 0.0832 | Accuracy: 0.8974\n",
      "Iterations: 7460/10000.... Loss: 0.0814 | Accuracy: 0.9018\n",
      "Iterations: 7470/10000.... Loss: 0.0814 | Accuracy: 0.9018\n",
      "Iterations: 7480/10000.... Loss: 0.0822 | Accuracy: 0.9004\n",
      "Iterations: 7490/10000.... Loss: 0.0812 | Accuracy: 0.9016\n",
      "Iterations: 7500/10000.... Loss: 0.0817 | Accuracy: 0.9002\n",
      "Iterations: 7510/10000.... Loss: 0.0809 | Accuracy: 0.9021\n",
      "Iterations: 7520/10000.... Loss: 0.0816 | Accuracy: 0.9016\n",
      "Iterations: 7530/10000.... Loss: 0.0800 | Accuracy: 0.9038\n",
      "Iterations: 7540/10000.... Loss: 0.0797 | Accuracy: 0.9030\n",
      "Iterations: 7550/10000.... Loss: 0.0794 | Accuracy: 0.9061\n",
      "Iterations: 7560/10000.... Loss: 0.0793 | Accuracy: 0.9052\n",
      "Iterations: 7570/10000.... Loss: 0.0801 | Accuracy: 0.9043\n",
      "Iterations: 7580/10000.... Loss: 0.0780 | Accuracy: 0.9053\n",
      "Iterations: 7590/10000.... Loss: 0.0797 | Accuracy: 0.9016\n",
      "Iterations: 7600/10000.... Loss: 0.0793 | Accuracy: 0.9042\n",
      "Iterations: 7610/10000.... Loss: 0.0782 | Accuracy: 0.9053\n",
      "Iterations: 7620/10000.... Loss: 0.0797 | Accuracy: 0.9035\n",
      "Iterations: 7630/10000.... Loss: 0.0780 | Accuracy: 0.9072\n",
      "Iterations: 7640/10000.... Loss: 0.0776 | Accuracy: 0.9074\n",
      "Iterations: 7650/10000.... Loss: 0.0781 | Accuracy: 0.9044\n",
      "Iterations: 7660/10000.... Loss: 0.0777 | Accuracy: 0.9035\n",
      "Iterations: 7670/10000.... Loss: 0.0769 | Accuracy: 0.9067\n",
      "Iterations: 7680/10000.... Loss: 0.0769 | Accuracy: 0.9074\n",
      "Iterations: 7690/10000.... Loss: 0.0773 | Accuracy: 0.9057\n",
      "Iterations: 7700/10000.... Loss: 0.0768 | Accuracy: 0.9068\n",
      "Iterations: 7710/10000.... Loss: 0.0776 | Accuracy: 0.9047\n",
      "Iterations: 7720/10000.... Loss: 0.0774 | Accuracy: 0.9057\n",
      "Iterations: 7730/10000.... Loss: 0.0767 | Accuracy: 0.9078\n",
      "Iterations: 7740/10000.... Loss: 0.0771 | Accuracy: 0.9055\n",
      "Iterations: 7750/10000.... Loss: 0.0761 | Accuracy: 0.9075\n",
      "Iterations: 7760/10000.... Loss: 0.0749 | Accuracy: 0.9096\n",
      "Iterations: 7770/10000.... Loss: 0.0757 | Accuracy: 0.9093\n",
      "Iterations: 7780/10000.... Loss: 0.0747 | Accuracy: 0.9111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 7790/10000.... Loss: 0.0756 | Accuracy: 0.9087\n",
      "Iterations: 7800/10000.... Loss: 0.0740 | Accuracy: 0.9107\n",
      "Iterations: 7810/10000.... Loss: 0.0729 | Accuracy: 0.9136\n",
      "Iterations: 7820/10000.... Loss: 0.0742 | Accuracy: 0.9113\n",
      "Iterations: 7830/10000.... Loss: 0.0749 | Accuracy: 0.9092\n",
      "Iterations: 7840/10000.... Loss: 0.0738 | Accuracy: 0.9112\n",
      "Iterations: 7850/10000.... Loss: 0.0728 | Accuracy: 0.9133\n",
      "Iterations: 7860/10000.... Loss: 0.0721 | Accuracy: 0.9148\n",
      "Iterations: 7870/10000.... Loss: 0.0740 | Accuracy: 0.9103\n",
      "Iterations: 7880/10000.... Loss: 0.0721 | Accuracy: 0.9140\n",
      "Iterations: 7890/10000.... Loss: 0.0719 | Accuracy: 0.9143\n",
      "Iterations: 7900/10000.... Loss: 0.0723 | Accuracy: 0.9138\n",
      "Iterations: 7910/10000.... Loss: 0.0718 | Accuracy: 0.9139\n",
      "Iterations: 7920/10000.... Loss: 0.0714 | Accuracy: 0.9159\n",
      "Iterations: 7930/10000.... Loss: 0.0707 | Accuracy: 0.9153\n",
      "Iterations: 7940/10000.... Loss: 0.0708 | Accuracy: 0.9167\n",
      "Iterations: 7950/10000.... Loss: 0.0722 | Accuracy: 0.9128\n",
      "Iterations: 7960/10000.... Loss: 0.0709 | Accuracy: 0.9171\n",
      "Iterations: 7970/10000.... Loss: 0.0710 | Accuracy: 0.9149\n",
      "Iterations: 7980/10000.... Loss: 0.0706 | Accuracy: 0.9142\n",
      "Iterations: 7990/10000.... Loss: 0.0705 | Accuracy: 0.9166\n",
      "Iterations: 8000/10000.... Loss: 0.0695 | Accuracy: 0.9164\n",
      "Iterations: 8010/10000.... Loss: 0.0683 | Accuracy: 0.9190\n",
      "Iterations: 8020/10000.... Loss: 0.0701 | Accuracy: 0.9162\n",
      "Iterations: 8030/10000.... Loss: 0.0694 | Accuracy: 0.9159\n",
      "Iterations: 8040/10000.... Loss: 0.0682 | Accuracy: 0.9203\n",
      "Iterations: 8050/10000.... Loss: 0.0689 | Accuracy: 0.9180\n",
      "Iterations: 8060/10000.... Loss: 0.0675 | Accuracy: 0.9210\n",
      "Iterations: 8070/10000.... Loss: 0.0675 | Accuracy: 0.9206\n",
      "Iterations: 8080/10000.... Loss: 0.0679 | Accuracy: 0.9191\n",
      "Iterations: 8090/10000.... Loss: 0.0679 | Accuracy: 0.9177\n",
      "Iterations: 8100/10000.... Loss: 0.0687 | Accuracy: 0.9160\n",
      "Iterations: 8110/10000.... Loss: 0.0671 | Accuracy: 0.9207\n",
      "Iterations: 8120/10000.... Loss: 0.0661 | Accuracy: 0.9226\n",
      "Iterations: 8130/10000.... Loss: 0.0659 | Accuracy: 0.9243\n",
      "Iterations: 8140/10000.... Loss: 0.0662 | Accuracy: 0.9207\n",
      "Iterations: 8150/10000.... Loss: 0.0668 | Accuracy: 0.9203\n",
      "Iterations: 8160/10000.... Loss: 0.0653 | Accuracy: 0.9243\n",
      "Iterations: 8170/10000.... Loss: 0.0658 | Accuracy: 0.9218\n",
      "Iterations: 8180/10000.... Loss: 0.0654 | Accuracy: 0.9226\n",
      "Iterations: 8190/10000.... Loss: 0.0659 | Accuracy: 0.9204\n",
      "Iterations: 8200/10000.... Loss: 0.0655 | Accuracy: 0.9214\n",
      "Iterations: 8210/10000.... Loss: 0.0639 | Accuracy: 0.9268\n",
      "Iterations: 8220/10000.... Loss: 0.0639 | Accuracy: 0.9258\n",
      "Iterations: 8230/10000.... Loss: 0.0637 | Accuracy: 0.9236\n",
      "Iterations: 8240/10000.... Loss: 0.0638 | Accuracy: 0.9271\n",
      "Iterations: 8250/10000.... Loss: 0.0639 | Accuracy: 0.9259\n",
      "Iterations: 8260/10000.... Loss: 0.0637 | Accuracy: 0.9256\n",
      "Iterations: 8270/10000.... Loss: 0.0637 | Accuracy: 0.9243\n",
      "Iterations: 8280/10000.... Loss: 0.0630 | Accuracy: 0.9265\n",
      "Iterations: 8290/10000.... Loss: 0.0644 | Accuracy: 0.9218\n",
      "Iterations: 8300/10000.... Loss: 0.0632 | Accuracy: 0.9246\n",
      "Iterations: 8310/10000.... Loss: 0.0629 | Accuracy: 0.9256\n",
      "Iterations: 8320/10000.... Loss: 0.0616 | Accuracy: 0.9280\n",
      "Iterations: 8330/10000.... Loss: 0.0615 | Accuracy: 0.9277\n",
      "Iterations: 8340/10000.... Loss: 0.0618 | Accuracy: 0.9265\n",
      "Iterations: 8350/10000.... Loss: 0.0610 | Accuracy: 0.9286\n",
      "Iterations: 8360/10000.... Loss: 0.0615 | Accuracy: 0.9271\n",
      "Iterations: 8370/10000.... Loss: 0.0598 | Accuracy: 0.9319\n",
      "Iterations: 8380/10000.... Loss: 0.0596 | Accuracy: 0.9315\n",
      "Iterations: 8390/10000.... Loss: 0.0599 | Accuracy: 0.9302\n",
      "Iterations: 8400/10000.... Loss: 0.0607 | Accuracy: 0.9283\n",
      "Iterations: 8410/10000.... Loss: 0.0609 | Accuracy: 0.9296\n",
      "Iterations: 8420/10000.... Loss: 0.0589 | Accuracy: 0.9324\n",
      "Iterations: 8430/10000.... Loss: 0.0586 | Accuracy: 0.9327\n",
      "Iterations: 8440/10000.... Loss: 0.0591 | Accuracy: 0.9305\n",
      "Iterations: 8450/10000.... Loss: 0.0589 | Accuracy: 0.9308\n",
      "Iterations: 8460/10000.... Loss: 0.0597 | Accuracy: 0.9300\n",
      "Iterations: 8470/10000.... Loss: 0.0567 | Accuracy: 0.9348\n",
      "Iterations: 8480/10000.... Loss: 0.0575 | Accuracy: 0.9328\n",
      "Iterations: 8490/10000.... Loss: 0.0576 | Accuracy: 0.9336\n",
      "Iterations: 8500/10000.... Loss: 0.0575 | Accuracy: 0.9323\n",
      "Iterations: 8510/10000.... Loss: 0.0560 | Accuracy: 0.9361\n",
      "Iterations: 8520/10000.... Loss: 0.0563 | Accuracy: 0.9360\n",
      "Iterations: 8530/10000.... Loss: 0.0564 | Accuracy: 0.9350\n",
      "Iterations: 8540/10000.... Loss: 0.0568 | Accuracy: 0.9346\n",
      "Iterations: 8550/10000.... Loss: 0.0571 | Accuracy: 0.9344\n",
      "Iterations: 8560/10000.... Loss: 0.0559 | Accuracy: 0.9357\n",
      "Iterations: 8570/10000.... Loss: 0.0551 | Accuracy: 0.9367\n",
      "Iterations: 8580/10000.... Loss: 0.0564 | Accuracy: 0.9342\n",
      "Iterations: 8590/10000.... Loss: 0.0552 | Accuracy: 0.9366\n",
      "Iterations: 8600/10000.... Loss: 0.0545 | Accuracy: 0.9372\n",
      "Iterations: 8610/10000.... Loss: 0.0541 | Accuracy: 0.9377\n",
      "Iterations: 8620/10000.... Loss: 0.0544 | Accuracy: 0.9373\n",
      "Iterations: 8630/10000.... Loss: 0.0538 | Accuracy: 0.9389\n",
      "Iterations: 8640/10000.... Loss: 0.0546 | Accuracy: 0.9367\n",
      "Iterations: 8650/10000.... Loss: 0.0536 | Accuracy: 0.9388\n",
      "Iterations: 8660/10000.... Loss: 0.0528 | Accuracy: 0.9399\n",
      "Iterations: 8670/10000.... Loss: 0.0536 | Accuracy: 0.9388\n",
      "Iterations: 8680/10000.... Loss: 0.0521 | Accuracy: 0.9411\n",
      "Iterations: 8690/10000.... Loss: 0.0518 | Accuracy: 0.9414\n",
      "Iterations: 8700/10000.... Loss: 0.0531 | Accuracy: 0.9390\n",
      "Iterations: 8710/10000.... Loss: 0.0517 | Accuracy: 0.9420\n",
      "Iterations: 8720/10000.... Loss: 0.0520 | Accuracy: 0.9407\n",
      "Iterations: 8730/10000.... Loss: 0.0515 | Accuracy: 0.9403\n",
      "Iterations: 8740/10000.... Loss: 0.0513 | Accuracy: 0.9415\n",
      "Iterations: 8750/10000.... Loss: 0.0518 | Accuracy: 0.9399\n",
      "Iterations: 8760/10000.... Loss: 0.0501 | Accuracy: 0.9433\n",
      "Iterations: 8770/10000.... Loss: 0.0498 | Accuracy: 0.9435\n",
      "Iterations: 8780/10000.... Loss: 0.0492 | Accuracy: 0.9452\n",
      "Iterations: 8790/10000.... Loss: 0.0491 | Accuracy: 0.9440\n",
      "Iterations: 8800/10000.... Loss: 0.0495 | Accuracy: 0.9435\n",
      "Iterations: 8810/10000.... Loss: 0.0496 | Accuracy: 0.9433\n",
      "Iterations: 8820/10000.... Loss: 0.0484 | Accuracy: 0.9459\n",
      "Iterations: 8830/10000.... Loss: 0.0487 | Accuracy: 0.9452\n",
      "Iterations: 8840/10000.... Loss: 0.0474 | Accuracy: 0.9464\n",
      "Iterations: 8850/10000.... Loss: 0.0473 | Accuracy: 0.9470\n",
      "Iterations: 8860/10000.... Loss: 0.0479 | Accuracy: 0.9466\n",
      "Iterations: 8870/10000.... Loss: 0.0475 | Accuracy: 0.9470\n",
      "Iterations: 8880/10000.... Loss: 0.0476 | Accuracy: 0.9471\n",
      "Iterations: 8890/10000.... Loss: 0.0475 | Accuracy: 0.9468\n",
      "Iterations: 8900/10000.... Loss: 0.0481 | Accuracy: 0.9452\n",
      "Iterations: 8910/10000.... Loss: 0.0460 | Accuracy: 0.9486\n",
      "Iterations: 8920/10000.... Loss: 0.0467 | Accuracy: 0.9475\n",
      "Iterations: 8930/10000.... Loss: 0.0475 | Accuracy: 0.9454\n",
      "Iterations: 8940/10000.... Loss: 0.0455 | Accuracy: 0.9497\n",
      "Iterations: 8950/10000.... Loss: 0.0456 | Accuracy: 0.9489\n",
      "Iterations: 8960/10000.... Loss: 0.0447 | Accuracy: 0.9510\n",
      "Iterations: 8970/10000.... Loss: 0.0444 | Accuracy: 0.9510\n",
      "Iterations: 8980/10000.... Loss: 0.0434 | Accuracy: 0.9533\n",
      "Iterations: 8990/10000.... Loss: 0.0443 | Accuracy: 0.9513\n",
      "Iterations: 9000/10000.... Loss: 0.0442 | Accuracy: 0.9498\n",
      "Iterations: 9010/10000.... Loss: 0.0437 | Accuracy: 0.9532\n",
      "Iterations: 9020/10000.... Loss: 0.0435 | Accuracy: 0.9526\n",
      "Iterations: 9030/10000.... Loss: 0.0420 | Accuracy: 0.9550\n",
      "Iterations: 9040/10000.... Loss: 0.0419 | Accuracy: 0.9541\n",
      "Iterations: 9050/10000.... Loss: 0.0424 | Accuracy: 0.9536\n",
      "Iterations: 9060/10000.... Loss: 0.0424 | Accuracy: 0.9537\n",
      "Iterations: 9070/10000.... Loss: 0.0426 | Accuracy: 0.9527\n",
      "Iterations: 9080/10000.... Loss: 0.0420 | Accuracy: 0.9536\n",
      "Iterations: 9090/10000.... Loss: 0.0407 | Accuracy: 0.9545\n",
      "Iterations: 9100/10000.... Loss: 0.0413 | Accuracy: 0.9545\n",
      "Iterations: 9110/10000.... Loss: 0.0402 | Accuracy: 0.9570\n",
      "Iterations: 9120/10000.... Loss: 0.0415 | Accuracy: 0.9535\n",
      "Iterations: 9130/10000.... Loss: 0.0404 | Accuracy: 0.9563\n",
      "Iterations: 9140/10000.... Loss: 0.0393 | Accuracy: 0.9577\n",
      "Iterations: 9150/10000.... Loss: 0.0391 | Accuracy: 0.9575\n",
      "Iterations: 9160/10000.... Loss: 0.0405 | Accuracy: 0.9548\n",
      "Iterations: 9170/10000.... Loss: 0.0389 | Accuracy: 0.9580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 9180/10000.... Loss: 0.0386 | Accuracy: 0.9584\n",
      "Iterations: 9190/10000.... Loss: 0.0382 | Accuracy: 0.9592\n",
      "Iterations: 9200/10000.... Loss: 0.0382 | Accuracy: 0.9589\n",
      "Iterations: 9210/10000.... Loss: 0.0388 | Accuracy: 0.9570\n",
      "Iterations: 9220/10000.... Loss: 0.0381 | Accuracy: 0.9582\n",
      "Iterations: 9230/10000.... Loss: 0.0375 | Accuracy: 0.9606\n",
      "Iterations: 9240/10000.... Loss: 0.0362 | Accuracy: 0.9614\n",
      "Iterations: 9250/10000.... Loss: 0.0371 | Accuracy: 0.9599\n",
      "Iterations: 9260/10000.... Loss: 0.0369 | Accuracy: 0.9601\n",
      "Iterations: 9270/10000.... Loss: 0.0367 | Accuracy: 0.9610\n",
      "Iterations: 9280/10000.... Loss: 0.0352 | Accuracy: 0.9611\n",
      "Iterations: 9290/10000.... Loss: 0.0354 | Accuracy: 0.9637\n",
      "Iterations: 9300/10000.... Loss: 0.0358 | Accuracy: 0.9604\n",
      "Iterations: 9310/10000.... Loss: 0.0353 | Accuracy: 0.9626\n",
      "Iterations: 9320/10000.... Loss: 0.0343 | Accuracy: 0.9628\n",
      "Iterations: 9330/10000.... Loss: 0.0347 | Accuracy: 0.9628\n",
      "Iterations: 9340/10000.... Loss: 0.0341 | Accuracy: 0.9632\n",
      "Iterations: 9350/10000.... Loss: 0.0351 | Accuracy: 0.9624\n",
      "Iterations: 9360/10000.... Loss: 0.0336 | Accuracy: 0.9650\n",
      "Iterations: 9370/10000.... Loss: 0.0334 | Accuracy: 0.9653\n",
      "Iterations: 9380/10000.... Loss: 0.0324 | Accuracy: 0.9669\n",
      "Iterations: 9390/10000.... Loss: 0.0330 | Accuracy: 0.9652\n",
      "Iterations: 9400/10000.... Loss: 0.0331 | Accuracy: 0.9639\n",
      "Iterations: 9410/10000.... Loss: 0.0328 | Accuracy: 0.9651\n",
      "Iterations: 9420/10000.... Loss: 0.0318 | Accuracy: 0.9671\n",
      "Iterations: 9430/10000.... Loss: 0.0314 | Accuracy: 0.9668\n",
      "Iterations: 9440/10000.... Loss: 0.0316 | Accuracy: 0.9673\n",
      "Iterations: 9450/10000.... Loss: 0.0317 | Accuracy: 0.9662\n",
      "Iterations: 9460/10000.... Loss: 0.0315 | Accuracy: 0.9672\n",
      "Iterations: 9470/10000.... Loss: 0.0311 | Accuracy: 0.9668\n",
      "Iterations: 9480/10000.... Loss: 0.0303 | Accuracy: 0.9682\n",
      "Iterations: 9490/10000.... Loss: 0.0299 | Accuracy: 0.9704\n",
      "Iterations: 9500/10000.... Loss: 0.0300 | Accuracy: 0.9686\n",
      "Iterations: 9510/10000.... Loss: 0.0296 | Accuracy: 0.9688\n",
      "Iterations: 9520/10000.... Loss: 0.0290 | Accuracy: 0.9713\n",
      "Iterations: 9530/10000.... Loss: 0.0289 | Accuracy: 0.9699\n",
      "Iterations: 9540/10000.... Loss: 0.0286 | Accuracy: 0.9712\n",
      "Iterations: 9550/10000.... Loss: 0.0281 | Accuracy: 0.9716\n",
      "Iterations: 9560/10000.... Loss: 0.0290 | Accuracy: 0.9698\n",
      "Iterations: 9570/10000.... Loss: 0.0275 | Accuracy: 0.9710\n",
      "Iterations: 9580/10000.... Loss: 0.0281 | Accuracy: 0.9708\n",
      "Iterations: 9590/10000.... Loss: 0.0273 | Accuracy: 0.9722\n",
      "Iterations: 9600/10000.... Loss: 0.0276 | Accuracy: 0.9717\n",
      "Iterations: 9610/10000.... Loss: 0.0267 | Accuracy: 0.9722\n",
      "Iterations: 9620/10000.... Loss: 0.0259 | Accuracy: 0.9740\n",
      "Iterations: 9630/10000.... Loss: 0.0272 | Accuracy: 0.9717\n",
      "Iterations: 9640/10000.... Loss: 0.0260 | Accuracy: 0.9738\n",
      "Iterations: 9650/10000.... Loss: 0.0258 | Accuracy: 0.9741\n",
      "Iterations: 9660/10000.... Loss: 0.0254 | Accuracy: 0.9747\n",
      "Iterations: 9670/10000.... Loss: 0.0253 | Accuracy: 0.9740\n",
      "Iterations: 9680/10000.... Loss: 0.0242 | Accuracy: 0.9756\n",
      "Iterations: 9690/10000.... Loss: 0.0247 | Accuracy: 0.9753\n",
      "Iterations: 9700/10000.... Loss: 0.0249 | Accuracy: 0.9750\n",
      "Iterations: 9710/10000.... Loss: 0.0239 | Accuracy: 0.9756\n",
      "Iterations: 9720/10000.... Loss: 0.0235 | Accuracy: 0.9765\n",
      "Iterations: 9730/10000.... Loss: 0.0232 | Accuracy: 0.9769\n",
      "Iterations: 9740/10000.... Loss: 0.0226 | Accuracy: 0.9781\n",
      "Iterations: 9750/10000.... Loss: 0.0232 | Accuracy: 0.9775\n",
      "Iterations: 9760/10000.... Loss: 0.0232 | Accuracy: 0.9766\n",
      "Iterations: 9770/10000.... Loss: 0.0231 | Accuracy: 0.9768\n",
      "Iterations: 9780/10000.... Loss: 0.0230 | Accuracy: 0.9763\n",
      "Iterations: 9790/10000.... Loss: 0.0221 | Accuracy: 0.9787\n",
      "Iterations: 9800/10000.... Loss: 0.0225 | Accuracy: 0.9777\n",
      "Iterations: 9810/10000.... Loss: 0.0225 | Accuracy: 0.9778\n",
      "Iterations: 9820/10000.... Loss: 0.0220 | Accuracy: 0.9786\n",
      "Iterations: 9830/10000.... Loss: 0.0216 | Accuracy: 0.9793\n",
      "Iterations: 9840/10000.... Loss: 0.0218 | Accuracy: 0.9784\n",
      "Iterations: 9850/10000.... Loss: 0.0214 | Accuracy: 0.9789\n",
      "Iterations: 9860/10000.... Loss: 0.0208 | Accuracy: 0.9805\n",
      "Iterations: 9870/10000.... Loss: 0.0205 | Accuracy: 0.9797\n",
      "Iterations: 9880/10000.... Loss: 0.0206 | Accuracy: 0.9802\n",
      "Iterations: 9890/10000.... Loss: 0.0200 | Accuracy: 0.9817\n",
      "Iterations: 9900/10000.... Loss: 0.0208 | Accuracy: 0.9796\n",
      "Iterations: 9910/10000.... Loss: 0.0200 | Accuracy: 0.9799\n",
      "Iterations: 9920/10000.... Loss: 0.0203 | Accuracy: 0.9798\n",
      "Iterations: 9930/10000.... Loss: 0.0202 | Accuracy: 0.9805\n",
      "Iterations: 9940/10000.... Loss: 0.0194 | Accuracy: 0.9812\n",
      "Iterations: 9950/10000.... Loss: 0.0186 | Accuracy: 0.9818\n",
      "Iterations: 9960/10000.... Loss: 0.0195 | Accuracy: 0.9808\n",
      "Iterations: 9970/10000.... Loss: 0.0187 | Accuracy: 0.9823\n",
      "Iterations: 9980/10000.... Loss: 0.0187 | Accuracy: 0.9827\n",
      "Iterations: 9990/10000.... Loss: 0.0183 | Accuracy: 0.9822\n",
      "Iterations: 10000/10000.... Loss: 0.0184 | Accuracy: 0.9824\n"
     ]
    }
   ],
   "source": [
    "n_iterations = 10000\n",
    "for iterations in range(5001, n_iterations+1):\n",
    "    input_seq,target_seq = generate_seq(batch_size = batch_size, vec_len = vec_len, R = R, T = T)\n",
    "    accuracy,total_loss = train(HebbFF_R6,criterion,optimizer,input_seq,target_seq,T)\n",
    "    if iterations % 10 == 0:\n",
    "        print('Iterations: {}/{}....'.format(iterations, n_iterations), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(total_loss.item()), end=' | ')\n",
    "        print(\"Accuracy: {:.4f}\".format(accuracy.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4e4b9d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 10010/12000.... Loss: 0.0190 | Accuracy: 0.9816\n",
      "Iterations: 10020/12000.... Loss: 0.0178 | Accuracy: 0.9833\n",
      "Iterations: 10030/12000.... Loss: 0.0180 | Accuracy: 0.9831\n",
      "Iterations: 10040/12000.... Loss: 0.0186 | Accuracy: 0.9813\n",
      "Iterations: 10050/12000.... Loss: 0.0175 | Accuracy: 0.9831\n",
      "Iterations: 10060/12000.... Loss: 0.0175 | Accuracy: 0.9830\n",
      "Iterations: 10070/12000.... Loss: 0.0170 | Accuracy: 0.9842\n",
      "Iterations: 10080/12000.... Loss: 0.0171 | Accuracy: 0.9837\n",
      "Iterations: 10090/12000.... Loss: 0.0168 | Accuracy: 0.9838\n",
      "Iterations: 10100/12000.... Loss: 0.0168 | Accuracy: 0.9841\n",
      "Iterations: 10110/12000.... Loss: 0.0168 | Accuracy: 0.9833\n",
      "Iterations: 10120/12000.... Loss: 0.0167 | Accuracy: 0.9840\n",
      "Iterations: 10130/12000.... Loss: 0.0166 | Accuracy: 0.9848\n",
      "Iterations: 10140/12000.... Loss: 0.0161 | Accuracy: 0.9847\n",
      "Iterations: 10150/12000.... Loss: 0.0173 | Accuracy: 0.9831\n",
      "Iterations: 10160/12000.... Loss: 0.0164 | Accuracy: 0.9842\n",
      "Iterations: 10170/12000.... Loss: 0.0163 | Accuracy: 0.9842\n",
      "Iterations: 10180/12000.... Loss: 0.0164 | Accuracy: 0.9844\n",
      "Iterations: 10190/12000.... Loss: 0.0160 | Accuracy: 0.9851\n",
      "Iterations: 10200/12000.... Loss: 0.0160 | Accuracy: 0.9851\n",
      "Iterations: 10210/12000.... Loss: 0.0157 | Accuracy: 0.9855\n",
      "Iterations: 10220/12000.... Loss: 0.0156 | Accuracy: 0.9849\n",
      "Iterations: 10230/12000.... Loss: 0.0159 | Accuracy: 0.9847\n",
      "Iterations: 10240/12000.... Loss: 0.0153 | Accuracy: 0.9853\n",
      "Iterations: 10250/12000.... Loss: 0.0147 | Accuracy: 0.9866\n",
      "Iterations: 10260/12000.... Loss: 0.0147 | Accuracy: 0.9864\n",
      "Iterations: 10270/12000.... Loss: 0.0154 | Accuracy: 0.9853\n",
      "Iterations: 10280/12000.... Loss: 0.0151 | Accuracy: 0.9854\n",
      "Iterations: 10290/12000.... Loss: 0.0154 | Accuracy: 0.9852\n",
      "Iterations: 10300/12000.... Loss: 0.0149 | Accuracy: 0.9857\n",
      "Iterations: 10310/12000.... Loss: 0.0150 | Accuracy: 0.9857\n",
      "Iterations: 10320/12000.... Loss: 0.0153 | Accuracy: 0.9852\n",
      "Iterations: 10330/12000.... Loss: 0.0141 | Accuracy: 0.9871\n",
      "Iterations: 10340/12000.... Loss: 0.0143 | Accuracy: 0.9864\n",
      "Iterations: 10350/12000.... Loss: 0.0141 | Accuracy: 0.9866\n",
      "Iterations: 10360/12000.... Loss: 0.0145 | Accuracy: 0.9864\n",
      "Iterations: 10370/12000.... Loss: 0.0143 | Accuracy: 0.9864\n",
      "Iterations: 10380/12000.... Loss: 0.0148 | Accuracy: 0.9863\n",
      "Iterations: 10390/12000.... Loss: 0.0145 | Accuracy: 0.9864\n",
      "Iterations: 10400/12000.... Loss: 0.0142 | Accuracy: 0.9866\n",
      "Iterations: 10410/12000.... Loss: 0.0133 | Accuracy: 0.9886\n",
      "Iterations: 10420/12000.... Loss: 0.0134 | Accuracy: 0.9870\n",
      "Iterations: 10430/12000.... Loss: 0.0138 | Accuracy: 0.9865\n",
      "Iterations: 10440/12000.... Loss: 0.0136 | Accuracy: 0.9873\n",
      "Iterations: 10450/12000.... Loss: 0.0142 | Accuracy: 0.9860\n",
      "Iterations: 10460/12000.... Loss: 0.0140 | Accuracy: 0.9863\n",
      "Iterations: 10470/12000.... Loss: 0.0134 | Accuracy: 0.9869\n",
      "Iterations: 10480/12000.... Loss: 0.0137 | Accuracy: 0.9868\n",
      "Iterations: 10490/12000.... Loss: 0.0139 | Accuracy: 0.9861\n",
      "Iterations: 10500/12000.... Loss: 0.0136 | Accuracy: 0.9872\n",
      "Iterations: 10510/12000.... Loss: 0.0134 | Accuracy: 0.9869\n",
      "Iterations: 10520/12000.... Loss: 0.0133 | Accuracy: 0.9870\n",
      "Iterations: 10530/12000.... Loss: 0.0128 | Accuracy: 0.9878\n",
      "Iterations: 10540/12000.... Loss: 0.0133 | Accuracy: 0.9870\n",
      "Iterations: 10550/12000.... Loss: 0.0128 | Accuracy: 0.9878\n",
      "Iterations: 10560/12000.... Loss: 0.0130 | Accuracy: 0.9873\n",
      "Iterations: 10570/12000.... Loss: 0.0128 | Accuracy: 0.9877\n",
      "Iterations: 10580/12000.... Loss: 0.0129 | Accuracy: 0.9878\n",
      "Iterations: 10590/12000.... Loss: 0.0129 | Accuracy: 0.9874\n",
      "Iterations: 10600/12000.... Loss: 0.0131 | Accuracy: 0.9872\n",
      "Iterations: 10610/12000.... Loss: 0.0122 | Accuracy: 0.9889\n",
      "Iterations: 10620/12000.... Loss: 0.0123 | Accuracy: 0.9886\n",
      "Iterations: 10630/12000.... Loss: 0.0126 | Accuracy: 0.9883\n",
      "Iterations: 10640/12000.... Loss: 0.0125 | Accuracy: 0.9886\n",
      "Iterations: 10650/12000.... Loss: 0.0121 | Accuracy: 0.9888\n",
      "Iterations: 10660/12000.... Loss: 0.0119 | Accuracy: 0.9886\n",
      "Iterations: 10670/12000.... Loss: 0.0122 | Accuracy: 0.9882\n",
      "Iterations: 10680/12000.... Loss: 0.0129 | Accuracy: 0.9872\n",
      "Iterations: 10690/12000.... Loss: 0.0123 | Accuracy: 0.9878\n",
      "Iterations: 10700/12000.... Loss: 0.0125 | Accuracy: 0.9884\n",
      "Iterations: 10710/12000.... Loss: 0.0124 | Accuracy: 0.9872\n",
      "Iterations: 10720/12000.... Loss: 0.0117 | Accuracy: 0.9886\n",
      "Iterations: 10730/12000.... Loss: 0.0114 | Accuracy: 0.9898\n",
      "Iterations: 10740/12000.... Loss: 0.0119 | Accuracy: 0.9883\n",
      "Iterations: 10750/12000.... Loss: 0.0122 | Accuracy: 0.9881\n",
      "Iterations: 10760/12000.... Loss: 0.0113 | Accuracy: 0.9897\n",
      "Iterations: 10770/12000.... Loss: 0.0123 | Accuracy: 0.9877\n",
      "Iterations: 10780/12000.... Loss: 0.0118 | Accuracy: 0.9879\n",
      "Iterations: 10790/12000.... Loss: 0.0114 | Accuracy: 0.9894\n",
      "Iterations: 10800/12000.... Loss: 0.0113 | Accuracy: 0.9894\n",
      "Iterations: 10810/12000.... Loss: 0.0115 | Accuracy: 0.9892\n",
      "Iterations: 10820/12000.... Loss: 0.0115 | Accuracy: 0.9889\n",
      "Iterations: 10830/12000.... Loss: 0.0115 | Accuracy: 0.9889\n",
      "Iterations: 10840/12000.... Loss: 0.0113 | Accuracy: 0.9894\n",
      "Iterations: 10850/12000.... Loss: 0.0114 | Accuracy: 0.9891\n",
      "Iterations: 10860/12000.... Loss: 0.0113 | Accuracy: 0.9891\n",
      "Iterations: 10870/12000.... Loss: 0.0115 | Accuracy: 0.9885\n",
      "Iterations: 10880/12000.... Loss: 0.0112 | Accuracy: 0.9892\n",
      "Iterations: 10890/12000.... Loss: 0.0109 | Accuracy: 0.9897\n",
      "Iterations: 10900/12000.... Loss: 0.0111 | Accuracy: 0.9893\n",
      "Iterations: 10910/12000.... Loss: 0.0112 | Accuracy: 0.9891\n",
      "Iterations: 10920/12000.... Loss: 0.0113 | Accuracy: 0.9885\n",
      "Iterations: 10930/12000.... Loss: 0.0113 | Accuracy: 0.9894\n",
      "Iterations: 10940/12000.... Loss: 0.0110 | Accuracy: 0.9894\n",
      "Iterations: 10950/12000.... Loss: 0.0106 | Accuracy: 0.9902\n",
      "Iterations: 10960/12000.... Loss: 0.0103 | Accuracy: 0.9904\n",
      "Iterations: 10970/12000.... Loss: 0.0104 | Accuracy: 0.9902\n",
      "Iterations: 10980/12000.... Loss: 0.0105 | Accuracy: 0.9901\n",
      "Iterations: 10990/12000.... Loss: 0.0106 | Accuracy: 0.9896\n",
      "Iterations: 11000/12000.... Loss: 0.0102 | Accuracy: 0.9903\n",
      "Iterations: 11010/12000.... Loss: 0.0109 | Accuracy: 0.9897\n",
      "Iterations: 11020/12000.... Loss: 0.0107 | Accuracy: 0.9894\n",
      "Iterations: 11030/12000.... Loss: 0.0102 | Accuracy: 0.9903\n",
      "Iterations: 11040/12000.... Loss: 0.0112 | Accuracy: 0.9888\n",
      "Iterations: 11050/12000.... Loss: 0.0108 | Accuracy: 0.9895\n",
      "Iterations: 11060/12000.... Loss: 0.0105 | Accuracy: 0.9895\n",
      "Iterations: 11070/12000.... Loss: 0.0105 | Accuracy: 0.9897\n",
      "Iterations: 11080/12000.... Loss: 0.0104 | Accuracy: 0.9902\n",
      "Iterations: 11090/12000.... Loss: 0.0106 | Accuracy: 0.9898\n",
      "Iterations: 11100/12000.... Loss: 0.0102 | Accuracy: 0.9906\n",
      "Iterations: 11110/12000.... Loss: 0.0102 | Accuracy: 0.9904\n",
      "Iterations: 11120/12000.... Loss: 0.0103 | Accuracy: 0.9902\n",
      "Iterations: 11130/12000.... Loss: 0.0097 | Accuracy: 0.9907\n",
      "Iterations: 11140/12000.... Loss: 0.0105 | Accuracy: 0.9896\n",
      "Iterations: 11150/12000.... Loss: 0.0104 | Accuracy: 0.9898\n",
      "Iterations: 11160/12000.... Loss: 0.0104 | Accuracy: 0.9898\n",
      "Iterations: 11170/12000.... Loss: 0.0100 | Accuracy: 0.9902\n",
      "Iterations: 11180/12000.... Loss: 0.0095 | Accuracy: 0.9912\n",
      "Iterations: 11190/12000.... Loss: 0.0103 | Accuracy: 0.9897\n",
      "Iterations: 11200/12000.... Loss: 0.0099 | Accuracy: 0.9910\n",
      "Iterations: 11210/12000.... Loss: 0.0102 | Accuracy: 0.9902\n",
      "Iterations: 11220/12000.... Loss: 0.0098 | Accuracy: 0.9904\n",
      "Iterations: 11230/12000.... Loss: 0.0094 | Accuracy: 0.9912\n",
      "Iterations: 11240/12000.... Loss: 0.0099 | Accuracy: 0.9909\n",
      "Iterations: 11250/12000.... Loss: 0.0093 | Accuracy: 0.9915\n",
      "Iterations: 11260/12000.... Loss: 0.0094 | Accuracy: 0.9910\n",
      "Iterations: 11270/12000.... Loss: 0.0101 | Accuracy: 0.9905\n",
      "Iterations: 11280/12000.... Loss: 0.0093 | Accuracy: 0.9915\n",
      "Iterations: 11290/12000.... Loss: 0.0098 | Accuracy: 0.9907\n",
      "Iterations: 11300/12000.... Loss: 0.0094 | Accuracy: 0.9910\n",
      "Iterations: 11310/12000.... Loss: 0.0098 | Accuracy: 0.9909\n",
      "Iterations: 11320/12000.... Loss: 0.0100 | Accuracy: 0.9903\n",
      "Iterations: 11330/12000.... Loss: 0.0095 | Accuracy: 0.9902\n",
      "Iterations: 11340/12000.... Loss: 0.0099 | Accuracy: 0.9903\n",
      "Iterations: 11350/12000.... Loss: 0.0096 | Accuracy: 0.9907\n",
      "Iterations: 11360/12000.... Loss: 0.0098 | Accuracy: 0.9907\n",
      "Iterations: 11370/12000.... Loss: 0.0097 | Accuracy: 0.9904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 11380/12000.... Loss: 0.0097 | Accuracy: 0.9907\n",
      "Iterations: 11390/12000.... Loss: 0.0091 | Accuracy: 0.9912\n",
      "Iterations: 11400/12000.... Loss: 0.0099 | Accuracy: 0.9900\n",
      "Iterations: 11410/12000.... Loss: 0.0090 | Accuracy: 0.9916\n",
      "Iterations: 11420/12000.... Loss: 0.0092 | Accuracy: 0.9912\n",
      "Iterations: 11430/12000.... Loss: 0.0097 | Accuracy: 0.9901\n",
      "Iterations: 11440/12000.... Loss: 0.0097 | Accuracy: 0.9902\n",
      "Iterations: 11450/12000.... Loss: 0.0096 | Accuracy: 0.9902\n",
      "Iterations: 11460/12000.... Loss: 0.0090 | Accuracy: 0.9913\n",
      "Iterations: 11470/12000.... Loss: 0.0093 | Accuracy: 0.9912\n",
      "Iterations: 11480/12000.... Loss: 0.0094 | Accuracy: 0.9906\n",
      "Iterations: 11490/12000.... Loss: 0.0094 | Accuracy: 0.9908\n",
      "Iterations: 11500/12000.... Loss: 0.0090 | Accuracy: 0.9912\n",
      "Iterations: 11510/12000.... Loss: 0.0090 | Accuracy: 0.9914\n",
      "Iterations: 11520/12000.... Loss: 0.0093 | Accuracy: 0.9904\n",
      "Iterations: 11530/12000.... Loss: 0.0093 | Accuracy: 0.9908\n",
      "Iterations: 11540/12000.... Loss: 0.0093 | Accuracy: 0.9905\n",
      "Iterations: 11550/12000.... Loss: 0.0091 | Accuracy: 0.9909\n",
      "Iterations: 11560/12000.... Loss: 0.0082 | Accuracy: 0.9922\n",
      "Iterations: 11570/12000.... Loss: 0.0090 | Accuracy: 0.9916\n",
      "Iterations: 11580/12000.... Loss: 0.0088 | Accuracy: 0.9917\n",
      "Iterations: 11590/12000.... Loss: 0.0088 | Accuracy: 0.9915\n",
      "Iterations: 11600/12000.... Loss: 0.0088 | Accuracy: 0.9914\n",
      "Iterations: 11610/12000.... Loss: 0.0084 | Accuracy: 0.9918\n",
      "Iterations: 11620/12000.... Loss: 0.0085 | Accuracy: 0.9919\n",
      "Iterations: 11630/12000.... Loss: 0.0084 | Accuracy: 0.9920\n",
      "Iterations: 11640/12000.... Loss: 0.0084 | Accuracy: 0.9922\n",
      "Iterations: 11650/12000.... Loss: 0.0091 | Accuracy: 0.9909\n",
      "Iterations: 11660/12000.... Loss: 0.0087 | Accuracy: 0.9915\n",
      "Iterations: 11670/12000.... Loss: 0.0081 | Accuracy: 0.9925\n",
      "Iterations: 11680/12000.... Loss: 0.0089 | Accuracy: 0.9910\n",
      "Iterations: 11690/12000.... Loss: 0.0084 | Accuracy: 0.9916\n",
      "Iterations: 11700/12000.... Loss: 0.0083 | Accuracy: 0.9921\n",
      "Iterations: 11710/12000.... Loss: 0.0083 | Accuracy: 0.9922\n",
      "Iterations: 11720/12000.... Loss: 0.0084 | Accuracy: 0.9919\n",
      "Iterations: 11730/12000.... Loss: 0.0082 | Accuracy: 0.9922\n",
      "Iterations: 11740/12000.... Loss: 0.0085 | Accuracy: 0.9916\n",
      "Iterations: 11750/12000.... Loss: 0.0086 | Accuracy: 0.9919\n",
      "Iterations: 11760/12000.... Loss: 0.0083 | Accuracy: 0.9919\n",
      "Iterations: 11770/12000.... Loss: 0.0085 | Accuracy: 0.9918\n",
      "Iterations: 11780/12000.... Loss: 0.0084 | Accuracy: 0.9917\n",
      "Iterations: 11790/12000.... Loss: 0.0086 | Accuracy: 0.9917\n",
      "Iterations: 11800/12000.... Loss: 0.0084 | Accuracy: 0.9915\n",
      "Iterations: 11810/12000.... Loss: 0.0082 | Accuracy: 0.9919\n",
      "Iterations: 11820/12000.... Loss: 0.0085 | Accuracy: 0.9916\n",
      "Iterations: 11830/12000.... Loss: 0.0081 | Accuracy: 0.9919\n",
      "Iterations: 11840/12000.... Loss: 0.0081 | Accuracy: 0.9924\n",
      "Iterations: 11850/12000.... Loss: 0.0083 | Accuracy: 0.9918\n",
      "Iterations: 11860/12000.... Loss: 0.0079 | Accuracy: 0.9926\n",
      "Iterations: 11870/12000.... Loss: 0.0083 | Accuracy: 0.9925\n",
      "Iterations: 11880/12000.... Loss: 0.0084 | Accuracy: 0.9920\n",
      "Iterations: 11890/12000.... Loss: 0.0082 | Accuracy: 0.9917\n",
      "Iterations: 11900/12000.... Loss: 0.0084 | Accuracy: 0.9915\n",
      "Iterations: 11910/12000.... Loss: 0.0083 | Accuracy: 0.9917\n",
      "Iterations: 11920/12000.... Loss: 0.0081 | Accuracy: 0.9920\n",
      "Iterations: 11930/12000.... Loss: 0.0082 | Accuracy: 0.9914\n",
      "Iterations: 11940/12000.... Loss: 0.0082 | Accuracy: 0.9915\n",
      "Iterations: 11950/12000.... Loss: 0.0083 | Accuracy: 0.9918\n",
      "Iterations: 11960/12000.... Loss: 0.0078 | Accuracy: 0.9926\n",
      "Iterations: 11970/12000.... Loss: 0.0074 | Accuracy: 0.9931\n",
      "Iterations: 11980/12000.... Loss: 0.0083 | Accuracy: 0.9913\n",
      "Iterations: 11990/12000.... Loss: 0.0078 | Accuracy: 0.9922\n",
      "Iterations: 12000/12000.... Loss: 0.0082 | Accuracy: 0.9919\n"
     ]
    }
   ],
   "source": [
    "n_iterations = 12000\n",
    "for iterations in range(10001, n_iterations+1):\n",
    "    input_seq,target_seq = generate_seq(batch_size = batch_size, vec_len = vec_len, R = R, T = T)\n",
    "    accuracy,total_loss = train(HebbFF_R6,criterion,optimizer,input_seq,target_seq,T)\n",
    "    if iterations % 10 == 0:\n",
    "        print('Iterations: {}/{}....'.format(iterations, n_iterations), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(total_loss.item()), end=' | ')\n",
    "        print(\"Accuracy: {:.4f}\".format(accuracy.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "db6f1a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R =  1 ... accuracy:  0.9962|loss:  0.0031\n",
      "R =  2 ... accuracy:  0.9959|loss:  0.0035\n",
      "R =  3 ... accuracy:  0.9961|loss:  0.0033\n",
      "R =  4 ... accuracy:  0.9948|loss:  0.0042\n",
      "R =  5 ... accuracy:  0.9941|loss:  0.0051\n",
      "R =  6 ... accuracy:  0.9922|loss:  0.0081\n",
      "R =  7 ... accuracy:  0.9851|loss:  0.0144\n",
      "R =  8 ... accuracy:  0.9692|loss:  0.0254\n",
      "R =  9 ... accuracy:  0.9409|loss:  0.0429\n",
      "R =  10 ... accuracy:  0.9102|loss:  0.0630\n",
      "R =  11 ... accuracy:  0.8777|loss:  0.0847\n",
      "R =  12 ... accuracy:  0.8493|loss:  0.1057\n",
      "R =  13 ... accuracy:  0.8248|loss:  0.1255\n",
      "R =  14 ... accuracy:  0.8068|loss:  0.1407\n",
      "R =  15 ... accuracy:  0.7917|loss:  0.1552\n",
      "R =  16 ... accuracy:  0.7779|loss:  0.1679\n",
      "R =  17 ... accuracy:  0.7689|loss:  0.1771\n",
      "R =  18 ... accuracy:  0.7591|loss:  0.1867\n",
      "R =  19 ... accuracy:  0.7514|loss:  0.1959\n",
      "R =  20 ... accuracy:  0.7485|loss:  0.1990\n",
      "R =  21 ... accuracy:  0.7414|loss:  0.2071\n",
      "R =  22 ... accuracy:  0.7394|loss:  0.2092\n",
      "R =  23 ... accuracy:  0.7328|loss:  0.2155\n",
      "R =  24 ... accuracy:  0.7269|loss:  0.2229\n",
      "R =  25 ... accuracy:  0.7251|loss:  0.2273\n",
      "R =  26 ... accuracy:  0.7243|loss:  0.2279\n",
      "R =  27 ... accuracy:  0.7200|loss:  0.2320\n",
      "R =  28 ... accuracy:  0.7157|loss:  0.2373\n",
      "R =  29 ... accuracy:  0.7122|loss:  0.2410\n",
      "R =  30 ... accuracy:  0.7110|loss:  0.2421\n",
      "R =  31 ... accuracy:  0.7058|loss:  0.2484\n",
      "R =  32 ... accuracy:  0.7095|loss:  0.2467\n",
      "R =  33 ... accuracy:  0.7066|loss:  0.2504\n",
      "R =  34 ... accuracy:  0.7042|loss:  0.2529\n",
      "R =  35 ... accuracy:  0.7014|loss:  0.2548\n",
      "R =  36 ... accuracy:  0.7007|loss:  0.2575\n",
      "R =  37 ... accuracy:  0.7000|loss:  0.2597\n",
      "R =  38 ... accuracy:  0.6979|loss:  0.2601\n",
      "R =  39 ... accuracy:  0.7001|loss:  0.2604\n",
      "R =  40 ... accuracy:  0.6971|loss:  0.2626\n"
     ]
    }
   ],
   "source": [
    "ACC_R6 = []\n",
    "for i in range(1, 41):\n",
    "    input_seq,target_seq = generate_seq(batch_size = batch_size, vec_len = vec_len, R = i, T = T)\n",
    "    accuracy,total_loss = test(HebbFF_R6,criterion,optimizer,input_seq,target_seq,T)\n",
    "    print('R = ',i,'...','accuracy: ',format(accuracy.item() , '.4f'), end = '|')\n",
    "    print('loss: ',format(total_loss.item() , '.4f'))\n",
    "    ACC_R6.append(accuracy.item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "038a7318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy across different intervals after training with R = 6')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "r_axis = np.arange(1,41)\n",
    "plt.plot(r_axis,ACC_R6)\n",
    "plt.title(\"Accuracy across different intervals after training with R = 6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353d2779",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
