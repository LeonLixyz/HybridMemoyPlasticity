{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22bbe03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d5d2776",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c7dcd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_seq(batch_size):\n",
    "    input = []\n",
    "    target = []\n",
    "    T = 50\n",
    "    for j in range(batch_size):\n",
    "        frequency = (5 - 1) * torch.rand(1, 1) + 1\n",
    "        theta = (5 - 1) * torch.rand(1, 1) + 1\n",
    "        amplitude = (5 - 1) * torch.rand(1, 1) + 1\n",
    "        time = torch.linspace(0, 5, steps=T)\n",
    "        x_p = torch.cat((frequency,theta,amplitude),0)\n",
    "        x = x_p.tile((T))\n",
    "        y = amplitude * torch.sin(frequency * time + theta)\n",
    "        input.append(x)\n",
    "        target.append(y)\n",
    "\n",
    "    input_seq = torch.transpose(torch.stack(input, dim=0), 1, 2)\n",
    "    target_seq = torch.stack(target, dim=0).view(batch_size,T,1)\n",
    "    \n",
    "    return(input_seq,target_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85c014b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, batch_first=True)   \n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(1, batch_size, self.hidden_dim)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17ba6e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd = RNN(input_size=3, output_size=1, hidden_dim=100)\n",
    "n_epochs = 50000\n",
    "lr=0.01\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(cfd.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bf52b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/50000............. Loss: 5.5352\n",
      "Epoch: 20/50000............. Loss: 5.2667\n",
      "Epoch: 30/50000............. Loss: 5.0930\n",
      "Epoch: 40/50000............. Loss: 5.0550\n",
      "Epoch: 50/50000............. Loss: 5.3820\n",
      "Epoch: 60/50000............. Loss: 5.0342\n",
      "Epoch: 70/50000............. Loss: 5.9425\n",
      "Epoch: 80/50000............. Loss: 4.9474\n",
      "Epoch: 90/50000............. Loss: 5.7296\n",
      "Epoch: 100/50000............. Loss: 4.6186\n",
      "Epoch: 110/50000............. Loss: 4.7884\n",
      "Epoch: 120/50000............. Loss: 5.2799\n",
      "Epoch: 130/50000............. Loss: 4.8809\n",
      "Epoch: 140/50000............. Loss: 4.4977\n",
      "Epoch: 150/50000............. Loss: 4.9557\n",
      "Epoch: 160/50000............. Loss: 4.3543\n",
      "Epoch: 170/50000............. Loss: 4.5078\n",
      "Epoch: 180/50000............. Loss: 4.7085\n",
      "Epoch: 190/50000............. Loss: 5.3272\n",
      "Epoch: 200/50000............. Loss: 4.6463\n",
      "Epoch: 210/50000............. Loss: 4.9015\n",
      "Epoch: 220/50000............. Loss: 4.5229\n",
      "Epoch: 230/50000............. Loss: 4.7914\n",
      "Epoch: 240/50000............. Loss: 5.3216\n",
      "Epoch: 250/50000............. Loss: 4.6866\n",
      "Epoch: 260/50000............. Loss: 4.5955\n",
      "Epoch: 270/50000............. Loss: 5.2768\n",
      "Epoch: 280/50000............. Loss: 4.6610\n",
      "Epoch: 290/50000............. Loss: 5.4606\n",
      "Epoch: 300/50000............. Loss: 5.2966\n",
      "Epoch: 310/50000............. Loss: 5.0901\n",
      "Epoch: 320/50000............. Loss: 4.6807\n",
      "Epoch: 330/50000............. Loss: 4.2531\n",
      "Epoch: 340/50000............. Loss: 4.9733\n",
      "Epoch: 350/50000............. Loss: 4.9511\n",
      "Epoch: 360/50000............. Loss: 4.5956\n",
      "Epoch: 370/50000............. Loss: 8.0526\n",
      "Epoch: 380/50000............. Loss: 5.1450\n",
      "Epoch: 390/50000............. Loss: 4.7742\n",
      "Epoch: 400/50000............. Loss: 5.3244\n",
      "Epoch: 410/50000............. Loss: 5.3506\n",
      "Epoch: 420/50000............. Loss: 4.8633\n",
      "Epoch: 430/50000............. Loss: 5.5641\n",
      "Epoch: 440/50000............. Loss: 3.9743\n",
      "Epoch: 450/50000............. Loss: 5.3270\n",
      "Epoch: 460/50000............. Loss: 5.0828\n",
      "Epoch: 470/50000............. Loss: 4.7130\n",
      "Epoch: 480/50000............. Loss: 5.1217\n",
      "Epoch: 490/50000............. Loss: 4.5732\n",
      "Epoch: 500/50000............. Loss: 4.7299\n",
      "Epoch: 510/50000............. Loss: 4.7222\n",
      "Epoch: 520/50000............. Loss: 4.4828\n",
      "Epoch: 530/50000............. Loss: 5.1846\n",
      "Epoch: 540/50000............. Loss: 5.3632\n",
      "Epoch: 550/50000............. Loss: 4.8336\n",
      "Epoch: 560/50000............. Loss: 5.0530\n",
      "Epoch: 570/50000............. Loss: 4.9219\n",
      "Epoch: 580/50000............. Loss: 5.0266\n",
      "Epoch: 590/50000............. Loss: 4.8723\n",
      "Epoch: 600/50000............. Loss: 4.9975\n",
      "Epoch: 610/50000............. Loss: 4.9373\n",
      "Epoch: 620/50000............. Loss: 4.4095\n",
      "Epoch: 630/50000............. Loss: 4.9951\n",
      "Epoch: 640/50000............. Loss: 5.2013\n",
      "Epoch: 650/50000............. Loss: 4.9423\n",
      "Epoch: 660/50000............. Loss: 4.7599\n",
      "Epoch: 670/50000............. Loss: 4.4573\n",
      "Epoch: 680/50000............. Loss: 4.6933\n",
      "Epoch: 690/50000............. Loss: 4.6856\n",
      "Epoch: 700/50000............. Loss: 5.1361\n",
      "Epoch: 710/50000............. Loss: 4.4669\n",
      "Epoch: 720/50000............. Loss: 4.6441\n",
      "Epoch: 730/50000............. Loss: 4.5107\n",
      "Epoch: 740/50000............. Loss: 4.3030\n",
      "Epoch: 750/50000............. Loss: 4.9242\n",
      "Epoch: 760/50000............. Loss: 5.1890\n",
      "Epoch: 770/50000............. Loss: 5.3199\n",
      "Epoch: 780/50000............. Loss: 5.5237\n",
      "Epoch: 790/50000............. Loss: 5.0684\n",
      "Epoch: 800/50000............. Loss: 5.0166\n",
      "Epoch: 810/50000............. Loss: 4.8523\n",
      "Epoch: 820/50000............. Loss: 4.5080\n",
      "Epoch: 830/50000............. Loss: 4.8390\n",
      "Epoch: 840/50000............. Loss: 4.8531\n",
      "Epoch: 850/50000............. Loss: 4.9826\n",
      "Epoch: 860/50000............. Loss: 5.5346\n",
      "Epoch: 870/50000............. Loss: 4.8728\n",
      "Epoch: 880/50000............. Loss: 4.5094\n",
      "Epoch: 890/50000............. Loss: 4.8158\n",
      "Epoch: 900/50000............. Loss: 4.4783\n",
      "Epoch: 910/50000............. Loss: 5.3139\n",
      "Epoch: 920/50000............. Loss: 4.6114\n",
      "Epoch: 930/50000............. Loss: 4.4661\n",
      "Epoch: 940/50000............. Loss: 4.6642\n",
      "Epoch: 950/50000............. Loss: 4.7845\n",
      "Epoch: 960/50000............. Loss: 5.0241\n",
      "Epoch: 970/50000............. Loss: 4.5514\n",
      "Epoch: 980/50000............. Loss: 4.7135\n",
      "Epoch: 990/50000............. Loss: 4.7991\n",
      "Epoch: 1000/50000............. Loss: 5.3481\n",
      "Epoch: 1010/50000............. Loss: 5.6148\n",
      "Epoch: 1020/50000............. Loss: 4.6718\n",
      "Epoch: 1030/50000............. Loss: 4.9300\n",
      "Epoch: 1040/50000............. Loss: 5.0377\n",
      "Epoch: 1050/50000............. Loss: 4.5667\n",
      "Epoch: 1060/50000............. Loss: 4.1895\n",
      "Epoch: 1070/50000............. Loss: 4.6164\n",
      "Epoch: 1080/50000............. Loss: 4.5063\n",
      "Epoch: 1090/50000............. Loss: 4.6387\n",
      "Epoch: 1100/50000............. Loss: 5.0938\n",
      "Epoch: 1110/50000............. Loss: 4.9198\n",
      "Epoch: 1120/50000............. Loss: 4.6470\n",
      "Epoch: 1130/50000............. Loss: 4.5763\n",
      "Epoch: 1140/50000............. Loss: 5.0374\n",
      "Epoch: 1150/50000............. Loss: 5.1870\n",
      "Epoch: 1160/50000............. Loss: 4.9298\n",
      "Epoch: 1170/50000............. Loss: 4.5604\n",
      "Epoch: 1180/50000............. Loss: 4.8970\n",
      "Epoch: 1190/50000............. Loss: 4.5061\n",
      "Epoch: 1200/50000............. Loss: 4.4403\n",
      "Epoch: 1210/50000............. Loss: 4.7929\n",
      "Epoch: 1220/50000............. Loss: 4.3658\n",
      "Epoch: 1230/50000............. Loss: 6.4886\n",
      "Epoch: 1240/50000............. Loss: 4.6785\n",
      "Epoch: 1250/50000............. Loss: 5.3212\n",
      "Epoch: 1260/50000............. Loss: 4.5578\n",
      "Epoch: 1270/50000............. Loss: 4.3450\n",
      "Epoch: 1280/50000............. Loss: 4.6858\n",
      "Epoch: 1290/50000............. Loss: 4.8795\n",
      "Epoch: 1300/50000............. Loss: 4.8661\n",
      "Epoch: 1310/50000............. Loss: 5.1067\n",
      "Epoch: 1320/50000............. Loss: 4.9232\n",
      "Epoch: 1330/50000............. Loss: 4.5557\n",
      "Epoch: 1340/50000............. Loss: 4.6968\n",
      "Epoch: 1350/50000............. Loss: 5.1339\n",
      "Epoch: 1360/50000............. Loss: 5.1251\n",
      "Epoch: 1370/50000............. Loss: 5.3841\n",
      "Epoch: 1380/50000............. Loss: 4.4690\n",
      "Epoch: 1390/50000............. Loss: 4.7390\n",
      "Epoch: 1400/50000............. Loss: 4.7347\n",
      "Epoch: 1410/50000............. Loss: 4.6227\n",
      "Epoch: 1420/50000............. Loss: 4.7899\n",
      "Epoch: 1430/50000............. Loss: 4.8308\n",
      "Epoch: 1440/50000............. Loss: 4.7591\n",
      "Epoch: 1450/50000............. Loss: 5.3387\n",
      "Epoch: 1460/50000............. Loss: 4.7882\n",
      "Epoch: 1470/50000............. Loss: 4.5941\n",
      "Epoch: 1480/50000............. Loss: 4.5868\n",
      "Epoch: 1490/50000............. Loss: 4.9198\n",
      "Epoch: 1500/50000............. Loss: 5.3186\n",
      "Epoch: 1510/50000............. Loss: 5.0786\n",
      "Epoch: 1520/50000............. Loss: 5.3621\n",
      "Epoch: 1530/50000............. Loss: 5.1688\n",
      "Epoch: 1540/50000............. Loss: 4.9112\n",
      "Epoch: 1550/50000............. Loss: 5.5155\n",
      "Epoch: 1560/50000............. Loss: 5.2931\n",
      "Epoch: 1570/50000............. Loss: 4.1766\n",
      "Epoch: 1580/50000............. Loss: 5.5241\n",
      "Epoch: 1590/50000............. Loss: 5.1039\n",
      "Epoch: 1600/50000............. Loss: 5.2148\n",
      "Epoch: 1610/50000............. Loss: 5.3628\n",
      "Epoch: 1620/50000............. Loss: 4.5121\n",
      "Epoch: 1630/50000............. Loss: 4.0144\n",
      "Epoch: 1640/50000............. Loss: 4.2589\n",
      "Epoch: 1650/50000............. Loss: 5.3500\n",
      "Epoch: 1660/50000............. Loss: 4.8633\n",
      "Epoch: 1670/50000............. Loss: 4.9369\n",
      "Epoch: 1680/50000............. Loss: 4.4619\n",
      "Epoch: 1690/50000............. Loss: 5.0049\n",
      "Epoch: 1700/50000............. Loss: 4.5828\n",
      "Epoch: 1710/50000............. Loss: 4.8968\n",
      "Epoch: 1720/50000............. Loss: 4.8933\n",
      "Epoch: 1730/50000............. Loss: 4.6298\n",
      "Epoch: 1740/50000............. Loss: 4.8176\n",
      "Epoch: 1750/50000............. Loss: 4.6512\n",
      "Epoch: 1760/50000............. Loss: 4.5412\n",
      "Epoch: 1770/50000............. Loss: 5.4632\n",
      "Epoch: 1780/50000............. Loss: 5.1095\n",
      "Epoch: 1790/50000............. Loss: 4.8853\n",
      "Epoch: 1800/50000............. Loss: 4.9714\n",
      "Epoch: 1810/50000............. Loss: 5.3743\n",
      "Epoch: 1820/50000............. Loss: 5.4920\n",
      "Epoch: 1830/50000............. Loss: 4.6242\n",
      "Epoch: 1840/50000............. Loss: 4.6078\n",
      "Epoch: 1850/50000............. Loss: 4.3893\n",
      "Epoch: 1860/50000............. Loss: 4.8296\n",
      "Epoch: 1870/50000............. Loss: 4.7216\n",
      "Epoch: 1880/50000............. Loss: 4.7304\n",
      "Epoch: 1890/50000............. Loss: 5.1682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1900/50000............. Loss: 4.4581\n",
      "Epoch: 1910/50000............. Loss: 4.4734\n",
      "Epoch: 1920/50000............. Loss: 5.2636\n",
      "Epoch: 1930/50000............. Loss: 4.4527\n",
      "Epoch: 1940/50000............. Loss: 4.3426\n",
      "Epoch: 1950/50000............. Loss: 4.8891\n",
      "Epoch: 1960/50000............. Loss: 4.3330\n",
      "Epoch: 1970/50000............. Loss: 4.5989\n",
      "Epoch: 1980/50000............. Loss: 5.0998\n",
      "Epoch: 1990/50000............. Loss: 4.7856\n",
      "Epoch: 2000/50000............. Loss: 4.9273\n",
      "Epoch: 2010/50000............. Loss: 4.8631\n",
      "Epoch: 2020/50000............. Loss: 4.4864\n",
      "Epoch: 2030/50000............. Loss: 5.3206\n",
      "Epoch: 2040/50000............. Loss: 4.2793\n",
      "Epoch: 2050/50000............. Loss: 4.8333\n",
      "Epoch: 2060/50000............. Loss: 4.3031\n",
      "Epoch: 2070/50000............. Loss: 4.6731\n",
      "Epoch: 2080/50000............. Loss: 5.5900\n",
      "Epoch: 2090/50000............. Loss: 4.8309\n",
      "Epoch: 2100/50000............. Loss: 4.3333\n",
      "Epoch: 2110/50000............. Loss: 5.7674\n",
      "Epoch: 2120/50000............. Loss: 4.4515\n",
      "Epoch: 2130/50000............. Loss: 4.5323\n",
      "Epoch: 2140/50000............. Loss: 5.1399\n",
      "Epoch: 2150/50000............. Loss: 4.8734\n",
      "Epoch: 2160/50000............. Loss: 5.0176\n",
      "Epoch: 2170/50000............. Loss: 5.0376\n",
      "Epoch: 2180/50000............. Loss: 4.5015\n",
      "Epoch: 2190/50000............. Loss: 4.5166\n",
      "Epoch: 2200/50000............. Loss: 5.0200\n",
      "Epoch: 2210/50000............. Loss: 5.0276\n",
      "Epoch: 2220/50000............. Loss: 4.4149\n",
      "Epoch: 2230/50000............. Loss: 5.3547\n",
      "Epoch: 2240/50000............. Loss: 4.7572\n",
      "Epoch: 2250/50000............. Loss: 4.9017\n",
      "Epoch: 2260/50000............. Loss: 4.8092\n",
      "Epoch: 2270/50000............. Loss: 4.1803\n",
      "Epoch: 2280/50000............. Loss: 5.0036\n",
      "Epoch: 2290/50000............. Loss: 4.6417\n",
      "Epoch: 2300/50000............. Loss: 4.5648\n",
      "Epoch: 2310/50000............. Loss: 4.8295\n",
      "Epoch: 2320/50000............. Loss: 4.7434\n",
      "Epoch: 2330/50000............. Loss: 4.8901\n",
      "Epoch: 2340/50000............. Loss: 4.1368\n",
      "Epoch: 2350/50000............. Loss: 4.4704\n",
      "Epoch: 2360/50000............. Loss: 4.5824\n",
      "Epoch: 2370/50000............. Loss: 4.7308\n",
      "Epoch: 2380/50000............. Loss: 4.4067\n",
      "Epoch: 2390/50000............. Loss: 4.4521\n",
      "Epoch: 2400/50000............. Loss: 4.7783\n",
      "Epoch: 2410/50000............. Loss: 5.1646\n",
      "Epoch: 2420/50000............. Loss: 4.4788\n",
      "Epoch: 2430/50000............. Loss: 4.5813\n",
      "Epoch: 2440/50000............. Loss: 4.6930\n",
      "Epoch: 2450/50000............. Loss: 5.1249\n",
      "Epoch: 2460/50000............. Loss: 3.9310\n",
      "Epoch: 2470/50000............. Loss: 4.6944\n",
      "Epoch: 2480/50000............. Loss: 5.0078\n",
      "Epoch: 2490/50000............. Loss: 4.9869\n",
      "Epoch: 2500/50000............. Loss: 5.0074\n",
      "Epoch: 2510/50000............. Loss: 4.6652\n",
      "Epoch: 2520/50000............. Loss: 4.8292\n",
      "Epoch: 2530/50000............. Loss: 4.6548\n",
      "Epoch: 2540/50000............. Loss: 4.4717\n",
      "Epoch: 2550/50000............. Loss: 5.0690\n",
      "Epoch: 2560/50000............. Loss: 4.9856\n",
      "Epoch: 2570/50000............. Loss: 5.2248\n",
      "Epoch: 2580/50000............. Loss: 4.7426\n",
      "Epoch: 2590/50000............. Loss: 5.0396\n",
      "Epoch: 2600/50000............. Loss: 4.7000\n",
      "Epoch: 2610/50000............. Loss: 4.4580\n",
      "Epoch: 2620/50000............. Loss: 4.8558\n",
      "Epoch: 2630/50000............. Loss: 4.4170\n",
      "Epoch: 2640/50000............. Loss: 4.4344\n",
      "Epoch: 2650/50000............. Loss: 4.0507\n",
      "Epoch: 2660/50000............. Loss: 5.1558\n",
      "Epoch: 2670/50000............. Loss: 4.6625\n",
      "Epoch: 2680/50000............. Loss: 4.9121\n",
      "Epoch: 2690/50000............. Loss: 4.5863\n",
      "Epoch: 2700/50000............. Loss: 4.6097\n",
      "Epoch: 2710/50000............. Loss: 5.0141\n",
      "Epoch: 2720/50000............. Loss: 4.5908\n",
      "Epoch: 2730/50000............. Loss: 4.5923\n",
      "Epoch: 2740/50000............. Loss: 5.2408\n",
      "Epoch: 2750/50000............. Loss: 5.1560\n",
      "Epoch: 2760/50000............. Loss: 5.2394\n",
      "Epoch: 2770/50000............. Loss: 4.6122\n",
      "Epoch: 2780/50000............. Loss: 4.5300\n",
      "Epoch: 2790/50000............. Loss: 5.1380\n",
      "Epoch: 2800/50000............. Loss: 4.9147\n",
      "Epoch: 2810/50000............. Loss: 5.1463\n",
      "Epoch: 2820/50000............. Loss: 4.5117\n",
      "Epoch: 2830/50000............. Loss: 4.7398\n",
      "Epoch: 2840/50000............. Loss: 5.1061\n",
      "Epoch: 2850/50000............. Loss: 4.4290\n",
      "Epoch: 2860/50000............. Loss: 4.7943\n",
      "Epoch: 2870/50000............. Loss: 4.2033\n",
      "Epoch: 2880/50000............. Loss: 4.3251\n",
      "Epoch: 2890/50000............. Loss: 4.4413\n",
      "Epoch: 2900/50000............. Loss: 5.0975\n",
      "Epoch: 2910/50000............. Loss: 4.5775\n",
      "Epoch: 2920/50000............. Loss: 4.4909\n",
      "Epoch: 2930/50000............. Loss: 5.2135\n",
      "Epoch: 2940/50000............. Loss: 4.4467\n",
      "Epoch: 2950/50000............. Loss: 4.9022\n",
      "Epoch: 2960/50000............. Loss: 4.5200\n",
      "Epoch: 2970/50000............. Loss: 4.6320\n",
      "Epoch: 2980/50000............. Loss: 4.3898\n",
      "Epoch: 2990/50000............. Loss: 4.9847\n",
      "Epoch: 3000/50000............. Loss: 5.0335\n",
      "Epoch: 3010/50000............. Loss: 4.7683\n",
      "Epoch: 3020/50000............. Loss: 4.3897\n",
      "Epoch: 3030/50000............. Loss: 4.9780\n",
      "Epoch: 3040/50000............. Loss: 5.1775\n",
      "Epoch: 3050/50000............. Loss: 4.3690\n",
      "Epoch: 3060/50000............. Loss: 4.8974\n",
      "Epoch: 3070/50000............. Loss: 4.0661\n",
      "Epoch: 3080/50000............. Loss: 4.9044\n",
      "Epoch: 3090/50000............. Loss: 4.9109\n",
      "Epoch: 3100/50000............. Loss: 5.4316\n",
      "Epoch: 3110/50000............. Loss: 4.4219\n",
      "Epoch: 3120/50000............. Loss: 5.2402\n",
      "Epoch: 3130/50000............. Loss: 5.0242\n",
      "Epoch: 3140/50000............. Loss: 4.4432\n",
      "Epoch: 3150/50000............. Loss: 4.9985\n",
      "Epoch: 3160/50000............. Loss: 4.7189\n",
      "Epoch: 3170/50000............. Loss: 4.7958\n",
      "Epoch: 3180/50000............. Loss: 5.2242\n",
      "Epoch: 3190/50000............. Loss: 4.6605\n",
      "Epoch: 3200/50000............. Loss: 5.2460\n",
      "Epoch: 3210/50000............. Loss: 5.0524\n",
      "Epoch: 3220/50000............. Loss: 4.0740\n",
      "Epoch: 3230/50000............. Loss: 5.1249\n",
      "Epoch: 3240/50000............. Loss: 4.3453\n",
      "Epoch: 3250/50000............. Loss: 4.6687\n",
      "Epoch: 3260/50000............. Loss: 4.4912\n",
      "Epoch: 3270/50000............. Loss: 5.1001\n",
      "Epoch: 3280/50000............. Loss: 5.0833\n",
      "Epoch: 3290/50000............. Loss: 4.6186\n",
      "Epoch: 3300/50000............. Loss: 4.2931\n",
      "Epoch: 3310/50000............. Loss: 5.0047\n",
      "Epoch: 3320/50000............. Loss: 4.5820\n",
      "Epoch: 3330/50000............. Loss: 4.9887\n",
      "Epoch: 3340/50000............. Loss: 5.0997\n",
      "Epoch: 3350/50000............. Loss: 4.9045\n",
      "Epoch: 3360/50000............. Loss: 4.3081\n",
      "Epoch: 3370/50000............. Loss: 5.1267\n",
      "Epoch: 3380/50000............. Loss: 4.4809\n",
      "Epoch: 3390/50000............. Loss: 4.8231\n",
      "Epoch: 3400/50000............. Loss: 4.4261\n",
      "Epoch: 3410/50000............. Loss: 4.4020\n",
      "Epoch: 3420/50000............. Loss: 4.4009\n",
      "Epoch: 3430/50000............. Loss: 4.9000\n",
      "Epoch: 3440/50000............. Loss: 5.0169\n",
      "Epoch: 3450/50000............. Loss: 4.7463\n",
      "Epoch: 3460/50000............. Loss: 4.6084\n",
      "Epoch: 3470/50000............. Loss: 4.2727\n",
      "Epoch: 3480/50000............. Loss: 4.5488\n",
      "Epoch: 3490/50000............. Loss: 4.5037\n",
      "Epoch: 3500/50000............. Loss: 4.7061\n",
      "Epoch: 3510/50000............. Loss: 4.5667\n",
      "Epoch: 3520/50000............. Loss: 4.5318\n",
      "Epoch: 3530/50000............. Loss: 5.0909\n",
      "Epoch: 3540/50000............. Loss: 4.6987\n",
      "Epoch: 3550/50000............. Loss: 5.0526\n",
      "Epoch: 3560/50000............. Loss: 4.5902\n",
      "Epoch: 3570/50000............. Loss: 5.0048\n",
      "Epoch: 3580/50000............. Loss: 4.9391\n",
      "Epoch: 3590/50000............. Loss: 4.9441\n",
      "Epoch: 3600/50000............. Loss: 5.1452\n",
      "Epoch: 3610/50000............. Loss: 5.4542\n",
      "Epoch: 3620/50000............. Loss: 4.9806\n",
      "Epoch: 3630/50000............. Loss: 4.8763\n",
      "Epoch: 3640/50000............. Loss: 4.5803\n",
      "Epoch: 3650/50000............. Loss: 4.6353\n",
      "Epoch: 3660/50000............. Loss: 5.0427\n",
      "Epoch: 3670/50000............. Loss: 4.4861\n",
      "Epoch: 3680/50000............. Loss: 4.2609\n",
      "Epoch: 3690/50000............. Loss: 5.3024\n",
      "Epoch: 3700/50000............. Loss: 5.1655\n",
      "Epoch: 3710/50000............. Loss: 4.8814\n",
      "Epoch: 3720/50000............. Loss: 4.6983\n",
      "Epoch: 3730/50000............. Loss: 4.8425\n",
      "Epoch: 3740/50000............. Loss: 4.6902\n",
      "Epoch: 3750/50000............. Loss: 4.4135\n",
      "Epoch: 3760/50000............. Loss: 4.4798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3770/50000............. Loss: 4.3908\n",
      "Epoch: 3780/50000............. Loss: 4.9668\n",
      "Epoch: 3790/50000............. Loss: 4.5746\n",
      "Epoch: 3800/50000............. Loss: 5.5509\n",
      "Epoch: 3810/50000............. Loss: 4.9088\n",
      "Epoch: 3820/50000............. Loss: 4.9544\n",
      "Epoch: 3830/50000............. Loss: 4.6973\n",
      "Epoch: 3840/50000............. Loss: 5.3798\n",
      "Epoch: 3850/50000............. Loss: 4.6801\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    input_seq,target_seq = generate_seq(batch_size = 100)\n",
    "\n",
    "    optimizer.zero_grad() \n",
    "\n",
    "    output, hidden = cfd(input_seq)\n",
    "    \n",
    "    loss = criterion(output, target_seq.view(-1,1))\n",
    "    \n",
    "    loss.backward() \n",
    "    optimizer.step() \n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27a516b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
